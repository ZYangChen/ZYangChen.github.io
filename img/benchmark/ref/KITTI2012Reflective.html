<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!-- saved from url=(0103)https://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php?benchmark=stereo&table=refl&error=4&eval=all -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>The KITTI Vision Benchmark Suite</title>
<link rel="stylesheet" type="text/css" href="./KITTI2012Reflective_files/style.css" media="screen">
<style type="text/css" data-fbcssmodules="css:fb.css.base css:fb.css.dialog css:fb.css.iframewidget css:fb.css.customer_chat_plugin_iframe">.fb_hidden{position:absolute;top:-10000px;z-index:10001}.fb_reposition{overflow:hidden;position:relative}.fb_invisible{display:none}.fb_reset{background:none;border:0;border-spacing:0;color:#000;cursor:auto;direction:ltr;font-family:'lucida grande', tahoma, verdana, arial, sans-serif;font-size:11px;font-style:normal;font-variant:normal;font-weight:normal;letter-spacing:normal;line-height:1;margin:0;overflow:visible;padding:0;text-align:left;text-decoration:none;text-indent:0;text-shadow:none;text-transform:none;visibility:visible;white-space:normal;word-spacing:normal}.fb_reset>div{overflow:hidden}@keyframes fb_transform{from{opacity:0;transform:scale(.95)}to{opacity:1;transform:scale(1)}}.fb_animate{animation:fb_transform .3s forwards}
.fb_hidden{position:absolute;top:-10000px;z-index:10001}.fb_reposition{overflow:hidden;position:relative}.fb_invisible{display:none}.fb_reset{background:none;border:0;border-spacing:0;color:#000;cursor:auto;direction:ltr;font-family:'lucida grande', tahoma, verdana, arial, sans-serif;font-size:11px;font-style:normal;font-variant:normal;font-weight:normal;letter-spacing:normal;line-height:1;margin:0;overflow:visible;padding:0;text-align:left;text-decoration:none;text-indent:0;text-shadow:none;text-transform:none;visibility:visible;white-space:normal;word-spacing:normal}.fb_reset>div{overflow:hidden}@keyframes fb_transform{from{opacity:0;transform:scale(.95)}to{opacity:1;transform:scale(1)}}.fb_animate{animation:fb_transform .3s forwards}
.fb_dialog{background:rgba(82, 82, 82, .7);position:absolute;top:-10000px;z-index:10001}.fb_dialog_advanced{border-radius:8px;padding:10px}.fb_dialog_content{background:#fff;color:#373737}.fb_dialog_close_icon{background:url(https://z-m-static.xx.fbcdn.net/rsrc.php/v3/yq/r/IE9JII6Z1Ys.png) no-repeat scroll 0 0 transparent;cursor:pointer;display:block;height:15px;position:absolute;right:18px;top:17px;width:15px}.fb_dialog_mobile .fb_dialog_close_icon{left:5px;right:auto;top:5px}.fb_dialog_padding{background-color:transparent;position:absolute;width:1px;z-index:-1}.fb_dialog_close_icon:hover{background:url(https://z-m-static.xx.fbcdn.net/rsrc.php/v3/yq/r/IE9JII6Z1Ys.png) no-repeat scroll 0 -15px transparent}.fb_dialog_close_icon:active{background:url(https://z-m-static.xx.fbcdn.net/rsrc.php/v3/yq/r/IE9JII6Z1Ys.png) no-repeat scroll 0 -30px transparent}.fb_dialog_iframe{line-height:0}.fb_dialog_content .dialog_title{background:#6d84b4;border:1px solid #365899;color:#fff;font-size:14px;font-weight:bold;margin:0}.fb_dialog_content .dialog_title>span{background:url(https://z-m-static.xx.fbcdn.net/rsrc.php/v3/yd/r/Cou7n-nqK52.gif) no-repeat 5px 50%;float:left;padding:5px 0 7px 26px}body.fb_hidden{height:100%;left:0;margin:0;overflow:visible;position:absolute;top:-10000px;transform:none;width:100%}.fb_dialog.fb_dialog_mobile.loading{background:url(https://z-m-static.xx.fbcdn.net/rsrc.php/v3/ya/r/3rhSv5V8j3o.gif) white no-repeat 50% 50%;min-height:100%;min-width:100%;overflow:hidden;position:absolute;top:0;z-index:10001}.fb_dialog.fb_dialog_mobile.loading.centered{background:none;height:auto;min-height:initial;min-width:initial;width:auto}.fb_dialog.fb_dialog_mobile.loading.centered #fb_dialog_loader_spinner{width:100%}.fb_dialog.fb_dialog_mobile.loading.centered .fb_dialog_content{background:none}.loading.centered #fb_dialog_loader_close{clear:both;color:#fff;display:block;font-size:18px;padding-top:20px}#fb-root #fb_dialog_ipad_overlay{background:rgba(0, 0, 0, .4);bottom:0;left:0;min-height:100%;position:absolute;right:0;top:0;width:100%;z-index:10000}#fb-root #fb_dialog_ipad_overlay.hidden{display:none}.fb_dialog.fb_dialog_mobile.loading iframe{visibility:hidden}.fb_dialog_mobile .fb_dialog_iframe{position:sticky;top:0}.fb_dialog_content .dialog_header{background:linear-gradient(from(#738aba), to(#2c4987));border-bottom:1px solid;border-color:#043b87;box-shadow:white 0 1px 1px -1px inset;color:#fff;font:bold 14px Helvetica, sans-serif;text-overflow:ellipsis;text-shadow:rgba(0, 30, 84, .296875) 0 -1px 0;vertical-align:middle;white-space:nowrap}.fb_dialog_content .dialog_header table{height:43px;width:100%}.fb_dialog_content .dialog_header td.header_left{font-size:12px;padding-left:5px;vertical-align:middle;width:60px}.fb_dialog_content .dialog_header td.header_right{font-size:12px;padding-right:5px;vertical-align:middle;width:60px}.fb_dialog_content .touchable_button{background:linear-gradient(from(#4267B2), to(#2a4887));background-clip:padding-box;border:1px solid #29487d;border-radius:3px;display:inline-block;line-height:18px;margin-top:3px;max-width:85px;padding:4px 12px;position:relative}.fb_dialog_content .dialog_header .touchable_button input{background:none;border:none;color:#fff;font:bold 12px Helvetica, sans-serif;margin:2px -12px;padding:2px 6px 3px 6px;text-shadow:rgba(0, 30, 84, .296875) 0 -1px 0}.fb_dialog_content .dialog_header .header_center{color:#fff;font-size:16px;font-weight:bold;line-height:18px;text-align:center;vertical-align:middle}.fb_dialog_content .dialog_content{background:url(https://z-m-static.xx.fbcdn.net/rsrc.php/v3/y9/r/jKEcVPZFk-2.gif) no-repeat 50% 50%;border:1px solid #4a4a4a;border-bottom:0;border-top:0;height:150px}.fb_dialog_content .dialog_footer{background:#f5f6f7;border:1px solid #4a4a4a;border-top-color:#ccc;height:40px}#fb_dialog_loader_close{float:left}.fb_dialog.fb_dialog_mobile .fb_dialog_close_icon{visibility:hidden}#fb_dialog_loader_spinner{animation:rotateSpinner 1.2s linear infinite;background-color:transparent;background-image:url(https://z-m-static.xx.fbcdn.net/rsrc.php/v3/yD/r/t-wz8gw1xG1.png);background-position:50% 50%;background-repeat:no-repeat;height:24px;width:24px}@keyframes rotateSpinner{0%{transform:rotate(0deg)}100%{transform:rotate(360deg)}}
.fb_iframe_widget{display:inline-block;position:relative}.fb_iframe_widget span{display:inline-block;position:relative;text-align:justify}.fb_iframe_widget iframe{position:absolute}.fb_iframe_widget_fluid_desktop,.fb_iframe_widget_fluid_desktop span,.fb_iframe_widget_fluid_desktop iframe{max-width:100%}.fb_iframe_widget_fluid_desktop iframe{min-width:220px;position:relative}.fb_iframe_widget_lift{z-index:1}.fb_iframe_widget_fluid{display:inline}.fb_iframe_widget_fluid span{width:100%}
.fb_mpn_mobile_landing_page_slide_out{animation-duration:200ms;animation-name:fb_mpn_landing_page_slide_out;transition-timing-function:ease-in}.fb_mpn_mobile_landing_page_slide_out_from_left{animation-duration:200ms;animation-name:fb_mpn_landing_page_slide_out_from_left;transition-timing-function:ease-in}.fb_mpn_mobile_landing_page_slide_up{animation-duration:500ms;animation-name:fb_mpn_landing_page_slide_up;transition-timing-function:ease-in}.fb_mpn_mobile_bounce_in{animation-duration:300ms;animation-name:fb_mpn_bounce_in;transition-timing-function:ease-in}.fb_mpn_mobile_bounce_out{animation-duration:300ms;animation-name:fb_mpn_bounce_out;transition-timing-function:ease-in}.fb_mpn_mobile_bounce_out_v2{animation-duration:300ms;animation-name:fb_mpn_fade_out;transition-timing-function:ease-in}.fb_customer_chat_bounce_in_v2{animation-duration:300ms;animation-name:fb_bounce_in_v2;transition-timing-function:ease-in}.fb_customer_chat_bounce_in_from_left{animation-duration:300ms;animation-name:fb_bounce_in_from_left;transition-timing-function:ease-in}.fb_customer_chat_bounce_out_v2{animation-duration:300ms;animation-name:fb_bounce_out_v2;transition-timing-function:ease-in}.fb_customer_chat_bounce_out_from_left{animation-duration:300ms;animation-name:fb_bounce_out_from_left;transition-timing-function:ease-in}.fb_invisible_flow{display:inherit;height:0;overflow-x:hidden;width:0}@keyframes fb_mpn_landing_page_slide_out{0%{margin:0 12px;width:100% - 24px}60%{border-radius:18px}100%{border-radius:50%;margin:0 24px;width:60px}}@keyframes fb_mpn_landing_page_slide_out_from_left{0%{left:12px;width:100% - 24px}60%{border-radius:18px}100%{border-radius:50%;left:12px;width:60px}}@keyframes fb_mpn_landing_page_slide_up{0%{bottom:0;opacity:0}100%{bottom:24px;opacity:1}}@keyframes fb_mpn_bounce_in{0%{opacity:.5;top:100%}100%{opacity:1;top:0}}@keyframes fb_mpn_fade_out{0%{bottom:30px;opacity:1}100%{bottom:0;opacity:0}}@keyframes fb_mpn_bounce_out{0%{opacity:1;top:0}100%{opacity:.5;top:100%}}@keyframes fb_bounce_in_v2{0%{opacity:0;transform:scale(0, 0);transform-origin:bottom right}50%{transform:scale(1.03, 1.03);transform-origin:bottom right}100%{opacity:1;transform:scale(1, 1);transform-origin:bottom right}}@keyframes fb_bounce_in_from_left{0%{opacity:0;transform:scale(0, 0);transform-origin:bottom left}50%{transform:scale(1.03, 1.03);transform-origin:bottom left}100%{opacity:1;transform:scale(1, 1);transform-origin:bottom left}}@keyframes fb_bounce_out_v2{0%{opacity:1;transform:scale(1, 1);transform-origin:bottom right}100%{opacity:0;transform:scale(0, 0);transform-origin:bottom right}}@keyframes fb_bounce_out_from_left{0%{opacity:1;transform:scale(1, 1);transform-origin:bottom left}100%{opacity:0;transform:scale(0, 0);transform-origin:bottom left}}@keyframes slideInFromBottom{0%{opacity:.1;transform:translateY(100%)}100%{opacity:1;transform:translateY(0)}}@keyframes slideInFromBottomDelay{0%{opacity:0;transform:translateY(100%)}97%{opacity:0;transform:translateY(100%)}100%{opacity:1;transform:translateY(0)}}</style></head>
<body>

<div id="fb-root" class=" fb_reset"><div style="position: absolute; top: -10000px; width: 0px; height: 0px;"><div></div></div></div>
<script src="./KITTI2012Reflective_files/sdk.js.下载" async="" crossorigin="anonymous"></script><script id="facebook-jssdk" src="./KITTI2012Reflective_files/sdk(1).js.下载"></script><script>(function(d, s, id) {
var js, fjs = d.getElementsByTagName(s)[0];
if (d.getElementById(id)) return;
js = d.createElement(s); js.id = id;
js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.6";
fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>

<div id="wrapper">
<div id="header" class="container">
<div id="logo">
<h1><a href="https://www.cvlibs.net/datasets/kitti">The KITTI Vision Benchmark Suite</a></h1>
<h2>A project of <a href="http://www.kit.edu/english" target="_blank">Karlsruhe Institute of Technology</a><br>and
<a href="http://www.ttic.edu/" target="_blank">Toyota Technological Institute at Chicago</a></h2>
</div>
<div id="banner">
<a href="https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/autonomous-vision/home/" target="_blank"><img src="./KITTI2012Reflective_files/unitue.jpg"></a>
<a href="http://www.ttic.edu/" target="_blank"><img src="./KITTI2012Reflective_files/ttic.jpg"></a>
<a href="http://www.kit.edu/english" target="_blank"><img src="./KITTI2012Reflective_files/kit.jpg"></a>
</div>
</div>
<div id="menu" class="container">
<ul id="navigation">
<li><a href="https://www.cvlibs.net/datasets/kitti/index.php">home</a></li>
<li><a href="https://www.cvlibs.net/datasets/kitti/setup.php">setup</a></li>
<li class="active"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo.php">stereo</a>
<ul>
<li><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php?benchmark=stereo" "="">Stereo 2012</a></li>
<li><a href="https://www.cvlibs.net/datasets/kitti/eval_scene_flow.php?benchmark=stereo">Stereo 2015</a></li>
</ul>
</li>
<li><a href="https://www.cvlibs.net/datasets/kitti/eval_flow.php">flow</a>
<ul>
<li><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php?benchmark=flow" "="">Flow 2012</a></li>
<li><a href="https://www.cvlibs.net/datasets/kitti/eval_scene_flow.php?benchmark=flow">Flow 2015</a></li>
</ul>
</li>
<li><a href="https://www.cvlibs.net/datasets/kitti/eval_scene_flow.php">sceneflow</a></li>

<li><a href="https://www.cvlibs.net/datasets/kitti/eval_depth_all.php">depth</a>
<ul>
<li><a href="https://www.cvlibs.net/datasets/kitti/eval_depth.php?benchmark=depth_completion">Depth Completion</a></li>
<li><a href="https://www.cvlibs.net/datasets/kitti/eval_depth.php?benchmark=depth_prediction">Depth Prediction</a></li>
</ul>
</li>

<li><a href="https://www.cvlibs.net/datasets/kitti/eval_odometry.php">odometry</a></li>
<li><a href="https://www.cvlibs.net/datasets/kitti/eval_3dobject.php">object</a>
<ul>
<li><a href="https://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=2d" "="">2d object</a></li>
<li><a href="https://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d" "="">3d object</a></li>
<li><a href="https://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=bev">bird's eye view</a></li>
</ul>
</li>
<li><a href="https://www.cvlibs.net/datasets/kitti/eval_tracking_overview.php">tracking</a>
<ul>
<li><a href="https://www.cvlibs.net/datasets/kitti/eval_tracking.php" "="">multi-object tracking</a></li>
<li><a href="https://www.cvlibs.net/datasets/kitti/eval_mots.php" "="">multi-object tracking and segmentation</a></li>
<li><a href="https://www.cvlibs.net/datasets/kitti/eval_step.php" "="">segmenting and tracking every pixel</a></li>
</ul>
</li>
<li><a href="https://www.cvlibs.net/datasets/kitti/eval_road.php">road</a></li>
<li><a href="https://www.cvlibs.net/datasets/kitti/eval_semantics.php">semantics</a>
<ul>
<li><a href="https://www.cvlibs.net/datasets/kitti/eval_semseg.php?benchmark=semantics2015" "="">pixel-level</a></li>
<li><a href="https://www.cvlibs.net/datasets/kitti/eval_instance_seg.php?benchmark=instanceSeg2015" "="">instance-level</a></li>
</ul>
</li>
<li><a href="https://www.cvlibs.net/datasets/kitti/raw_data.php">raw data</a></li>
<li><a href="https://www.cvlibs.net/datasets/kitti/user_submit.php">submit results</a></li>
</ul>
</div>
<div id="top-bar" class="container">
<div class="bar"><div class="text">
  <div style="width:900px">
<div style="float:left;">
  <a href="https://www.cvlibs.net/" target="_blank">A. Geiger</a> |
  <a href="http://www.mrt.kit.edu/mitarbeiter_lenz.php" target="_blank">P. Lenz</a> |
  <a href="http://www.mrt.kit.edu/mitarbeiter_stiller.php" target="_blank">C. Stiller</a> |
  <a href="http://ttic.uchicago.edu/~rurtasun/" target="_blank">R. Urtasun</a>
</div>
<div style="float:right;">
<a href="https://www.cvlibs.net/datasets/kitti/user_login.php">Log in</a>
</div>
</div>
</div></div>
</div>
<div id="page" class="container">
<div id="content">


<div class="section">
<h2 class="title">Stereo Evaluation 2012</h2>
<div class="entry"><p>
<img src="./KITTI2012Reflective_files/header_stereo.jpg"><br>
The stereo / flow benchmark consists of 194 training image pairs and 195 test image pairs, saved in loss less png format. Our evaluation server computes the average number of bad pixels for all non-occluded or occluded (=all groundtruth) pixels. We require that all methods use the same parameter set for all test pairs. Our development kit provides details about the data format as well as MATLAB / C++ utility functions for reading and writing disparity maps and flow fields.
</p><ul>
<li><a href="https://www.cvlibs.net/datasets/kitti/user_login.php" target="_blank">Download stereo/optical flow data set (2 GB)</a></li>
<li><a href="https://www.cvlibs.net/datasets/kitti/user_login.php" target="_blank">Download stereo/optical flow calibration files (1 MB)</a></li>
<li><a href="https://www.cvlibs.net/datasets/kitti/user_login.php" target="_blank">Download multi-view extension (20 frames per scene, all cameras) (17 GB)</a></li>
<li><a href="https://www.cvlibs.net/datasets/kitti/user_login.php" target="_blank">Download stereo/optical flow development kit (3 MB)</a></li>
<li><a href="https://www.cvlibs.net/projects/displets/" target="_blank">Semantic and instance labels for 60 images and car labels for all training images (1 MB)</a></li>
</ul>
<p></p>
<p>
Our evaluation table ranks all methods according to the number of non-occluded erroneous pixels at the specified disparity / end-point error threshold. All methods providing less than 100 % density have been interpolated using simple background interpolation as explained in the corresponding header file in the development kit. For each method we show:
</p>
<ul>
<li><b>Out-Noc:</b> Percentage of erroneous pixels in non-occluded areas</li>
<li><b>Out-All:</b> Percentage of erroneous pixels in total</li>
<li><b>Avg-Noc:</b> Average disparity / end-point error in non-occluded areas</li>
<li><b>Avg-All:</b> Average disparity / end-point error in total</li>
<li><b>Density:</b> Percentage of pixels for which ground truth has been provided by the method</li>
</ul>
<p>
<b>Note:</b> On 04.11.2013 we have improved the ground truth disparity maps and flow fields leading to slightly improvements for all methods. Please download the stereo/flow dataset with the improved ground truth for training again, if you have downloaded the dataset prior to 04.11.2013. Please consider reporting these new number for all future submissions. Links to last leaderboards before the updates: <a href="https://www.cvlibs.net/datasets/kitti/backups/2013_10_30_19_47_30_stereo.html" target="blank">stereo</a> and <a href="https://www.cvlibs.net/datasets/kitti/backups/2013_10_30_19_47_30_flow.html" target="blank">flow</a>!
</p>

<div class="alertbox_600"><b>Important Policy Update:</b> As more and more non-published work and re-implementations of existing work is submitted to KITTI, we have established a new policy: from now on, only submissions with significant novelty that are leading to a peer-reviewed paper in a conference or journal are allowed. Minor modifications of existing algorithms or student research projects are not allowed. Such work must be evaluated on a split of the training set. To ensure that our policy is adopted, new users must detail their status, describe their work and specify the targeted venue during registration. Furthermore, we will regularly delete all entries that are 6 months old but are still anonymous or do not have a paper associated with them. For conferences, 6 month is enough to determine if a paper has been accepted and to add the bibliography information. For longer review cycles, you need to resubmit your results.</div><div class="alertbox_600"><b><u><center>Additional information used by the methods</center></u></b><ul><li><img src="./KITTI2012Reflective_files/icon_fl.png"> Flow: Method uses optical flow (2 temporally adjacent images)</li><li><img src="./KITTI2012Reflective_files/icon_mv.png"> Multiview: Method uses more than 2 temporally adjacent images</li><li><img src="./KITTI2012Reflective_files/icon_ms.png"> Motion stereo: Method uses epipolar geometry for computing optical flow</li><li><img src="./KITTI2012Reflective_files/icon_at.png"> Additional training data: Use of additional data sources for training (see details)</li></ul></div>
<!--
<br>
<a href="http://www.robustvision.net"><center>
<img src="http://www.robustvision.net/images/banner.png" /></center></a>
-->

<br>

<form method="get" name="form_options" action="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php">
<input type="hidden" name="benchmark" value="stereo">
<b>Table</b>
<select name="table" onchange="document.forms[&#39;form_options&#39;].submit()"> 
<option value="all">All</option><option value="refl" selected="">Reflective</option></select>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<b>Error threshold</b>
<select name="error" onchange="document.forms[&#39;form_options&#39;].submit()"> 
<option value="2">2 pixels</option><option value="3">3 pixels</option><option value="4" selected="">4 pixels</option><option value="5">5 pixels</option></select>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<b>Evaluation area</b>
<select name="eval" onchange="document.forms[&#39;form_options&#39;].submit()"> 
<option value="all" selected="">All pixels </option><option value="est">Estimated pixels </option></select> 
</form>
<br>



<form method="post" action="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all"><table class="results">
  <tbody><tr class="heading">
    <td class="results"></td>
     <td class="results">Method</td>
     <td class="results">Setting</td>
     <td class="results">Code</td>
     <td class="results"><span style="color:red"><u>Out-Noc</u></span></td>
     <td class="results">Out-All</td>
     <td class="results">Avg-Noc</td>
     <td class="results">Avg-All</td>
     <td class="results">Runtime</td>
     <td class="results">Environment</td>
     <td class="results"><input type="submit" value="Compare" name="compare"></td>
   </tr>
   <tr>
    <td class="results">1</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=d70f35235c979e53d05cb9a2d161ca80e51b612e">MoCha-Stereo</a></td>
     <td class="results"></td>
     <td class="results"><b></b></td>
     <td class="results"><b> 2.62 %</b></td>
     <td class="results"><b> 3.08 %</b></td>
     <td class="results"><b>  0.8 px</b></td>
     <td class="results">  0.9 px</td>
     <td class="results">0.41 s</td>
     <td class="results">NVIDIA Tesla A6000 (PyTorch)</td>
     <td class="results"><input type="checkbox" value="d70f35235c979e53d05cb9a2d161ca80e51b612e" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">2</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=bed182333eb0299301947ef66bf6c4762458bf53">IGEV-LFMS</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 2.85 %</td>
     <td class="results"> 3.53 %</td>
     <td class="results">  0.9 px</td>
     <td class="results">  1.0 px</td>
     <td class="results">0.18 s</td>
     <td class="results">GPU @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="bed182333eb0299301947ef66bf6c4762458bf53" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">3</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=ca0e70512d9d9c435d5eb3f6ae3ffebfede95b8c">RiskMin</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 2.87 %</td>
     <td class="results"> 3.74 %</td>
     <td class="results">  0.9 px</td>
     <td class="results">  1.1 px</td>
     <td class="results">0.20 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="ca0e70512d9d9c435d5eb3f6ae3ffebfede95b8c" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">4</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=555c2a8ee5eea96fbc67dc61bc63d054c2e13eb0">IGE_Corr</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 2.92 %</td>
     <td class="results"> 3.59 %</td>
     <td class="results">  0.9 px</td>
     <td class="results">  1.0 px</td>
     <td class="results">0.2 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="555c2a8ee5eea96fbc67dc61bc63d054c2e13eb0" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">5</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=0f4106ec9d37381f2feef283cfd586865c6db4f3">IGEV-Stereo(32)</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/gangweiX/IGEV" target="blank">code</a></td>
     <td class="results"> 2.92 %</td>
     <td class="results"> 3.35 %</td>
     <td class="results">  0.9 px</td>
     <td class="results">  1.0 px</td>
     <td class="results">0.32 s</td>
     <td class="results">NVIDIA RTX 3090 (PyTorch)</td>
     <td class="results"><input type="checkbox" value="0f4106ec9d37381f2feef283cfd586865c6db4f3" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">G. Xu, X. Wang, X. Ding and X. Yang: <a href="http://scholar.google.de/scholar?q=Iterative%20Geometry%20Encoding%20Volume%20for%20Stereo%20Matching"> Iterative Geometry Encoding Volume for 
Stereo Matching</a>. CVPR 2023.<br></td>
   </tr>
   <tr>
    <td class="results">6</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=2a991b30ef75e122324a7423831c44c6fb0cd411">SG-Stereo</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 2.97 %</td>
     <td class="results"> 3.80 %</td>
     <td class="results">  1.1 px</td>
     <td class="results">  1.2 px</td>
     <td class="results">0.6 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="2a991b30ef75e122324a7423831c44c6fb0cd411" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">7</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=51db7e3bea4c5a1067f7fdf2f5f57167fec41eba">Any-IGEV</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 3.03 %</td>
     <td class="results"> 3.39 %</td>
     <td class="results">  1.0 px</td>
     <td class="results">  1.1 px</td>
     <td class="results">0.32 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="51db7e3bea4c5a1067f7fdf2f5f57167fec41eba" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">8</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=e5264ea69e28600f5fa5bce570b3e241114a34dd">MC-Stereo</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 3.06 %</td>
     <td class="results"> 3.93 %</td>
     <td class="results">  1.0 px</td>
     <td class="results">  1.1 px</td>
     <td class="results">0.40 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="e5264ea69e28600f5fa5bce570b3e241114a34dd" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">9</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=3d8d219c0300e5d4129cbcbfddd71f812a86e0e8">IGEV-Stereo</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 3.16 %</td>
     <td class="results"> 3.57 %</td>
     <td class="results">  1.0 px</td>
     <td class="results">  1.1 px</td>
     <td class="results">0.18 s</td>
     <td class="results">NVIDIA RTX 3090 (PyTorch)</td>
     <td class="results"><input type="checkbox" value="3d8d219c0300e5d4129cbcbfddd71f812a86e0e8" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">G. Xu, X. Wang, X. Ding and X. Yang: <a href="http://scholar.google.de/scholar?q=Iterative%20Geometry%20Encoding%20Volume%20for%20Stereo%20Matching"> Iterative Geometry Encoding Volume for 
Stereo Matching</a>. CVPR 2023.<br></td>
   </tr>
   <tr>
    <td class="results">10</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=b5876c81c7631e9f4a40beb1eb98f0c28d8de73d">EGA-Stereo</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/yuankang1234/EGA-Stereo" target="blank">code</a></td>
     <td class="results"> 3.18 %</td>
     <td class="results"> 4.20 %</td>
     <td class="results">  1.0 px</td>
     <td class="results">  1.1 px</td>
     <td class="results">0.41 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="b5876c81c7631e9f4a40beb1eb98f0c28d8de73d" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">11</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=a7a5ba9dc0621d403e23622ee32047d6c9e7a991">DN + GANet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 3.36 %</td>
     <td class="results"> 4.63 %</td>
     <td class="results">  1.0 px</td>
     <td class="results">  1.2 px</td>
     <td class="results">1.8 s</td>
     <td class="results">GPU @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="a7a5ba9dc0621d403e23622ee32047d6c9e7a991" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">12</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=c4098c8ffd33407d235943da333cdcc13879fb1e">DiffuVolume</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 3.38 %</td>
     <td class="results"> 4.19 %</td>
     <td class="results">  1.0 px</td>
     <td class="results">  1.2 px</td>
     <td class="results">0.36 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="c4098c8ffd33407d235943da333cdcc13879fb1e" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">13</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=efa81865cbf57c745e1b43aee132fb2a71b7750b">PCWNet</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/gallenszl/PCW-Net" target="blank">code</a></td>
     <td class="results"> 3.38 %</td>
     <td class="results"> 4.19 %</td>
     <td class="results">  1.0 px</td>
     <td class="results">  1.2 px</td>
     <td class="results">0.44 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="efa81865cbf57c745e1b43aee132fb2a71b7750b" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Z. Shen, Y. Dai, X. Song, Z. Rao, D. Zhou and L. Zhang: <a href="http://scholar.google.de/scholar?q=PCW-Net:%20Pyramid%20Combination%20and%20Warping%20Cost%20Volume%20for%20Stereo%20Matching"> PCW-Net: Pyramid Combination and Warping 
Cost Volume for Stereo Matching</a>. European Conference on Computer 
Vision(ECCV) 2022.<br></td>
   </tr>
   <tr>
    <td class="results">14</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=291879cd4bc5b6bcf57a3cbcbcff4e9587b01d30">SplitNet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 3.40 %</td>
     <td class="results"> 4.15 %</td>
     <td class="results">  1.1 px</td>
     <td class="results">  1.2 px</td>
     <td class="results">0.07 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="291879cd4bc5b6bcf57a3cbcbcff4e9587b01d30" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">15</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=c873d14d14c51a65023f5b0181b358fa4ac25c4c">GANet+ADL</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 3.43 %</td>
     <td class="results"> 4.39 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.67 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="c873d14d14c51a65023f5b0181b358fa4ac25c4c" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">16</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=8100602ea89b691b2589189924cb587fea7d538f">RCGSNP</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 3.45 %</td>
     <td class="results"> 4.30 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.3 px</td>
     <td class="results">0.12 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="8100602ea89b691b2589189924cb587fea7d538f" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">17</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=35d3c0c4a327c53b90f02ab5a373f6c021d53a65">CGF-ACV</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/gangweiX/CGI-Stereo" target="blank">code</a></td>
     <td class="results"> 3.45 %</td>
     <td class="results"> 4.40 %</td>
     <td class="results">  1.0 px</td>
     <td class="results">  1.1 px</td>
     <td class="results">0.24 s</td>
     <td class="results">NVIDIA RTX 3090 (PyTorch)</td>
     <td class="results"><input type="checkbox" value="35d3c0c4a327c53b90f02ab5a373f6c021d53a65" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">18</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=545722d6e426e447e2f162ac46022cad6309e168">UGNet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 3.47 %</td>
     <td class="results"> 4.62 %</td>
     <td class="results">  1.1 px</td>
     <td class="results">  1.3 px</td>
     <td class="results">0.3 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="545722d6e426e447e2f162ac46022cad6309e168" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">19</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=0055dd8df26afaf4212cd771a7fcc5d297578115">PCMAnet</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/Anonymous" target="blank">code</a></td>
     <td class="results"> 3.48 %</td>
     <td class="results"> 4.92 %</td>
     <td class="results">  1.1 px</td>
     <td class="results">  1.2 px</td>
     <td class="results">0.27 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="0055dd8df26afaf4212cd771a7fcc5d297578115" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">20</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=a94bf9ff745ede2188ef55a204fe41c1d9ec9ae9">HD^3-Stereo</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/ucbdrive/hd3" target="blank">code</a></td>
     <td class="results"> 3.49 %</td>
     <td class="results"> 4.88 %</td>
     <td class="results">  1.0 px</td>
     <td class="results">  1.1 px</td>
     <td class="results">0.14 s</td>
     <td class="results">NVIDIA Pascal Titan XP</td>
     <td class="results"><input type="checkbox" value="a94bf9ff745ede2188ef55a204fe41c1d9ec9ae9" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Z. Yin, T. Darrell and F. Yu: <a href="http://scholar.google.de/scholar?q=Hierarchical%20Discrete%20Distribution%20Decomposition%20for%20Match%20Density%20Estimation"> Hierarchical Discrete Distribution Decomposition 
for Match Density Estimation</a>. CVPR 2019.<br></td>
   </tr>
   <tr>
    <td class="results">21</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=4466f882bfc1e9e7072f75b588158a605d239f22">SSMF</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 3.50 %</td>
     <td class="results"> 4.31 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.20 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="4466f882bfc1e9e7072f75b588158a605d239f22" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">22</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=3e943792d8f60b79d740d9b5643f201f42cf1b48">OnestageStereo</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 3.53 %</td>
     <td class="results"> 4.64 %</td>
     <td class="results">  1.1 px</td>
     <td class="results">  1.2 px</td>
     <td class="results">1 s</td>
     <td class="results">GPU @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="3e943792d8f60b79d740d9b5643f201f42cf1b48" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">23</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=aaece0927af830eaa2da73304570e50df66e1921">LEAStereo</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/XuelianCheng/LEAStereo" target="blank">code</a></td>
     <td class="results"> 3.56 %</td>
     <td class="results"> 4.32 %</td>
     <td class="results">  1.1 px</td>
     <td class="results">  1.2 px</td>
     <td class="results">0.3 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="aaece0927af830eaa2da73304570e50df66e1921" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">X. Cheng, Y. Zhong, M. Harandi, Y. Dai, X. Chang, H. Li, T. Drummond and Z. Ge: <a href="http://scholar.google.de/scholar?q=Hierarchical%20Neural%20Architecture%20Search%20for%20Deep%20Stereo%20Matching"> Hierarchical Neural Architecture Search 
for Deep Stereo Matching</a>. Advances in Neural Information 
Processing Systems 2020.<br></td>
   </tr>
   <tr>
    <td class="results">24</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=8b32473fdbf954b3457802eac62786d9081f7f6d">GEMAStereo</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 3.63 %</td>
     <td class="results"> 4.66 %</td>
     <td class="results">  1.1 px</td>
     <td class="results">  1.2 px</td>
     <td class="results">0.03 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="8b32473fdbf954b3457802eac62786d9081f7f6d" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">25</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=309587ff6db4acf8bfa6cc16e11c1f9f89663ae1">FGDS-Net</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 3.63 %</td>
     <td class="results"> 4.72 %</td>
     <td class="results">  1.1 px</td>
     <td class="results">  1.2 px</td>
     <td class="results">0.3 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="309587ff6db4acf8bfa6cc16e11c1f9f89663ae1" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">26</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=34a87ece6055edb40bfa7f7b2b01d343e9296821">Any-RAFT</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 3.65 %</td>
     <td class="results"> 4.27 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.2 px</td>
     <td class="results">0.32 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="34a87ece6055edb40bfa7f7b2b01d343e9296821" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">27</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=edaf203894c89cfcfd2b122f2cbf450e679037d4">LSE+CFNet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 3.66 %</td>
     <td class="results"> 4.84 %</td>
     <td class="results">  1.1 px</td>
     <td class="results">  1.2 px</td>
     <td class="results">0.30 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="edaf203894c89cfcfd2b122f2cbf450e679037d4" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">28</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=b3bea984be9a41085e232b565c4994c6f4e4b02d">NeXt-Stereo</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 3.69 %</td>
     <td class="results"> 4.31 %</td>
     <td class="results">  1.1 px</td>
     <td class="results">  1.2 px</td>
     <td class="results">0.06 s</td>
     <td class="results">GPU @ 2.0 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="b3bea984be9a41085e232b565c4994c6f4e4b02d" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">29</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=438a11c6821e1b3ea76c46b3be40182484e086a3">BSDual-CNN</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 3.75 %</td>
     <td class="results"> 4.47 %</td>
     <td class="results">  1.0 px</td>
     <td class="results">  1.1 px</td>
     <td class="results">0.45 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="438a11c6821e1b3ea76c46b3be40182484e086a3" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">30</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=a6b7858dc8dfeb4cee17178e1c82f6e8f041f6c3">EdgeStereo-V2</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 3.78 %</td>
     <td class="results"> 5.06 %</td>
     <td class="results">  1.0 px</td>
     <td class="results">  1.2 px</td>
     <td class="results">0.32 s</td>
     <td class="results">Nvidia GTX Titan Xp</td>
     <td class="results"><input type="checkbox" value="a6b7858dc8dfeb4cee17178e1c82f6e8f041f6c3" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">X. Song, X. Zhao, L. Fang, H. Hu and Y. Yu: <a href="http://scholar.google.de/scholar?q=Edgestereo:%20An%20effective%20multi-task%20learning%20network%20for%20stereo%20matching%20and%20edge%20detection"> Edgestereo: An effective multi-task 
learning network for stereo matching and edge 
detection</a>. International Journal of Computer 
Vision (IJCV) 2019.<br></td>
   </tr>
   <tr>
    <td class="results">31</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=7142036666146e2512cdfe4182b5631ce2a9e8c6">AutoDispNet-CSS</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/lmb-freiburg/autodispnet" target="blank">code</a></td>
     <td class="results"> 3.78 %</td>
     <td class="results"> 4.47 %</td>
     <td class="results">  1.0 px</td>
     <td class="results">  1.1 px</td>
     <td class="results">0.9 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="7142036666146e2512cdfe4182b5631ce2a9e8c6" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">T. Saikia, Y. Marrakchi, A. Zela, F. Hutter and T. Brox: <a href="http://scholar.google.de/scholar?q=AutoDispNet:%20Improving%20Disparity%20Estimation%20with%20AutoML"> AutoDispNet: Improving Disparity 
Estimation with AutoML</a>. The IEEE International 
Conference on Computer Vision (ICCV) 2019.<br></td>
   </tr>
   <tr>
    <td class="results">32</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=5b13b32360a7cdf158a78b76ab2161756042bb1b">ADStereo</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 3.78 %</td>
     <td class="results"> 4.91 %</td>
     <td class="results">  1.1 px</td>
     <td class="results">  1.2 px</td>
     <td class="results">0.05 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="5b13b32360a7cdf158a78b76ab2161756042bb1b" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">33</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=fa3ca79db3be983658690e08745a66bc8525ba9e">PSMNet+CBAM</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 3.92 %</td>
     <td class="results"> 5.29 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.3 px</td>
     <td class="results">0.36 s</td>
     <td class="results">NVIDIA RTX 3090 (Python)</td>
     <td class="results"><input type="checkbox" value="fa3ca79db3be983658690e08745a66bc8525ba9e" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">34</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=f0b006b79d2d62f26ee03d29348fc1a39a050864">ICVP</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/ohkwon718/icvp" target="blank">code</a></td>
     <td class="results"> 3.94 %</td>
     <td class="results"> 4.74 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.2 px</td>
     <td class="results">0.17 s</td>
     <td class="results">GPU @ 1.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="f0b006b79d2d62f26ee03d29348fc1a39a050864" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">O. Kwon and E. Zell: <a href="http://scholar.google.de/scholar?q=Image-Coupled%20Volume%20Propagation%20for%20Stereo%20Matching"> Image-Coupled Volume Propagation for 
Stereo Matching</a>. 2023 IEEE International Conference on 
Image Processing (ICIP) 2023.<br></td>
   </tr>
   <tr>
    <td class="results">35</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=d0e9d3a2722998a259cbf5a9d96ccad48e20ff0e">MAF-Stereo</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/LeiJ-USTB/MAF-Stereo/tree/main" target="blank">code</a></td>
     <td class="results"> 3.99 %</td>
     <td class="results"> 5.20 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.07 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="d0e9d3a2722998a259cbf5a9d96ccad48e20ff0e" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">36</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=7f75bed8dcc0b887d33ea6cee0c07442f171886c">Cs-Net</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.04 %</td>
     <td class="results"> 5.47 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.3 px</td>
     <td class="results">0.6 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="7f75bed8dcc0b887d33ea6cee0c07442f171886c" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">37</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=6a4165ff454a08f58a12c1e9a80551b95711e3f8">HITNet</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://arxiv.org/abs/2007.12140" target="blank">code</a></td>
     <td class="results"> 4.04 %</td>
     <td class="results"> 5.34 %</td>
     <td class="results">  1.0 px</td>
     <td class="results">  1.2 px</td>
     <td class="results">0.02 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python + C/C++)</td>
     <td class="results"><input type="checkbox" value="6a4165ff454a08f58a12c1e9a80551b95711e3f8" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">V. Tankovich, C. Häne, Y. Zhang, A. Kowdle, S. Fanello and S. Bouaziz: <a href="http://scholar.google.de/scholar?q=HITNet:%20Hierarchical%20Iterative%20Tile%20Refinement%20Network%20for%20Real-time%20Stereo%20Matching"> HITNet: Hierarchical Iterative Tile 
Refinement Network for Real-time Stereo 
Matching</a>. CVPR 2021.<br></td>
   </tr>
   <tr>
    <td class="results">38</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=deec320942951830de20df3418ad1908ef0fffab">taugr1215</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.05 %</td>
     <td class="results"> 5.30 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.3 px</td>
     <td class="results">0.35 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="deec320942951830de20df3418ad1908ef0fffab" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">39</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=69b001fa280be3416b48c5f17e04deb6ac7eb46d">PDSNet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.05 %</td>
     <td class="results"> 5.87 %</td>
     <td class="results">  1.4 px</td>
     <td class="results">  1.6 px</td>
     <td class="results">0.5 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python + C/C++)</td>
     <td class="results"><input type="checkbox" value="69b001fa280be3416b48c5f17e04deb6ac7eb46d" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">S. Tulyakov, A. Ivanov and F. Fleuret: <a href="http://scholar.google.de/scholar?q=Practical%20Deep%20Stereo%20(PDS):%20Toward%20applications-friendly%20deep%20stereo%20matching"> Practical Deep Stereo (PDS): Toward 
applications-friendly deep stereo matching</a>. Proceedings of the international conference 
on Neural Information Processing Systems (NIPS) 2018.<br></td>
   </tr>
   <tr>
    <td class="results">40</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=763bd4ec0ec04bdb3421874025fd8a7604780b74">NLCA-Net v2</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/Archaic-Atom/NLCA-Net_v2" target="blank">code</a></td>
     <td class="results"> 4.06 %</td>
     <td class="results"> 5.19 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.3 px</td>
     <td class="results">0.67 s</td>
     <td class="results">GPU @ &gt;3.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="763bd4ec0ec04bdb3421874025fd8a7604780b74" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Z. Rao, D. Yuchao, S. Zhelun and H. Renjie: <a href="http://scholar.google.de/scholar?q=Rethinking%20Training%20Strategy%20in%20Stereo%20Matching"> Rethinking Training Strategy in 
Stereo Matching</a>. IEEE TRANSACTIONS ON NEURAL 
NETWORKS AND LEARNING SYSTEMS .<br></td>
   </tr>
   <tr>
    <td class="results">41</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=8c74b328c1096f6059474b4eb0c159dc53ec30f2">PFSMNet</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/N.A" target="blank">code</a></td>
     <td class="results"> 4.14 %</td>
     <td class="results"> 5.27 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.3 px</td>
     <td class="results">0.31 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="8c74b328c1096f6059474b4eb0c159dc53ec30f2" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">K. Zeng, Y. Wang, Q. Zhu, J. Mao and H. Zhang: <a href="http://scholar.google.de/scholar?q=Deep%20Progressive%20Fusion%20Stereo%20Network"> Deep Progressive Fusion Stereo Network</a>. IEEE Transactions on Intelligent 
Transportation Systems 2021.<br></td>
   </tr>
   <tr>
    <td class="results">42</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=38bd0b459d408176890889a635e48b79331912bd">UCFNet</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/gallenszl/UCFNet" target="blank">code</a></td>
     <td class="results"> 4.15 %</td>
     <td class="results"> 4.99 %</td>
     <td class="results">  1.1 px</td>
     <td class="results">  1.2 px</td>
     <td class="results">0.21 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="38bd0b459d408176890889a635e48b79331912bd" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Z. Shen, X. Song, Y. Dai, D. Zhou, Z. Rao and L. Zhang: <a href="http://scholar.google.de/scholar?q=Digging%20Into%20Uncertainty-Based%20Pseudo-Label%20for%20Robust%20Stereo%20Matching"> Digging Into Uncertainty-Based Pseudo-
Label for Robust Stereo Matching</a>. IEEE Transactions on Pattern Analysis 
and Machine Intelligence 2023.<br></td>
   </tr>
   <tr>
    <td class="results">43</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=38ab8d5d0df1c6736dbadd8171bacffedebea311">LaC+GANet</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/SpadeLiu/Lac-GwcNet" target="blank">code</a></td>
     <td class="results"> 4.15 %</td>
     <td class="results"> 5.18 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.5 px</td>
     <td class="results">1.8 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="38ab8d5d0df1c6736dbadd8171bacffedebea311" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">B. Liu, H. Yu and Y. Long: <a href="http://scholar.google.de/scholar?q=Local%20Similarity%20Pattern%20and%20Cost%20Self-Reassembling%20for%20Deep%20Stereo%20Matching%20Networks"> Local Similarity Pattern and Cost Self-
Reassembling for Deep Stereo Matching Networks</a>. Proceedings of the AAAI Conference on 
Artificial Intelligence 2022.<br></td>
   </tr>
   <tr>
    <td class="results">44</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=646fc3c0f61183aa4b1c6855bf08f1baf21a5006">URDAD</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.18 %</td>
     <td class="results"> 5.30 %</td>
     <td class="results">  1.5 px</td>
     <td class="results">  1.6 px</td>
     <td class="results">0.35 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="646fc3c0f61183aa4b1c6855bf08f1baf21a5006" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">45</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=0b15ef871151d50e3798616cc1b18dc7b57ed33c">ADPNet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.20 %</td>
     <td class="results"> 5.55 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.5 px</td>
     <td class="results">0.06 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="0b15ef871151d50e3798616cc1b18dc7b57ed33c" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">46</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=30d8ee671ab63793dc72846b50117b30932194ad">SegStereo</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/yangguorun/SegStereo" target="blank">code</a></td>
     <td class="results"> 4.22 %</td>
     <td class="results"> 5.52 %</td>
     <td class="results">  1.1 px</td>
     <td class="results">  1.3 px</td>
     <td class="results">0.6 s</td>
     <td class="results">Nvidia GTX Titan Xp</td>
     <td class="results"><input type="checkbox" value="30d8ee671ab63793dc72846b50117b30932194ad" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">G. Yang, H. Zhao, J. Shi, Z. Deng and J. Jia: <a href="http://scholar.google.de/scholar?q=SegStereo:%20Exploiting%20Semantic%20Information%20for%20Disparity%20Estimation"> SegStereo: Exploiting Semantic 
Information for Disparity Estimation</a>. ECCV 2018.<br></td>
   </tr>
   <tr>
    <td class="results">47</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=5815652db2e1d52e5e677731cc033978751aaf29">RAFT-Stereo</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/princeton-vl/RAFT-Stereo" target="blank">code</a></td>
     <td class="results"> 4.24 %</td>
     <td class="results"> 5.08 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.3 px</td>
     <td class="results">0.38 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="5815652db2e1d52e5e677731cc033978751aaf29" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">48</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=6c97eae4bcc14cc0d6d45c888291870ee8c0b8c3">CFNet</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/gallenszl/CFNet" target="blank">code</a></td>
     <td class="results"> 4.24 %</td>
     <td class="results"> 5.05 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.3 px</td>
     <td class="results">0.18 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="6c97eae4bcc14cc0d6d45c888291870ee8c0b8c3" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Z. Shen, Y. Dai and Z. Rao: <a href="http://scholar.google.de/scholar?q=CFNet:%20Cascade%20and%20Fused%20Cost%20Volume%20for%20Robust%20Stereo%20Matching"> CFNet: Cascade and Fused Cost Volume for 
Robust Stereo Matching</a>. IEEE Conference on Computer Vision 
and 
Pattern Recognition (CVPR) 2021.<br>Z. Shen, X. Song, Y. Dai, D. Zhou, Z. Rao and L. Zhang: <a href="http://scholar.google.de/scholar?q=Digging%20Into%20Uncertainty-Based%20Pseudo-Label%20for%20Robust%20Stereo%20Matching"> Digging Into Uncertainty-Based Pseudo-
Label for Robust Stereo Matching</a>. IEEE Transactions on Pattern Analysis 
and Machine Intelligence 2023.<br></td>
   </tr>
   <tr>
    <td class="results">49</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=a65b6b3b537f011a41fd14191ce87917cf029064">High_U+A_coex</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.26 %</td>
     <td class="results"> 5.47 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.35 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="a65b6b3b537f011a41fd14191ce87917cf029064" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">ERROR: Wrong syntax in BIBTEX file.<br></td>
   </tr>
   <tr>
    <td class="results">50</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=9e57f91f6b254b5fe955b72981519f7c1653e344">taugr12</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.26 %</td>
     <td class="results"> 5.56 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.3 px</td>
     <td class="results">0.35 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="9e57f91f6b254b5fe955b72981519f7c1653e344" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">51</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=aab94bf5d3e9c17fcd80b70bf8ac7c632d759413">BGNet+</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.26 %</td>
     <td class="results"> 5.80 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.02 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="aab94bf5d3e9c17fcd80b70bf8ac7c632d759413" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">B. Xu, Y. Xu, X. Yang, W. Jia and Y. Guo: <a href="http://scholar.google.de/scholar?q=Bilateral%20Grid%20Learning%20for%20Stereo%20Matching%20Network"> Bilateral Grid Learning for Stereo Matching 
Network</a>. Proceedings of the IEEE/CVF Conference on 
Computer Vision and Pattern Recognition (CVPR) 2021.<br></td>
   </tr>
   <tr>
    <td class="results">52</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=4edfe932a9a8dff36a32b4b43b5a3671fefe0f05">SCVFormer</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.27 %</td>
     <td class="results"> 5.42 %</td>
     <td class="results">  1.4 px</td>
     <td class="results">  1.6 px</td>
     <td class="results">0.09 s</td>
     <td class="results">NVIDIA RTX 3090 (PyTorch)</td>
     <td class="results"><input type="checkbox" value="4edfe932a9a8dff36a32b4b43b5a3671fefe0f05" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">53</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=5de2104a4d51ca74d50cfe23869777038d6c5a14">yjlgreen</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.28 %</td>
     <td class="results"> 5.65 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.35 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="5de2104a4d51ca74d50cfe23869777038d6c5a14" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">54</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=95af4a21253204c14e9dc7ab8beb9d9b114cfb9d">GANet-deep</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/feihuzhang/GANet" target="blank">code</a></td>
     <td class="results"> 4.32 %</td>
     <td class="results"> 5.66 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.3 px</td>
     <td class="results">1.8 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="95af4a21253204c14e9dc7ab8beb9d9b114cfb9d" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">F. Zhang, V. Prisacariu, R. Yang and P. Torr: <a href="http://scholar.google.de/scholar?q=GA-Net:%20Guided%20Aggregation%20Net%20for%20End-to-end%20Stereo%20Matching"> GA-Net: Guided Aggregation Net for 
End-to-end Stereo Matching</a>. Proceedings of the IEEE Conference 
on Computer Vision and Pattern Recognition 
(CVPR) 2019.<br></td>
   </tr>
   <tr>
    <td class="results">55</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=2a3a494515adc0ee987461d611dc400a783477da">TBFE-Net</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.34 %</td>
     <td class="results"> 5.50 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.3 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="2a3a494515adc0ee987461d611dc400a783477da" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">56</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=5399eeaecc5801f137b83877687952c38fc6e26f">ProNet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.35 %</td>
     <td class="results"> 5.56 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.33 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="5399eeaecc5801f137b83877687952c38fc6e26f" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">57</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=bc6dc74c24153caa683b2cb135c11a566537956e">ERSCNet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.35 %</td>
     <td class="results"> 6.20 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.28 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="bc6dc74c24153caa683b2cb135c11a566537956e" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Anonymous: <a href="http://scholar.google.de/scholar?q=ERSCNet"> ERSCNet</a>. Proceedings of the European 
Conference on Computer Vision (ECCV) 2020.<br></td>
   </tr>
   <tr>
    <td class="results">58</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=7a015d226dbe3f538f775ee0ae63a277fcb87fb1">DMCNet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.38 %</td>
     <td class="results"> 5.83 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.27 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="7a015d226dbe3f538f775ee0ae63a277fcb87fb1" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">59</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=f358425ae985577b0b393cb30a9036dcd22b3672">AMNet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.44 %</td>
     <td class="results"> 5.62 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.3 px</td>
     <td class="results">0.9 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="f358425ae985577b0b393cb30a9036dcd22b3672" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">X. Du, M. El-Khamy and J. Lee: <a href="http://scholar.google.de/scholar?q=AMNet:%20Deep%20Atrous%20Multiscale%20Stereo%20Disparity%20Estimation%20Networks"> AMNet: Deep Atrous Multiscale Stereo 
Disparity Estimation Networks</a>. 2019.<br></td>
   </tr>
   <tr>
    <td class="results">60</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=81a8c2f9f03884ff5851ce2f547464adb0aefd6d">HCRNet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.46 %</td>
     <td class="results"> 5.68 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.3 px</td>
     <td class="results">0.19 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="81a8c2f9f03884ff5851ce2f547464adb0aefd6d" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">61</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=16b58b9d18b7882071689c0ebc17ff137f0832a7">DPCTF-S</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.47 %</td>
     <td class="results"> 5.70 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.11 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="16b58b9d18b7882071689c0ebc17ff137f0832a7" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Y. Deng, J. Xiao, S. Zhou and J. Feng: <a href="http://scholar.google.de/scholar?q=Detail%20Preserving%20Coarse-to-Fine%20Matching%20for%20Stereo%20Matching%20and%20Optical%20Flow"> Detail Preserving Coarse-to-Fine Matching 
for Stereo Matching and Optical Flow</a>. IEEE Transactions on Image Processing 2021.<br></td>
   </tr>
   <tr>
    <td class="results">62</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=5afa037f868955a4a2576038ce4b380ead583257">pcanet</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/Anonymous" target="blank">code</a></td>
     <td class="results"> 4.48 %</td>
     <td class="results"> 6.08 %</td>
     <td class="results">  1.4 px</td>
     <td class="results">  1.6 px</td>
     <td class="results">0.27 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="5afa037f868955a4a2576038ce4b380ead583257" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">63</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=fc22a6c71f5bf5c5e185c0d212f8e72b6307d81e">GRNet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.51 %</td>
     <td class="results"> 5.60 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.3 px</td>
     <td class="results">0.19 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="fc22a6c71f5bf5c5e185c0d212f8e72b6307d81e" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">64</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=c1cbc65b799cac5429f3285bb9090b4d50927c21">LaC+GwcNet</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/SpadeLiu/Lac-GwcNet" target="blank">code</a></td>
     <td class="results"> 4.55 %</td>
     <td class="results"> 5.89 %</td>
     <td class="results">  1.5 px</td>
     <td class="results">  1.7 px</td>
     <td class="results">0.65 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="c1cbc65b799cac5429f3285bb9090b4d50927c21" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">B. Liu, H. Yu and Y. Long: <a href="http://scholar.google.de/scholar?q=Local%20Similarity%20Pattern%20and%20Cost%20Self-Reassembling%20for%20Deep%20Stereo%20Matching%20Networks"> Local Similarity Pattern and Cost Self-
Reassembling for Deep Stereo Matching Networks</a>. Proceedings of the AAAI Conference on 
Artificial Intelligence 2022.<br></td>
   </tr>
   <tr>
    <td class="results">65</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=fe7f11585da4b1735ea301455cfa3439b0bcf482">SCV-Stereo</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://sites.google.com/view/scv-stereo" target="blank">code</a></td>
     <td class="results"> 4.57 %</td>
     <td class="results"> 5.96 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.08 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="fe7f11585da4b1735ea301455cfa3439b0bcf482" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">H. Wang, R. Fan and M. Liu: <a href="http://scholar.google.de/scholar?q=SCV-Stereo:%20Learning%20stereo%20matching%20from%20a%20sparse%20cost%20volume"> SCV-Stereo: Learning stereo 
matching from a sparse cost volume</a>. 2021 IEEE International Conference 
on Image Processing (ICIP) 2021.<br></td>
   </tr>
   <tr>
    <td class="results">66</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=4aa3f9273cb0bb792b959f9d85e41758d5e7a369">OptStereo</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.58 %</td>
     <td class="results"> 5.87 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.10 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="4aa3f9273cb0bb792b959f9d85e41758d5e7a369" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">H. Wang, R. Fan, P. Cai and M. Liu: <a href="http://scholar.google.de/scholar?q=PVStereo:%20Pyramid%20voting%20module%20for%20end-to-end%20self-supervised%20stereo%20matching"> PVStereo: Pyramid voting module for 
end-to-end self-supervised stereo matching</a>. IEEE Robotics and Automation Letters 2021.<br></td>
   </tr>
   <tr>
    <td class="results">67</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=307269ce47b172353171d42e12f18e9edf41aaaf">CoEx</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/antabangun/coex" target="blank">code</a></td>
     <td class="results"> 4.61 %</td>
     <td class="results"> 6.00 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.027 s</td>
     <td class="results">RTX 2080Ti (Python)</td>
     <td class="results"><input type="checkbox" value="307269ce47b172353171d42e12f18e9edf41aaaf" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">A. Bangunharcana, J. Cho, S. Lee, I. Kweon, K. Kim and S. Kim: <a href="http://scholar.google.de/scholar?q=Correlate-and-Excite:%20Real-Time%20Stereo%20Matching%20via%20Guided%20Cost%20Volume%20Excitation"> Correlate-and-Excite: Real-Time Stereo Matching via Guided Cost Volume Excitation</a>. 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2021.<br></td>
   </tr>
   <tr>
    <td class="results">68</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=4ff42a3a35162b326bc70358a87becb53faebd6f">NLCA-Net-3</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/NPU-IAP/NLCA-Net" target="blank">code</a></td>
     <td class="results"> 4.63 %</td>
     <td class="results"> 5.57 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.44 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="4ff42a3a35162b326bc70358a87becb53faebd6f" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Z. Rao, M. He, Y. Dai, Z. Zhu, B. Li and R. He: <a href="http://scholar.google.de/scholar?q=NLCA-Net:%20a%20non-local%20context%20attention%20network%20for%20stereo%20matching"> NLCA-Net: a non-local context attention 
network for stereo matching</a>. APSIPA Transactions on Signal and 
Information Processing 2020.<br></td>
   </tr>
   <tr>
    <td class="results">69</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=70f1d55de5bf51fe4a0c542ccd6e6af328af7836">CAL-Net</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.66 %</td>
     <td class="results"> 5.96 %</td>
     <td class="results">  1.5 px</td>
     <td class="results">  1.7 px</td>
     <td class="results">0.44 s</td>
     <td class="results">4 cores @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="70f1d55de5bf51fe4a0c542ccd6e6af328af7836" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">S. Chen, B. Li, W. Wang, H. Zhang, H. Li and Z. Wang: <a href="http://scholar.google.de/scholar?q=Cost%20Affinity%20Learning%20Network%20for%20Stereo%20Matching"> Cost Affinity Learning Network for 
Stereo Matching</a>. IEEE International Conference on 
Acoustics, Speech and Signal Processing,
               ICASSP 2021, Toronto, ON, Canada, 
June 6-11, 2021 2021.<br></td>
   </tr>
   <tr>
    <td class="results">70</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=3bbf3064b706ba3cf91f01e1689da1d7a748d7cc">High_U+A_coex</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.68 %</td>
     <td class="results"> 5.61 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.35 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="3bbf3064b706ba3cf91f01e1689da1d7a748d7cc" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">ERROR: Wrong syntax in BIBTEX file.<br></td>
   </tr>
   <tr>
    <td class="results">71</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=78466cd98a7216487e55f86c958491664f5fd00c">VCNet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.68 %</td>
     <td class="results"> 5.67 %</td>
     <td class="results">  1.4 px</td>
     <td class="results">  1.5 px</td>
     <td class="results">0.6 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="78466cd98a7216487e55f86c958491664f5fd00c" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">ERROR: Wrong syntax in BIBTEX file.<br></td>
   </tr>
   <tr>
    <td class="results">72</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=571e62b69d0d5497536fdcd09758a071696fd511">PGNet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.70 %</td>
     <td class="results"> 6.13 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.5 px</td>
     <td class="results">0.7 s</td>
     <td class="results">1 core @ 2.5 Ghz (python)</td>
     <td class="results"><input type="checkbox" value="571e62b69d0d5497536fdcd09758a071696fd511" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">S. Chen, Z. Xiang, C. Qiao, Y. Chen and T. Bai: <a href="http://scholar.google.de/scholar?q=PGNet:%20Panoptic%20parsing%20guided%20deep%20stereo%20matching"> PGNet: Panoptic parsing guided deep stereo 
matching</a>. Neurocomputing 2021.<br></td>
   </tr>
   <tr>
    <td class="results">73</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=1ea0bd9c470e6e2a72d6c6562f20295735227c9f">Abc-Net</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.73 %</td>
     <td class="results"> 5.92 %</td>
     <td class="results">  1.4 px</td>
     <td class="results">  1.5 px</td>
     <td class="results">0.72 s</td>
     <td class="results">4 cores @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="1ea0bd9c470e6e2a72d6c6562f20295735227c9f" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">X. Li, Y. Fan, G. Lv and H. Ma: <a href="http://scholar.google.de/scholar?q=Area-based%20correlation%20and%20non-local%20attention%20network%20for%20stereo%20matching"> Area-based correlation and non-local 
attention network for stereo matching</a>. The Visual Computer 2021.<br></td>
   </tr>
   <tr>
    <td class="results">74</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=19d93f7c0a007e0b4a2dd08d6fd5d775ccb3e2ac">DANet-Stereo</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.75 %</td>
     <td class="results"> 5.91 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.5 px</td>
     <td class="results">2.7 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="19d93f7c0a007e0b4a2dd08d6fd5d775ccb3e2ac" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">75</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=8e486ff2e1c157b0e77b592d424ad0079aeac4e8">MDM-Stereo</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.80 %</td>
     <td class="results"> 6.09 %</td>
     <td class="results">  1.4 px</td>
     <td class="results">  1.6 px</td>
     <td class="results">0.09 s</td>
     <td class="results">NVIDIA RTX 3090 (PyTorch)</td>
     <td class="results"><input type="checkbox" value="8e486ff2e1c157b0e77b592d424ad0079aeac4e8" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">76</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=08807a54fd6520161cfb7e4c1c86c5e9b150dd80">SGNet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.87 %</td>
     <td class="results"> 6.27 %</td>
     <td class="results">  1.4 px</td>
     <td class="results">  1.5 px</td>
     <td class="results">0.6 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python + C/C++)</td>
     <td class="results"><input type="checkbox" value="08807a54fd6520161cfb7e4c1c86c5e9b150dd80" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">S. Chen, Z. Xiang, C. Qiao, Y. Chen and T. Bai: <a href="http://scholar.google.de/scholar?q=SGNet:%20Semantics%20Guided%20Deep%20Stereo%20Matching"> SGNet: Semantics Guided Deep Stereo 
Matching</a>. Proceedings of the Asian Conference 
on Computer Vision (ACCV) 2020.<br></td>
   </tr>
   <tr>
    <td class="results">77</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=2deee7d1b0fa0b7279d64ea76a8bea054f92d468">CREStereo</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/megvii-research/CREStereo" target="blank">code</a></td>
     <td class="results"> 4.93 %</td>
     <td class="results"> 5.55 %</td>
     <td class="results">  1.4 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.40 s</td>
     <td class="results">GPU @ &gt;3.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="2deee7d1b0fa0b7279d64ea76a8bea054f92d468" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">J. Li, P. Wang, P. Xiong, T. Cai, Z. Yan, L. Yang, J. Liu, H. Fan and S. Liu: <a href="http://scholar.google.de/scholar?q=Practical%20Stereo%20Matching%20via%20Cascaded%20Recurrent%20Network%20with%20Adaptive%20Correlation"> Practical Stereo Matching via 
Cascaded Recurrent Network with Adaptive 
Correlation</a>. 2022.<br></td>
   </tr>
   <tr>
    <td class="results">78</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=ce7eb1b27caa058d1216d7bd5c36d4ad240cfd17">SASNet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.96 %</td>
     <td class="results"> 6.34 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.5 px</td>
     <td class="results">0.21 s</td>
     <td class="results">GPU @ &gt;3.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="ce7eb1b27caa058d1216d7bd5c36d4ad240cfd17" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">79</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=b86acf80a214ad0b297623eda5a023e61c821eb6">SSPCVNet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 4.98 %</td>
     <td class="results"> 6.55 %</td>
     <td class="results">  1.5 px</td>
     <td class="results">  1.7 px</td>
     <td class="results">0.9 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="b86acf80a214ad0b297623eda5a023e61c821eb6" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Z. Wu, X. Wu, X. Zhang, S. Wang and L. Ju: <a href="http://scholar.google.de/scholar?q=Semantic%20Stereo%20Matching%20With%20Pyramid%20Cost%20Volumes"> Semantic Stereo Matching With Pyramid Cost 
Volumes</a>. The IEEE International Conference on 
Computer Vision (ICCV) 2019.<br></td>
   </tr>
   <tr>
    <td class="results">80</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=9492be6689afb1230617f8e03bad54553563eaa5">GCGANet-V1</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 5.00 %</td>
     <td class="results"> 6.02 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.5 px</td>
     <td class="results">0.15 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="9492be6689afb1230617f8e03bad54553563eaa5" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">81</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=591c66c3e6f03ca412f5f3cc88c8993807556236">W-Stereo-a-r</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 5.03 %</td>
     <td class="results"> 6.49 %</td>
     <td class="results">  1.4 px</td>
     <td class="results">  1.5 px</td>
     <td class="results">0.07 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="591c66c3e6f03ca412f5f3cc88c8993807556236" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">82</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=8b24dc93d253f2cc00a22aef716539e75e09763f">iResNet-i2</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/leonzfa/iResNet" target="blank">code</a></td>
     <td class="results"> 5.07 %</td>
     <td class="results"> 6.34 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.3 px</td>
     <td class="results">0.12 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="8b24dc93d253f2cc00a22aef716539e75e09763f" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Z. Liang, Y. Feng, Y. Guo, H. Liu, W. Chen, L. Qiao, L. Zhou and J. Zhang: <a href="http://scholar.google.de/scholar?q=Learning%20for%20disparity%20estimation%20through%20feature%20constancy"> Learning for disparity estimation through feature constancy</a>. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2018.<br></td>
   </tr>
   <tr>
    <td class="results">83</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=0eaa4dfc00678885056097844091012bf5011f2e">IEG-Net</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 5.09 %</td>
     <td class="results"> 6.56 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.40 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="0eaa4dfc00678885056097844091012bf5011f2e" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">84</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=270ff2e82cc9a0ce0aacc96b134154bc3e5f1295">AAG</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 5.09 %</td>
     <td class="results"> 6.56 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">1.2 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="270ff2e82cc9a0ce0aacc96b134154bc3e5f1295" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">85</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=170f1f9c2d9c001f2f824f437c18e821e880270e">DSN</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 5.11 %</td>
     <td class="results"> 6.65 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.5 px</td>
     <td class="results">0.03 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="170f1f9c2d9c001f2f824f437c18e821e880270e" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">86</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=f1f97672bf6c76ee1aed9b582cbf44b4c663d881">HSM</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/gengshan-y/high-res-stereo" target="blank">code</a></td>
     <td class="results"> 5.13 %</td>
     <td class="results"> 6.77 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.6 px</td>
     <td class="results">0.15 s</td>
     <td class="results">Titan X Pascal</td>
     <td class="results"><input type="checkbox" value="f1f97672bf6c76ee1aed9b582cbf44b4c663d881" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">G. Yang, J. Manela, M. Happold and D. Ramanan: <a href="http://scholar.google.de/scholar?q=Hierarchical%20Deep%20Stereo%20Matching%20on%20High-%20Resolution%20Images"> Hierarchical Deep Stereo Matching on 
High- 
Resolution Images</a>. The IEEE Conference on Computer 
Vision 
and Pattern Recognition (CVPR) 2019.<br></td>
   </tr>
   <tr>
    <td class="results">87</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=db88dc602d56035d3794e61dd5588cbd99fb6d19">OB_GWC</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 5.17 %</td>
     <td class="results"> 6.43 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.35 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="db88dc602d56035d3794e61dd5588cbd99fb6d19" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">88</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=4ad35f21d11b2b750f27bc7633405b8a1eab1c40">FAPEEM</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 5.18 %</td>
     <td class="results"> 6.65 %</td>
     <td class="results">  1.4 px</td>
     <td class="results">  1.6 px</td>
     <td class="results">0.35 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="4ad35f21d11b2b750f27bc7633405b8a1eab1c40" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">89</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=37dd9700fb54f0635f0e55a889b6ae82797eb28d">ACVNet</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/gangweiX/ACVNet" target="blank">code</a></td>
     <td class="results"> 5.18 %</td>
     <td class="results"> 6.48 %</td>
     <td class="results">  1.4 px</td>
     <td class="results">  1.5 px</td>
     <td class="results">0.2 s</td>
     <td class="results">NVIDIA RTX 3090 (PyTorch)</td>
     <td class="results"><input type="checkbox" value="37dd9700fb54f0635f0e55a889b6ae82797eb28d" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">G. Xu, J. Cheng, P. Guo and X. Yang: <a href="http://scholar.google.de/scholar?q=Attention%20Concatenation%20Volume%20for%20Accurate%20and%20Efficient%20Stereo%20Matching"> Attention Concatenation Volume for 
Accurate and Efficient Stereo Matching</a>. CVPR 2022.<br></td>
   </tr>
   <tr>
    <td class="results">90</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=ed27f535e5e0c16433905be65b0ad4267c720bb3">NLCA-Net</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/NPU-IAP/NLCA-Net" target="blank">code</a></td>
     <td class="results"> 5.19 %</td>
     <td class="results"> 6.43 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.6 s</td>
     <td class="results">GPU @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="ed27f535e5e0c16433905be65b0ad4267c720bb3" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Z. Rao, M. He, Y. Dai, Z. Zhu, B. Li and R. He: <a href="http://scholar.google.de/scholar?q=NLCA-Net:%20a%20non-local%20context%20attention%20network%20for%20stereo%20matching"> NLCA-Net: a non-local context attention 
network for stereo matching</a>. APSIPA Transactions on Signal and 
Information Processing 2020.<br></td>
   </tr>
   <tr>
    <td class="results">91</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=527aa895dcea97ff7d603059a7324c67dbeaa98b">AcfNet</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/DeepMotionAIResearch/DenseMatchingBenchmark" target="blank">code</a></td>
     <td class="results"> 5.20 %</td>
     <td class="results"> 6.44 %</td>
     <td class="results">  1.8 px</td>
     <td class="results">  1.9 px</td>
     <td class="results">0.48 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="527aa895dcea97ff7d603059a7324c67dbeaa98b" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Y. Zhang, Y. Chen, X. Bai, S. Yu, K. Yu, Z. Li and K. Yang: <a href="http://scholar.google.de/scholar?q=Adaptive%20Unimodal%20Cost%20Volume%20Filtering%20for%20Deep%20Stereo%20Matching"> Adaptive Unimodal Cost Volume Filtering for Deep 
Stereo Matching</a>. AAAI 2020.<br></td>
   </tr>
   <tr>
    <td class="results">92</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=9fe5173383ad853646f787cd7b3b80abe23b5308">AANet+</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/haofeixu/aanet" target="blank">code</a></td>
     <td class="results"> 5.25 %</td>
     <td class="results"> 6.66 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.06 s</td>
     <td class="results">NVIDIA V100 GPU</td>
     <td class="results"><input type="checkbox" value="9fe5173383ad853646f787cd7b3b80abe23b5308" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">H. Xu and J. Zhang: <a href="http://scholar.google.de/scholar?q=AANet:%20Adaptive%20Aggregation%20Network%20for%20Efficient%20Stereo%20Matching"> AANet: Adaptive Aggregation Network 
for Efficient Stereo Matching</a>. CVPR 2020.<br></td>
   </tr>
   <tr>
    <td class="results">93</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=66733b3d9ed8b8fa03d45ddace230fe9876964aa">CFP-Net</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/progressforever/Cross-form-Pyramid-Network-for-Stereo-Matching-CFPNet-.git" target="blank">code</a></td>
     <td class="results"> 5.26 %</td>
     <td class="results"> 6.90 %</td>
     <td class="results">  1.4 px</td>
     <td class="results">  1.6 px</td>
     <td class="results">0.95 s</td>
     <td class="results">8 cores @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="66733b3d9ed8b8fa03d45ddace230fe9876964aa" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Z. Zhu, M. He, Y. Dai, Z. Rao and B. Li: <a href="http://scholar.google.de/scholar?q=Multi-scale%20Cross-form%20Pyramid%20Network%20for%20Stereo%20Matching"> Multi-scale Cross-form Pyramid Network for Stereo Matching</a>. arXiv preprint 2019.<br></td>
   </tr>
   <tr>
    <td class="results">94</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=dabf981c0f3a354452d338a0a9c4792d6e18bc4e">MABNet_origin</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123730341.pdf" target="blank">code</a></td>
     <td class="results"> 5.29 %</td>
     <td class="results"> 6.33 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.38 s</td>
     <td class="results">Nvidia rtx2080ti (Python)</td>
     <td class="results"><input type="checkbox" value="dabf981c0f3a354452d338a0a9c4792d6e18bc4e" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">J. Xing, Z. Qi, J. Dong, J. Cai and H. Liu: <a href="http://scholar.google.de/scholar?q=MABNet:%20A%20Lightweight%20Stereo%20Network%20Based%20on%20Multibranch%20Adjustable%20Bottleneck%20Module"> MABNet: A Lightweight Stereo Network 
Based on Multibranch Adjustable Bottleneck 
Module</a>. .<br></td>
   </tr>
   <tr>
    <td class="results">95</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=a87fddafdb8d685f9bd66051f4bc3167254877fc">ASNet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 5.35 %</td>
     <td class="results"> 6.89 %</td>
     <td class="results">  1.5 px</td>
     <td class="results">  1.7 px</td>
     <td class="results">0.17 s</td>
     <td class="results">GPU @ &gt;3.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="a87fddafdb8d685f9bd66051f4bc3167254877fc" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">96</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=96859a706d880ece5e78311186d4028609d06f5c">GASN</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 5.37 %</td>
     <td class="results"> 6.95 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.5 px</td>
     <td class="results">0.09 s</td>
     <td class="results">NVIDIA RTX 3090 (PyTorch)</td>
     <td class="results"><input type="checkbox" value="96859a706d880ece5e78311186d4028609d06f5c" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">97</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=1a0b31765de2b5363fba32ee7f6c8eb23d84834d">ED-Net</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 5.39 %</td>
     <td class="results"> 7.09 %</td>
     <td class="results">  1.4 px</td>
     <td class="results">  1.6 px</td>
     <td class="results">0.24 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="1a0b31765de2b5363fba32ee7f6c8eb23d84834d" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">98</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=1a255081f86d2001e9fd3f7781b6c5a298e2ee5d">AFNet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 5.41 %</td>
     <td class="results"> 6.48 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.25 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="1a255081f86d2001e9fd3f7781b6c5a298e2ee5d" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">99</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=9381dbbf3df3e28901873b03d1c7d4f129b23de4">GDANet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 5.42 %</td>
     <td class="results"> 6.82 %</td>
     <td class="results">  1.5 px</td>
     <td class="results">  1.7 px</td>
     <td class="results">0.04 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="9381dbbf3df3e28901873b03d1c7d4f129b23de4" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">100</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=605c4f5186b8df9e15baf293107c103da8540c29">yjlig</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 5.48 %</td>
     <td class="results"> 6.95 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.5 px</td>
     <td class="results">0.35 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="605c4f5186b8df9e15baf293107c103da8540c29" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">101</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=f3f55cf2ed2ce0ba544cc38d18cd687dc788e161">EAC-Stereo</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/yuankang1234/eac_stereo" target="blank">code</a></td>
     <td class="results"> 5.48 %</td>
     <td class="results"> 6.95 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.5 px</td>
     <td class="results">0.38s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="f3f55cf2ed2ce0ba544cc38d18cd687dc788e161" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">102</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=b2d616a45b7b7bda1cb9d1fd834b5d7c70e9f4cc">GANet-15</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/feihuzhang/GANet" target="blank">code</a></td>
     <td class="results"> 5.49 %</td>
     <td class="results"> 7.10 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.5 px</td>
     <td class="results">0.36 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="b2d616a45b7b7bda1cb9d1fd834b5d7c70e9f4cc" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">F. Zhang, V. Prisacariu, R. Yang and P. Torr: <a href="http://scholar.google.de/scholar?q=GA-Net:%20Guided%20Aggregation%20Net%20for%20End-to-end%20Stereo%20Matching"> GA-Net: Guided Aggregation Net for 
End-to-end Stereo Matching</a>. Proceedings of the IEEE Conference 
on Computer Vision and Pattern Recognition 
(CVPR) 2019.<br></td>
   </tr>
   <tr>
    <td class="results">103</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=98cdc5e692e3977d3afe34b3f91db674861201a9">FADNet</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/HKBU-HPML/FADNet" target="blank">code</a></td>
     <td class="results"> 5.57 %</td>
     <td class="results"> 6.51 %</td>
     <td class="results">  1.2 px</td>
     <td class="results">  1.3 px</td>
     <td class="results">0.05 s</td>
     <td class="results">Tesla V100 (Python)</td>
     <td class="results"><input type="checkbox" value="98cdc5e692e3977d3afe34b3f91db674861201a9" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Q. Wang, S. Shi, S. Zheng, K. Zhao and X. Chu: <a href="http://scholar.google.de/scholar?q=FADNet:%20A%20Fast%20and%20Accurate%20Network%20for%20Disparity%20Estimation"> FADNet: A Fast and Accurate Network 
for Disparity Estimation</a>. arXiv preprint arXiv:2003.10758 2020.<br></td>
   </tr>
   <tr>
    <td class="results">104</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=ed3ace1b672df08c9377adf90b763c174071c74a">OA_COEX</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 5.59 %</td>
     <td class="results"> 7.09 %</td>
     <td class="results">  1.4 px</td>
     <td class="results">  1.6 px</td>
     <td class="results">0.35 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="ed3ace1b672df08c9377adf90b763c174071c74a" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">105</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=d3123e97c07b3b83d7898391d8c531e0082af28c">GwcNet-gc</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/xy-guo/GwcNet" target="blank">code</a></td>
     <td class="results"> 5.69 %</td>
     <td class="results"> 6.70 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.32 s</td>
     <td class="results">GPU @ 2.0 Ghz (Java + C/C++)</td>
     <td class="results"><input type="checkbox" value="d3123e97c07b3b83d7898391d8c531e0082af28c" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">X. Guo, K. Yang, W. Yang, X. Wang and H. Li: <a href="http://scholar.google.de/scholar?q=Group-wise%20correlation%20stereo%20network"> Group-wise correlation stereo network</a>. CVPR 2019.<br></td>
   </tr>
   <tr>
    <td class="results">106</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=a23b67e654e89119e4430d6e2361cc94978c9b23">OB_GWC</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 5.69 %</td>
     <td class="results"> 6.70 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.4 px</td>
     <td class="results">0.35 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="a23b67e654e89119e4430d6e2361cc94978c9b23" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">107</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=8f8de9dcdcc1c2545c5daf13ef2c4251f688930d">PASNet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 5.82 %</td>
     <td class="results"> 6.82 %</td>
     <td class="results">  1.4 px</td>
     <td class="results">  1.5 px</td>
     <td class="results">0.38 s</td>
     <td class="results">GPU @ 3.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="8f8de9dcdcc1c2545c5daf13ef2c4251f688930d" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">108</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=29a2ffee068863ed8a025e8c105d1be095a05fa1">PSMNet</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/JiaRenChang/PSMNet" target="blank">code</a></td>
     <td class="results"> 5.89 %</td>
     <td class="results"> 7.29 %</td>
     <td class="results">  1.4 px</td>
     <td class="results">  1.6 px</td>
     <td class="results">0.41 s</td>
     <td class="results">Nvidia Titan Xp</td>
     <td class="results"><input type="checkbox" value="29a2ffee068863ed8a025e8c105d1be095a05fa1" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">J. Chang and Y. Chen: <a href="http://scholar.google.de/scholar?q=Pyramid%20Stereo%20Matching%20Network"> Pyramid Stereo Matching Network</a>. arXiv preprint arXiv:1803.08669 2018.<br></td>
   </tr>
   <tr>
    <td class="results">109</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=e316c03b92d0d32fc007a592e0355f005100dafe">Fast DS-CS</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://projects.ayanc.org/fdscs/" target="blank">code</a></td>
     <td class="results"> 6.01 %</td>
     <td class="results"> 7.23 %</td>
     <td class="results">  1.3 px</td>
     <td class="results">  1.5 px</td>
     <td class="results">0.02 s</td>
     <td class="results">GPU @ 2.0 Ghz (Python + C/C++)</td>
     <td class="results"><input type="checkbox" value="e316c03b92d0d32fc007a592e0355f005100dafe" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">K. Yee and A. Chakrabarti: <a href="http://scholar.google.de/scholar?q=Fast%20Deep%20Stereo%20with%202D%20Convolutional%20Processing%20of%20Cost%20Signatures"> Fast Deep Stereo with 2D Convolutional 
Processing of Cost Signatures</a>. WACV 2020 (to appear).<br></td>
   </tr>
   <tr>
    <td class="results">110</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=b8e98b5698bc34ddcf9f6bc40bf28a26d89d7314">Lite-CREStereo++</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 6.01 %</td>
     <td class="results"> 7.05 %</td>
     <td class="results">  1.4 px</td>
     <td class="results">  1.5 px</td>
     <td class="results">1 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="b8e98b5698bc34ddcf9f6bc40bf28a26d89d7314" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">111</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=3ffe42237c607d302224ee24ba07f1d06bf3f6f9">GAMNet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 6.04 %</td>
     <td class="results"> 7.81 %</td>
     <td class="results">  1.4 px</td>
     <td class="results">  1.6 px</td>
     <td class="results">1 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="3ffe42237c607d302224ee24ba07f1d06bf3f6f9" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">112</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=e6ceddc0f2c4c512fcf321accb1bca5ded68420e">WSMCnet</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/wyf2017/WSMCnet" target="blank">code</a></td>
     <td class="results"> 6.08 %</td>
     <td class="results"> 7.50 %</td>
     <td class="results">  2.1 px</td>
     <td class="results">  2.3 px</td>
     <td class="results">0.39 s</td>
     <td class="results">GPU @ Nvidia GTX 1070 (Pytorch)</td>
     <td class="results"><input type="checkbox" value="e6ceddc0f2c4c512fcf321accb1bca5ded68420e" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Y. Wang, H. Wang, G. Yu, M. Yang, Y. Yuan and J. Quan: <a href="http://scholar.google.de/scholar?q=Stereo%20Matching%20Algorithm%20Based%20on%20Three-Dimensional%20Convolutional%20Neural%20Network"> Stereo Matching Algorithm Based on Three-Dimensional Convolutional Neural Network</a>. Acta Optica Sinica 2019.<br></td>
   </tr>
   <tr>
    <td class="results">113</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=1a7d3eecc0b4b4ed2994c7319d51db9200dacba0">Displets</a></td>
     <td class="results"></td>
     <td class="results"><a href="http://www.cvlibs.net/projects/displets/" target="blank">code</a></td>
     <td class="results"> 6.11 %</td>
     <td class="results"> 7.23 %</td>
     <td class="results">  1.9 px</td>
     <td class="results">  2.3 px</td>
     <td class="results">265 s</td>
     <td class="results">&gt;8 cores @ 3.0 Ghz (Matlab + C/C++)</td>
     <td class="results"><input type="checkbox" value="1a7d3eecc0b4b4ed2994c7319d51db9200dacba0" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">F. Guney and A. Geiger: <a href="http://scholar.google.de/scholar?q=Displets:%20Resolving%20Stereo%20Ambiguities%20using%20Object%20Knowledge"> Displets: Resolving Stereo Ambiguities using Object Knowledge</a>. Conference on Computer Vision and Pattern Recognition (CVPR) 2015.<br></td>
   </tr>
   <tr>
    <td class="results">114</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=d6ced17514e92eebe9f2d4887263e9e2ad2dccd9">PVStereo</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 6.17 %</td>
     <td class="results"> 7.06 %</td>
     <td class="results">  2.2 px</td>
     <td class="results">  2.3 px</td>
     <td class="results">0.10 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="d6ced17514e92eebe9f2d4887263e9e2ad2dccd9" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">H. Wang, R. Fan, P. Cai and M. Liu: <a href="http://scholar.google.de/scholar?q=PVStereo:%20Pyramid%20voting%20module%20for%20end-to-end%20self-supervised%20stereo%20matching"> PVStereo: Pyramid voting module 
for end-to-end self-supervised stereo matching</a>. IEEE Robotics and Automation 
Letters 2021.<br></td>
   </tr>
   <tr>
    <td class="results">115</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=3e04aa5d4fcf9f17cb962e1d8287e911eccac844">GAANet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 6.64 %</td>
     <td class="results"> 8.21 %</td>
     <td class="results">  1.8 px</td>
     <td class="results">  2.0 px</td>
     <td class="results">0.08</td>
     <td class="results">2080tiGPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="3e04aa5d4fcf9f17cb962e1d8287e911eccac844" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">116</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=75c861a69308e7b28db43c8bfd7f8c90a142cf66">RTSnet</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://ieeexplore.ieee.org/abstract/document/8803514" target="blank">code</a></td>
     <td class="results"> 6.69 %</td>
     <td class="results"> 8.25 %</td>
     <td class="results">  1.7 px</td>
     <td class="results">  1.9 px</td>
     <td class="results">0.02 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="75c861a69308e7b28db43c8bfd7f8c90a142cf66" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">H. Lee and Y. Shin: <a href="http://scholar.google.de/scholar?q=Real-Time%20Stereo%20Matching%20Network%20with%20High%20Accuracy"> Real-Time Stereo Matching Network with High 
Accuracy</a>. 2019 IEEE International Conference on Image 
Processing (ICIP) 2019.<br></td>
   </tr>
   <tr>
    <td class="results">117</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=c634eb93377338000564fa411f7bead10fba50e6">MSDC-Net</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 6.72 %</td>
     <td class="results"> 8.37 %</td>
     <td class="results">  1.8 px</td>
     <td class="results">  2.0 px</td>
     <td class="results">0.6 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="c634eb93377338000564fa411f7bead10fba50e6" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Z. Rao, M. He, Y. Dai, Z. Zhu, B. Li and R. He: <a href="http://scholar.google.de/scholar?q=MSDC-Net:%20Multi-Scale%20Dense%20and%20Contextual%20Networks%20for%20Stereo%20Matching"> MSDC-Net: Multi-Scale Dense and 
Contextual Networks for Stereo Matching</a>. 2019 Asia-Pacific Signal and 
Information Processing Association Annual Summit 
and Conference (APSIPA ASC) 2019.<br></td>
   </tr>
   <tr>
    <td class="results">118</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=5d2506d68599f206afa6e8ce3fc05aab8407da34">MMStereo</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 6.78 %</td>
     <td class="results"> 8.23 %</td>
     <td class="results">  1.6 px</td>
     <td class="results">  1.7 px</td>
     <td class="results">0.04 s</td>
     <td class="results">Nvidia Titan RTX (Python)</td>
     <td class="results"><input type="checkbox" value="5d2506d68599f206afa6e8ce3fc05aab8407da34" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">K. Shankar, M. Tjersland, J. Ma, K. Stone and M. Bajracharya: <a href="http://scholar.google.de/scholar?q=A%20Learned%20Stereo%20Depth%20System%20for%20Robotic%20Manipulation%20in%20Homes"> A Learned Stereo Depth System for 
Robotic Manipulation in Homes</a>. .<br></td>
   </tr>
   <tr>
    <td class="results">119</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=4151c13f4487758ba68e78372a293a8723bf8259">Displets v2</a></td>
     <td class="results"></td>
     <td class="results"><a href="http://www.cvlibs.net/projects/displets/" target="blank">code</a></td>
     <td class="results"> 6.92 %</td>
     <td class="results"> 8.02 %</td>
     <td class="results">  2.0 px</td>
     <td class="results">  2.2 px</td>
     <td class="results">265 s</td>
     <td class="results">&gt;8 cores @ 3.0 Ghz (Matlab + C/C++)</td>
     <td class="results"><input type="checkbox" value="4151c13f4487758ba68e78372a293a8723bf8259" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">F. Guney and A. Geiger: <a href="http://scholar.google.de/scholar?q=Displets:%20Resolving%20Stereo%20Ambiguities%20using%20Object%20Knowledge"> Displets: Resolving Stereo Ambiguities 
using Object 
Knowledge</a>. Conference on Computer Vision and 
Pattern Recognition 
(CVPR) 2015.<br></td>
   </tr>
   <tr>
    <td class="results">120</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=2e6d69f49d8df3cecf379829bd028bf70cbfc262">WaveletStereo</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 7.38 %</td>
     <td class="results"> 9.27 %</td>
     <td class="results">  1.7 px</td>
     <td class="results">  1.9 px</td>
     <td class="results">0.27 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="2e6d69f49d8df3cecf379829bd028bf70cbfc262" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Anonymous: <a href="http://scholar.google.de/scholar?q=WaveletStereo:%20Learning%20wavelet%20coefficients%20for%20stereo%20matching"> WaveletStereo: Learning wavelet coefficients 
for stereo matching</a>. arXiv: Computer Vision and Pattern 
Recognition 2019.<br></td>
   </tr>
   <tr>
    <td class="results">121</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=4ebead8158ed396db8aa422de308baf7c6910987">AANet</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/haofeixu/aanet" target="blank">code</a></td>
     <td class="results"> 7.89 %</td>
     <td class="results"> 8.91 %</td>
     <td class="results">  1.7 px</td>
     <td class="results">  1.8 px</td>
     <td class="results">0.06 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="4ebead8158ed396db8aa422de308baf7c6910987" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">H. Xu and J. Zhang: <a href="http://scholar.google.de/scholar?q=AANet:%20Adaptive%20Aggregation%20Networkfor%20Efficient%20Stereo%20Matching"> AANet: Adaptive Aggregation Network
for Efficient Stereo Matching</a>. CVPR 2020.<br></td>
   </tr>
   <tr>
    <td class="results">122</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=679c63631fd1225192f547a03a9ac7e8204d580c">DSN</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/cogsys-tuebingen/" target="blank">code</a></td>
     <td class="results"> 8.01 %</td>
     <td class="results">10.20 %</td>
     <td class="results">  1.9 px</td>
     <td class="results">  2.2 px</td>
     <td class="results">0.03 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="679c63631fd1225192f547a03a9ac7e8204d580c" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">123</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=087a02ae0db557c2a5d100b7b3a273215c9e0c35">MDTE4</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 8.12 %</td>
     <td class="results">10.06 %</td>
     <td class="results">  2.2 px</td>
     <td class="results">  2.4 px</td>
     <td class="results">0.03 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="087a02ae0db557c2a5d100b7b3a273215c9e0c35" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">124</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=8da072a8f49d792632b8940582d5578c7d86b747">GC-NET</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 8.13 %</td>
     <td class="results"> 9.77 %</td>
     <td class="results">  1.8 px</td>
     <td class="results">  2.0 px</td>
     <td class="results">0.9 s</td>
     <td class="results">Nvidia GTX Titan X</td>
     <td class="results"><input type="checkbox" value="8da072a8f49d792632b8940582d5578c7d86b747" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">A. Kendall, H. Martirosyan, S. Dasgupta, P. Henry, R. Kennedy, A. Bachrach and A. Bry: <a href="http://scholar.google.de/scholar?q=End-to-End%20Learning%20of%20Geometry%20and%20Context%20for%20Deep%20Stereo%20Regression"> End-to-End Learning of Geometry and Context for 
Deep Stereo Regression</a>. Proceedings of the International Conference on 
Computer Vision (ICCV) 2017.<br></td>
   </tr>
   <tr>
    <td class="results">125</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=477b629737f07b65403214c1c00a1b70a26cab36">Ct-Net</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 8.74 %</td>
     <td class="results">10.46 %</td>
     <td class="results">  3.1 px</td>
     <td class="results">  3.4 px</td>
     <td class="results">0.45 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="477b629737f07b65403214c1c00a1b70a26cab36" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">126</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=f0f80b4836c780154f3b20ec79e135d33a0c8679">VC-SF</a></td>
     <td class="results"><div class="icon"><img src="./KITTI2012Reflective_files/icon_fl.png" alt="This method uses optical flow information."></div><div class="icon"><img src="./KITTI2012Reflective_files/icon_mv.png" alt="This method makes use of multiple (&gt;2) views."></div></td>
     <td class="results"></td>
     <td class="results"> 9.11 %</td>
     <td class="results"> 9.64 %</td>
     <td class="results">  2.7 px</td>
     <td class="results">  2.8 px</td>
     <td class="results">300 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="f0f80b4836c780154f3b20ec79e135d33a0c8679" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">C. Vogel, S. Roth and K. Schindler: <a href="http://scholar.google.de/scholar?q=View-Consistent%203D%20Scene%20Flow%20Estimation%20over%20Multiple%20Frames"> View-Consistent 3D Scene Flow 
Estimation over Multiple Frames</a>. Proceedings of European 
Conference on Computer Vision. Lecture 
Notes in, Computer Science 2014.<br></td>
   </tr>
   <tr>
    <td class="results">127</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=97aa73040b1bb44aa63838e29e2a43d0b83f7773">PRSM</a></td>
     <td class="results"><div class="icon"><img src="./KITTI2012Reflective_files/icon_fl.png" alt="This method uses optical flow information."></div><div class="icon"><img src="./KITTI2012Reflective_files/icon_mv.png" alt="This method makes use of multiple (&gt;2) views."></div></td>
     <td class="results"><a href="https://github.com/vogechri/PRSM" target="blank">code</a></td>
     <td class="results"> 9.13 %</td>
     <td class="results"> 9.75 %</td>
     <td class="results">  2.0 px</td>
     <td class="results">  2.1 px</td>
     <td class="results">300 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="97aa73040b1bb44aa63838e29e2a43d0b83f7773" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">C. Vogel, K. Schindler and S. Roth: <a href="http://scholar.google.de/scholar?q=3D%20Scene%20Flow%20Estimation%20with%20a%20Piecewise%20Rigid%20Scene%20Model"> 3D Scene Flow Estimation with a 
Piecewise Rigid Scene Model</a>. ijcv 2015.<br></td>
   </tr>
   <tr>
    <td class="results">128</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=881e33eaff3d0b5714f5dca1773690ea70f54417">OSF</a></td>
     <td class="results"><div class="icon"><img src="./KITTI2012Reflective_files/icon_fl.png" alt="This method uses optical flow information."></div></td>
     <td class="results"><a href="http://www.cvlibs.net/projects/objectsceneflow" target="blank">code</a></td>
     <td class="results"> 9.27 %</td>
     <td class="results">12.24 %</td>
     <td class="results">  2.1 px</td>
     <td class="results">  2.6 px</td>
     <td class="results">50 min</td>
     <td class="results">1 core @ 3.0 Ghz (Matlab + C/C++)</td>
     <td class="results"><input type="checkbox" value="881e33eaff3d0b5714f5dca1773690ea70f54417" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">M. Menze and A. Geiger: <a href="http://scholar.google.de/scholar?q=Object%20Scene%20Flow%20for%20Autonomous%20Vehicles"> Object Scene Flow for Autonomous Vehicles</a>. Conference on Computer Vision and Pattern Recognition (CVPR) 2015.<br></td>
   </tr>
   <tr>
    <td class="results">129</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=822a012d9b7b710a98b5d046cdc47315ff39034f">TSNnet_Teacher</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results"> 9.34 %</td>
     <td class="results">11.52 %</td>
     <td class="results">  2.5 px</td>
     <td class="results">  2.9 px</td>
     <td class="results">0.01 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="822a012d9b7b710a98b5d046cdc47315ff39034f" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">130</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=310bf5c980ecb54adb94ec543b03678498aaff29">TSNnet_naive</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">10.41 %</td>
     <td class="results">12.89 %</td>
     <td class="results">  2.3 px</td>
     <td class="results">  2.8 px</td>
     <td class="results">0.01 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="310bf5c980ecb54adb94ec543b03678498aaff29" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">131</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=8da0d646261d044b722b429e2d105c596bc5b81e">RecResNet</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/kbatsos/RecResNet" target="blank">code</a></td>
     <td class="results">10.64 %</td>
     <td class="results">13.40 %</td>
     <td class="results">  2.1 px</td>
     <td class="results">  2.5 px</td>
     <td class="results">0.3 s</td>
     <td class="results">GPU @ NVIDIA TITAN X (Tensorflow)</td>
     <td class="results"><input type="checkbox" value="8da0d646261d044b722b429e2d105c596bc5b81e" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">K. Batsos and P. Mordohai: <a href="http://scholar.google.de/scholar?q=RecResNet:%20A%20Recurrent%20Residual%20CNN%20Architecture%20for%20Disparity%20Map%20Enhancement"> RecResNet: A Recurrent Residual CNN 
Architecture for Disparity Map Enhancement</a>.  In International Conference on 3D 
Vision (3DV)  2018.<br></td>
   </tr>
   <tr>
    <td class="results">132</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=4727d3cf8de3539de7b378fb0ee2bd417d2dd033">PCBP-SS</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">10.74 %</td>
     <td class="results">14.75 %</td>
     <td class="results">  2.4 px</td>
     <td class="results">  3.9 px</td>
     <td class="results">5 min</td>
     <td class="results">4 cores @ 2.5 Ghz (Matlab + C/C++)</td>
     <td class="results"><input type="checkbox" value="4727d3cf8de3539de7b378fb0ee2bd417d2dd033" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">K. Yamaguchi, D. McAllester and R. Urtasun: <a href="http://scholar.google.de/scholar?q=Robust%20Monocular%20Epipolar%20Flow%20Estimation"> Robust Monocular Epipolar Flow Estimation</a>. CVPR 2013.<br></td>
   </tr>
   <tr>
    <td class="results">133</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=57058992819451cc27e4df0735a067daff8f4022">SsSMnet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">10.87 %</td>
     <td class="results">13.21 %</td>
     <td class="results">  3.1 px</td>
     <td class="results">  3.6 px</td>
     <td class="results">0.8 s</td>
     <td class="results">Titan Xp</td>
     <td class="results"><input type="checkbox" value="57058992819451cc27e4df0735a067daff8f4022" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Y. Zhong, Y. Dai and H. Li: <a href="http://scholar.google.de/scholar?q=Self-Supervised%20Learning%20for%20Stereo%20Matching%20with%20Self-Improving%20Ability"> Self-Supervised Learning for Stereo 
Matching with Self-Improving Ability</a>. arXiv:1709.00930 2017.<br></td>
   </tr>
   <tr>
    <td class="results">134</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=88cbea108f3a0f7264f037aeb3162c79d9460451">JSOSM</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">10.90 %</td>
     <td class="results">13.35 %</td>
     <td class="results">  2.4 px</td>
     <td class="results">  2.8 px</td>
     <td class="results">105 s</td>
     <td class="results">8 cores @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="88cbea108f3a0f7264f037aeb3162c79d9460451" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">X. Li and J. Liu: <a href="http://scholar.google.de/scholar?q=EFFICIENT%20STEREO%20MATCHING%20USING%20SEGMENT%20OPTIMIZATION"> EFFICIENT STEREO MATCHING USING SEGMENT 
OPTIMIZATION</a>. ICIP  2016.<br></td>
   </tr>
   <tr>
    <td class="results">135</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=24c3251fce46fa37bc2634c1a3b0dc40f0870ff6">TSNnet_student</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">11.24 %</td>
     <td class="results">13.77 %</td>
     <td class="results">  3.1 px</td>
     <td class="results">  3.8 px</td>
     <td class="results">0.01 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="24c3251fce46fa37bc2634c1a3b0dc40f0870ff6" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">136</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=476fe5f19f6eb55b3fcbdc16ad0a2ca952567a5b">DispNetC</a></td>
     <td class="results"></td>
     <td class="results"><a href="http://lmb.informatik.uni-freiburg.de/resources/software.php" target="blank">code</a></td>
     <td class="results">11.38 %</td>
     <td class="results">13.19 %</td>
     <td class="results">  2.1 px</td>
     <td class="results">  2.3 px</td>
     <td class="results">0.06 s</td>
     <td class="results">Nvidia GTX Titan X (Caffe)</td>
     <td class="results"><input type="checkbox" value="476fe5f19f6eb55b3fcbdc16ad0a2ca952567a5b" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">N. Mayer, E. Ilg, P. Häusser, P. Fischer, D. Cremers, A. Dosovitskiy and T. Brox: <a href="http://scholar.google.de/scholar?q=A%20Large%20Dataset%20to%20Train%20Convolutional%20Networks%20for%20Disparity,%20Optical%20Flow,%20and%20Scene%20Flow%20Estimation"> A Large Dataset to Train 
Convolutional Networks for Disparity, Optical 
Flow, and Scene Flow Estimation</a>. CVPR 2016.<br></td>
   </tr>
   <tr>
    <td class="results">137</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=f8017c3fe7859e6e79b29822b68620431d2d487c">FD-Fusion</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/ferreram/FD-Fusion" target="blank">code</a></td>
     <td class="results">11.38 %</td>
     <td class="results">13.56 %</td>
     <td class="results">  2.6 px</td>
     <td class="results">  2.9 px</td>
     <td class="results">0.01 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="f8017c3fe7859e6e79b29822b68620431d2d487c" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">M. Ferrera, A. Boulch and J. Moras: <a href="http://scholar.google.de/scholar?q=Fast%20Stereo%20Disparity%20Maps%20Refinement%20By%20Fusion%20of%20Data-Based%20And%20Model-Based%20Estimations"> Fast Stereo Disparity Maps Refinement By Fusion of Data-Based And Model-Based Estimations</a>. International Conference on 3D Vision (3DV) 2019.<br></td>
   </tr>
   <tr>
    <td class="results">138</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=811e8c08ded709595e20f3ecc1210ca70d255eb5">P3SNet+</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/aemlek/P3SNet" target="blank">code</a></td>
     <td class="results">11.66 %</td>
     <td class="results">14.13 %</td>
     <td class="results">  2.1 px</td>
     <td class="results">  2.4 px</td>
     <td class="results">0.01 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="811e8c08ded709595e20f3ecc1210ca70d255eb5" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">A. Emlek and M. Peker: <a href="http://scholar.google.de/scholar?q=P3SNet:%20Parallel%20Pyramid%20Pooling%20Stereo%20Network"> P3SNet: Parallel Pyramid Pooling Stereo 
Network</a>. IEEE Transactions on Intelligent 
Transportation Systems 2023.<br></td>
   </tr>
   <tr>
    <td class="results">139</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=599b196ca9bf607a178c1b3eafe3fbc2a8dbfbc6">cfusion</a></td>
     <td class="results"><div class="icon"><img src="./KITTI2012Reflective_files/icon_mv.png" alt="This method makes use of multiple (&gt;2) views."></div></td>
     <td class="results"><a href="https://github.com/alcor-vision/confidence-fusion" target="blank">code</a></td>
     <td class="results">11.76 %</td>
     <td class="results">12.43 %</td>
     <td class="results">  2.6 px</td>
     <td class="results">  2.8 px</td>
     <td class="results">70 s</td>
     <td class="results">GPU (Matlab + CUDA)</td>
     <td class="results"><input type="checkbox" value="599b196ca9bf607a178c1b3eafe3fbc2a8dbfbc6" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">V. Ntouskos and F. Pirri: <a href="http://scholar.google.de/scholar?q=Confidence%20driven%20TGV%20fusion"> Confidence driven TGV fusion</a>. arXiv preprint arXiv:1603.09302 2016.<br></td>
   </tr>
   <tr>
    <td class="results">140</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=fe470a3d1799fe724036893bef3479e720518b55">SPS-StFl</a></td>
     <td class="results"><div class="icon"><img src="./KITTI2012Reflective_files/icon_fl.png" alt="This method uses optical flow information."></div><div class="icon"><img src="./KITTI2012Reflective_files/icon_ms.png" alt="This method makes use of the epipolar geometry."></div></td>
     <td class="results"></td>
     <td class="results">11.94 %</td>
     <td class="results">14.88 %</td>
     <td class="results">  2.9 px</td>
     <td class="results">  3.6 px</td>
     <td class="results">35 s</td>
     <td class="results">1 core @ 3.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="fe470a3d1799fe724036893bef3479e720518b55" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">K. Yamaguchi, D. McAllester and R. Urtasun: <a href="http://scholar.google.de/scholar?q=Efficient%20Joint%20Segmentation,%20Occlusion%20Labeling,%20Stereo%20and%20Flow%20Estimation"> Efficient Joint Segmentation, Occlusion Labeling, Stereo 
and Flow Estimation</a>. ECCV 2014.<br></td>
   </tr>
   <tr>
    <td class="results">141</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=81694fba3bf7ccf1f3798ffbeedd85c8cf28b735">SGM-Net</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">12.18 %</td>
     <td class="results">15.62 %</td>
     <td class="results">  3.0 px</td>
     <td class="results">  3.8 px</td>
     <td class="results">67 s</td>
     <td class="results">Titan X</td>
     <td class="results"><input type="checkbox" value="81694fba3bf7ccf1f3798ffbeedd85c8cf28b735" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">A. Seki and M. Pollefeys: <a href="http://scholar.google.de/scholar?q=SGM-Nets:%20Semi-Global%20Matching%20With%20Neural%20Networks"> SGM-Nets: Semi-Global Matching With Neural 
Networks</a>. CVPR 2017.<br></td>
   </tr>
   <tr>
    <td class="results">142</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=da9bf21f2d10f7f3e3e48695b54672338ca88f19">CoR</a></td>
     <td class="results"></td>
     <td class="results"><a href="http://www.ttic.edu/chakrabarti/consensus/" target="blank">code</a></td>
     <td class="results">12.21 %</td>
     <td class="results">15.95 %</td>
     <td class="results">  2.7 px</td>
     <td class="results">  4.1 px</td>
     <td class="results">6 s</td>
     <td class="results">6 cores @ 3.3 Ghz (Matlab + C/C++)</td>
     <td class="results"><input type="checkbox" value="da9bf21f2d10f7f3e3e48695b54672338ca88f19" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">A. Chakrabarti, Y. Xiong, S. Gortler and T. Zickler: <a href="http://scholar.google.de/scholar?q=Low-level%20Vision%20by%20Consensus%20in%20a%20Spatial%20Hierarchy%20of%20Regions"> Low-level Vision by Consensus in a Spatial 
Hierarchy of Regions</a>. CVPR 2015.<br></td>
   </tr>
   <tr>
    <td class="results">143</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=cd8e3c03cce0def2fc1b41623fc98aa427f66044">MABNet_tiny</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123730341.pdf" target="blank">code</a></td>
     <td class="results">12.34 %</td>
     <td class="results">14.45 %</td>
     <td class="results">  2.5 px</td>
     <td class="results">  2.8 px</td>
     <td class="results">0.11 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="cd8e3c03cce0def2fc1b41623fc98aa427f66044" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">J. Xing, Z. Qi, J. Dong, J. Cai and H. Liu: <a href="http://scholar.google.de/scholar?q=MABNet:%20A%20Lightweight%20Stereo%20Network%20Based%20on%20Multibranch%20Adjustable%20Bottleneck%20Module"> MABNet: A Lightweight Stereo Network 
Based on Multibranch Adjustable Bottleneck 
Module</a>. .<br></td>
   </tr>
   <tr>
    <td class="results">144</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=e4a0ec4f91ed8dcc9d4a9a2422b57dc147b74850">DDS-SS</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">12.48 %</td>
     <td class="results">15.39 %</td>
     <td class="results">  2.5 px</td>
     <td class="results">  3.0 px</td>
     <td class="results">1 min</td>
     <td class="results">1 core @ 2.5 Ghz (Matlab + C/C++)</td>
     <td class="results"><input type="checkbox" value="e4a0ec4f91ed8dcc9d4a9a2422b57dc147b74850" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">D. Wei, C. Liu and W. Freeman: <a href="http://scholar.google.de/scholar?q=A%20Data-driven%20Regularization%20Model%20for%20Stereo%20and%20Flow"> A Data-driven Regularization Model for Stereo and Flow</a>. 3DTV-Conference, 2014 International Conference on 2014.<br></td>
   </tr>
   <tr>
    <td class="results">145</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=1a7944d8789a957188acc469c09f417f035ea6eb">CNNF+SGM</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">12.66 %</td>
     <td class="results">16.12 %</td>
     <td class="results">  2.9 px</td>
     <td class="results">  3.9 px</td>
     <td class="results">71 s</td>
     <td class="results">TESLA K40C</td>
     <td class="results"><input type="checkbox" value="1a7944d8789a957188acc469c09f417f035ea6eb" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">F. Zhang and B. Wah: <a href="http://scholar.google.de/scholar?q=Fundamental%20Principles%20on%20Learning%20New%20Features%20for%20Effective%20Dense%20Matching"> Fundamental Principles on Learning New 
Features for Effective Dense Matching</a>. IEEE Transactions on Image 
Processing 2018.<br></td>
   </tr>
   <tr>
    <td class="results">146</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=158bf9ff2c37d01c0def96840b7045d3b9592668">PCBP</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">12.66 %</td>
     <td class="results">16.57 %</td>
     <td class="results">  2.8 px</td>
     <td class="results">  4.4 px</td>
     <td class="results">5 min</td>
     <td class="results">4 cores @ 2.5 Ghz (Matlab + C/C++)</td>
     <td class="results"><input type="checkbox" value="158bf9ff2c37d01c0def96840b7045d3b9592668" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">K. Yamaguchi, T. Hazan, D. McAllester and R. Urtasun: <a href="http://scholar.google.de/scholar?q=Continuous%20Markov%20Random%20Fields%20for%20Robust%20Stereo%20Estimation"> Continuous Markov Random Fields for Robust Stereo 
Estimation</a>. ECCV 2012.<br></td>
   </tr>
   <tr>
    <td class="results">147</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=d155755d5ac84dd7ba1fe30a6a71657c25168c00">L-ResMatch</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/amitshaked/resmatch" target="blank">code</a></td>
     <td class="results">12.92 %</td>
     <td class="results">16.52 %</td>
     <td class="results">  3.7 px</td>
     <td class="results">  5.2 px</td>
     <td class="results">48 s</td>
     <td class="results">Titan X (Torch7, CUDA)</td>
     <td class="results"><input type="checkbox" value="d155755d5ac84dd7ba1fe30a6a71657c25168c00" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">A. Shaked and L. Wolf: <a href="http://scholar.google.de/scholar?q=Improved%20Stereo%20Matching%20with%20Constant%20Highway%20Networks%20and%20Reflective%20Loss"> Improved Stereo Matching with Constant Highway 
Networks and Reflective Loss</a>. arXiv preprint arxiv:1701.00165 2016.<br></td>
   </tr>
   <tr>
    <td class="results">148</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=ad0fa26dece27853ecb7919e8184d271defcebc6">P3SNet</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/aemlek/P3SNet" target="blank">code</a></td>
     <td class="results">13.01 %</td>
     <td class="results">15.71 %</td>
     <td class="results">  2.3 px</td>
     <td class="results">  2.8 px</td>
     <td class="results">0.01 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="ad0fa26dece27853ecb7919e8184d271defcebc6" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">A. Emlek and M. Peker: <a href="http://scholar.google.de/scholar?q=P3SNet:%20Parallel%20Pyramid%20Pooling%20Stereo%20Network"> P3SNet: Parallel Pyramid Pooling Stereo 
Network</a>. IEEE Transactions on Intelligent 
Transportation Systems 2023.<br></td>
   </tr>
   <tr>
    <td class="results">149</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=e4b6529f3f6fc3baec689f1dccbf268e0c37316f">SPS-St</a></td>
     <td class="results"></td>
     <td class="results"><a href="http://ttic.uchicago.edu/~dmcallester/SPS/index.html" target="blank">code</a></td>
     <td class="results">13.11 %</td>
     <td class="results">16.11 %</td>
     <td class="results">  3.1 px</td>
     <td class="results">  3.6 px</td>
     <td class="results">2 s</td>
     <td class="results">1 core @ 3.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="e4b6529f3f6fc3baec689f1dccbf268e0c37316f" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">K. Yamaguchi, D. McAllester and R. Urtasun: <a href="http://scholar.google.de/scholar?q=Efficient%20Joint%20Segmentation,%20Occlusion%20Labeling,%20Stereo%20and%20Flow%20Estimation"> Efficient Joint Segmentation, Occlusion Labeling, Stereo and 
Flow Estimation</a>. ECCV 2014.<br></td>
   </tr>
   <tr>
    <td class="results">150</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=810169a667c1d8f712ce4c82969a5e9b8b4956c8">Deep Embed</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">13.18 %</td>
     <td class="results">16.70 %</td>
     <td class="results">  2.8 px</td>
     <td class="results">  3.8 px</td>
     <td class="results">3 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="810169a667c1d8f712ce4c82969a5e9b8b4956c8" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Z. Chen, X. Sun, Y. Yu, L. Wang and C. Huang: <a href="http://scholar.google.de/scholar?q=A%20Deep%20Visual%20Correspondence%20Embedding%20Model%20for%20Stereo%20Matching%20Costs"> A Deep Visual Correspondence 
Embedding Model for Stereo Matching Costs</a>. ICCV 2015.<br></td>
   </tr>
   <tr>
    <td class="results">151</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=73a6fff5a9ea04b49c942eadfb48c8c01171a80a">PBCP</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">13.40 %</td>
     <td class="results">16.75 %</td>
     <td class="results">  3.1 px</td>
     <td class="results">  4.2 px</td>
     <td class="results">68 s</td>
     <td class="results">Nvidia GTX Titan X</td>
     <td class="results"><input type="checkbox" value="73a6fff5a9ea04b49c942eadfb48c8c01171a80a" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">A. Seki and M. Pollefeys: <a href="http://scholar.google.de/scholar?q=Patch%20Based%20Confidence%20Prediction%20for%20Dense%20Disparity%20Map"> Patch Based Confidence Prediction for 
Dense Disparity Map</a>. British Machine Vision Conference 
(BMVC) 2016.<br></td>
   </tr>
   <tr>
    <td class="results">152</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=5562463411f3017c42551f9b39fa88bcf4bed21c">CBMV</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/kbatsos/CBMV" target="blank">code</a></td>
     <td class="results">13.61 %</td>
     <td class="results">17.01 %</td>
     <td class="results">  3.7 px</td>
     <td class="results">  4.4 px</td>
     <td class="results">250 s</td>
     <td class="results">6 cores@3.0Ghz(Python,C/C++,CUDA TitanX)</td>
     <td class="results"><input type="checkbox" value="5562463411f3017c42551f9b39fa88bcf4bed21c" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">K. Batsos, C. Cai and P. Mordohai: <a href="http://scholar.google.de/scholar?q=CBMV:%20A%20Coalesced%20Bidirectional%20Matching%20Volume%20for%20Disparity%20Estimation"> CBMV: A Coalesced Bidirectional Matching 
Volume for Disparity Estimation</a>. 2018.<br></td>
   </tr>
   <tr>
    <td class="results">153</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=47e636953a6a22c5e04c4aa3e51cf241f2abd9b0">SMCM</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">13.64 %</td>
     <td class="results">17.93 %</td>
     <td class="results">  2.8 px</td>
     <td class="results">  4.8 px</td>
     <td class="results">1800 s</td>
     <td class="results">Nvidia GTX 1080 (Caffe)</td>
     <td class="results"><input type="checkbox" value="47e636953a6a22c5e04c4aa3e51cf241f2abd9b0" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">M. Yang, Y. Liu, Y. Cai and Z. You: <a href="http://scholar.google.de/scholar?q=Stereo%20matching%20based%20on%20classification%20of%20materials"> Stereo matching based on classification of 
materials</a>. Neurocomputing 2016.<br></td>
   </tr>
   <tr>
    <td class="results">154</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=c1648f879a5613888271930c8c3d218db849b9b4">MC-CNN-acrt</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/jzbontar/mc-cnn" target="blank">code</a></td>
     <td class="results">13.76 %</td>
     <td class="results">17.17 %</td>
     <td class="results">  3.2 px</td>
     <td class="results">  4.1 px</td>
     <td class="results">67 s</td>
     <td class="results">Nvidia GTX Titan X (CUDA, Lua/Torch7)</td>
     <td class="results"><input type="checkbox" value="c1648f879a5613888271930c8c3d218db849b9b4" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">J. Zbontar and Y. LeCun: <a href="http://scholar.google.de/scholar?q=Stereo%20Matching%20by%20Training%20a%20Convolutional%20Neural%20Network%20to%20Compare%20Image%20Patches"> Stereo Matching by Training a Convolutional 
Neural Network to Compare Image Patches</a>. Submitted to JMLR .<br></td>
   </tr>
   <tr>
    <td class="results">155</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=681e21fb266154ab96083fdeba7d4b201d796e15">CKDNet_naïve</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">13.82 %</td>
     <td class="results">16.53 %</td>
     <td class="results">  2.9 px</td>
     <td class="results">  3.4 px</td>
     <td class="results">0.01 s</td>
     <td class="results">AGX @ 32TOPs python</td>
     <td class="results"><input type="checkbox" value="681e21fb266154ab96083fdeba7d4b201d796e15" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">156</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=9a2e4dfdc9d8e3edeb183996d1fab8ee48af5c93">MC-CNN-WS</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/tlkvstepan/mc-cnn-ws" target="blank">code</a></td>
     <td class="results">14.12 %</td>
     <td class="results">17.77 %</td>
     <td class="results">  3.1 px</td>
     <td class="results">  3.8 px</td>
     <td class="results">1.35 s</td>
     <td class="results">1 core 2.5 Ghz + K40 NVIDIA, Lua-Torch</td>
     <td class="results"><input type="checkbox" value="9a2e4dfdc9d8e3edeb183996d1fab8ee48af5c93" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">S. Tulyakov, A. Ivanov and F. Fleuret: <a href="http://scholar.google.de/scholar?q=Weakly%20supervised%20learning%20of%20deep%20metrics%20for%20stereo%20reconstruction"> Weakly supervised learning of deep 
metrics for stereo reconstruction</a>. ICCV 2017.<br></td>
   </tr>
   <tr>
    <td class="results">157</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=c7c0efefce88a16d81a48110256a8a30f01bebec">StereoSLIC</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">14.32 %</td>
     <td class="results">17.59 %</td>
     <td class="results">  2.8 px</td>
     <td class="results">  3.6 px</td>
     <td class="results">2.3 s</td>
     <td class="results">1 core @ 3.0 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="c7c0efefce88a16d81a48110256a8a30f01bebec" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">K. Yamaguchi, D. McAllester and R. Urtasun: <a href="http://scholar.google.de/scholar?q=Robust%20Monocular%20Epipolar%20Flow%20Estimation"> Robust Monocular Epipolar Flow Estimation</a>. CVPR 2013.<br></td>
   </tr>
   <tr>
    <td class="results">158</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=61c7ff9a8edf7f4d8f67764468b14e636c8e6a22">PR-Sf+E</a></td>
     <td class="results"><div class="icon"><img src="./KITTI2012Reflective_files/icon_fl.png" alt="This method uses optical flow information."></div></td>
     <td class="results"></td>
     <td class="results">14.45 %</td>
     <td class="results">17.28 %</td>
     <td class="results">  3.3 px</td>
     <td class="results">  4.0 px</td>
     <td class="results">200 s</td>
     <td class="results">4 cores @ 3.0 Ghz (Matlab + C/C++)</td>
     <td class="results"><input type="checkbox" value="61c7ff9a8edf7f4d8f67764468b14e636c8e6a22" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">C. Vogel, K. Schindler and S. Roth: <a href="http://scholar.google.de/scholar?q=Piecewise%20Rigid%20Scene%20Flow"> Piecewise Rigid Scene Flow</a>. International Conference on Computer 
Vision (ICCV) 2013.<br></td>
   </tr>
   <tr>
    <td class="results">159</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=42f2afcf02732d8888e9b9e0462e786a9f4173fd">MC-CNN</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">14.93 %</td>
     <td class="results">18.22 %</td>
     <td class="results">  3.5 px</td>
     <td class="results">  4.3 px</td>
     <td class="results">100 s</td>
     <td class="results">Nvidia GTX Titan (CUDA, Lua/Torch7)</td>
     <td class="results"><input type="checkbox" value="42f2afcf02732d8888e9b9e0462e786a9f4173fd" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">J. Zbontar and Y. LeCun: <a href="http://scholar.google.de/scholar?q=Computing%20the%20Stereo%20Matching%20Cost%20with%20a%20Convolutional%20Neural%20Network"> Computing the Stereo Matching Cost with a 
Convolutional Neural Network</a>. Conference on Computer Vision and 
Pattern Recognition (CVPR) 2015.<br></td>
   </tr>
   <tr>
    <td class="results">160</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=be57b1d4eb443df6716245bdc19a56426c86dc33">pSGM</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">14.96 %</td>
     <td class="results">18.98 %</td>
     <td class="results">  3.3 px</td>
     <td class="results">  5.7 px</td>
     <td class="results">7.92 s</td>
     <td class="results">4 cores @ 3.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="be57b1d4eb443df6716245bdc19a56426c86dc33" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Y. Lee, M. Park, Y. Hwang, Y. Shin and C. Kyung: <a href="http://scholar.google.de/scholar?q=Memory-Efficient%20Parametric%20Semiglobal%20Matching"> Memory-Efficient Parametric Semiglobal 
Matching</a>. IEEE Signal Processing Letters 2018.<br></td>
   </tr>
   <tr>
    <td class="results">161</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=fc26d17ac1ed7b256d8c4696cdce80b6e09a9866">TCD-CRF</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">14.98 %</td>
     <td class="results">19.36 %</td>
     <td class="results">  3.3 px</td>
     <td class="results">  6.6 px</td>
     <td class="results">60 s</td>
     <td class="results">4 cores @ 3.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="fc26d17ac1ed7b256d8c4696cdce80b6e09a9866" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">S. Arjomand Bigdeli, G. Budweiser and M. Zwicker: <a href="http://scholar.google.de/scholar?q=Temporally%20Coherent%20Disparity%20Maps%20Using%20CRFs%20with%20Fast%204D%20Filtering"> Temporally Coherent Disparity Maps Using CRFs with Fast 4D Filtering</a>. Proc. ACPR 2015.<br></td>
   </tr>
   <tr>
    <td class="results">162</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=e0e3ea2c6003cfac18d24e815efbf12f95bb377a">DLP</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">15.26 %</td>
     <td class="results">19.42 %</td>
     <td class="results">  3.2 px</td>
     <td class="results">  5.9 px</td>
     <td class="results">60 s</td>
     <td class="results">8 cores @ &gt;3.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="e0e3ea2c6003cfac18d24e815efbf12f95bb377a" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">V. Nguyen, H. Nguyen and J. Jeon: <a href="http://scholar.google.de/scholar?q=Robust%20Stereo%20Data%20Cost%20With%20a%20Learning%20Strategy"> Robust Stereo Data Cost With a Learning 
Strategy</a>. IEEE Transactions on Intelligent 
Transportation Systems 2017.<br></td>
   </tr>
   <tr>
    <td class="results">163</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=c9723929db2d16a16d99355eebc859a3e13f255e">Content-CNN</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">15.53 %</td>
     <td class="results">18.91 %</td>
     <td class="results">  3.6 px</td>
     <td class="results">  4.2 px</td>
     <td class="results">0.7 s</td>
     <td class="results">Nvidia GTX Titan X (Torch)</td>
     <td class="results"><input type="checkbox" value="c9723929db2d16a16d99355eebc859a3e13f255e" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">W. Luo, A. Schwing and R. Urtasun: <a href="http://scholar.google.de/scholar?q=Efficient%20Deep%20Learning%20for%20Stereo%20Matching"> Efficient Deep Learning for Stereo Matching</a>. CVPR 2016.<br></td>
   </tr>
   <tr>
    <td class="results">164</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=a9b886fc740cc0dbfbcfaaba44f0c8ad2cb6a06d">PR-Sceneflow</a></td>
     <td class="results"><div class="icon"><img src="./KITTI2012Reflective_files/icon_fl.png" alt="This method uses optical flow information."></div></td>
     <td class="results"></td>
     <td class="results">15.59 %</td>
     <td class="results">18.28 %</td>
     <td class="results">  3.3 px</td>
     <td class="results">  4.0 px</td>
     <td class="results">150 sec</td>
     <td class="results">4 core @ 3.0 Ghz (Matlab - C/C++)</td>
     <td class="results"><input type="checkbox" value="a9b886fc740cc0dbfbcfaaba44f0c8ad2cb6a06d" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">C. Vogel, K. Schindler and S. Roth: <a href="http://scholar.google.de/scholar?q=Piecewise%20Rigid%20Scene%20Flow"> Piecewise Rigid Scene Flow</a>. International Conference on Computer 
Vision (ICCV) 2013.<br></td>
   </tr>
   <tr>
    <td class="results">165</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=0f852fcb57f48fe730be25541e42d014db8ab96d">CRD-Fusion</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/fanxiule/CRD_Fusion" target="blank">code</a></td>
     <td class="results">15.65 %</td>
     <td class="results">18.41 %</td>
     <td class="results">  2.9 px</td>
     <td class="results">  3.5 px</td>
     <td class="results">0.02 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="0f852fcb57f48fe730be25541e42d014db8ab96d" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">X. Fan, S. Jeon and B. Fidan: <a href="http://scholar.google.de/scholar?q=Occlusion-Aware%20Self-Supervised%20Stereo%20Matching%20with%20Confidence%20Guided%20Raw%20Disparity%20Fusion"> Occlusion-Aware Self-Supervised Stereo 
Matching with Confidence Guided Raw Disparity 
Fusion</a>. Conference on Robots and Vision 2022.<br></td>
   </tr>
   <tr>
    <td class="results">166</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=ab1b0720066dc47097a378b7c259449738ed0d60">AAFS+</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">15.76 %</td>
     <td class="results">17.70 %</td>
     <td class="results">  3.0 px</td>
     <td class="results">  3.2 px</td>
     <td class="results">0.01 s</td>
     <td class="results">1 core @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="ab1b0720066dc47097a378b7c259449738ed0d60" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">167</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=a4df3232e499b6e4a2347715356aebde8e40ebc1">MBM</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">16.38 %</td>
     <td class="results">19.53 %</td>
     <td class="results">  3.6 px</td>
     <td class="results">  4.3 px</td>
     <td class="results">0.2 s</td>
     <td class="results">1 core @ 3.0 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="a4df3232e499b6e4a2347715356aebde8e40ebc1" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">N. Einecke and J. Eggert: <a href="http://scholar.google.de/scholar?q=A%20Multi-Block-Matching%20Approach%20for%20Stereo"> A Multi-Block-Matching Approach for Stereo</a>. IV 2015.<br></td>
   </tr>
   <tr>
    <td class="results">168</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=a523730d5b45571628b40ea777233986a8ba137a">CoR-Conf</a></td>
     <td class="results"></td>
     <td class="results"><a href="http://www.ttic.edu/chakrabarti/consensus/" target="blank">code</a></td>
     <td class="results">16.59 %</td>
     <td class="results">20.08 %</td>
     <td class="results">  4.0 px</td>
     <td class="results">  5.4 px</td>
     <td class="results">6 s</td>
     <td class="results">6 cores @ 3.3 Ghz (Matlab + C/C++)</td>
     <td class="results"><input type="checkbox" value="a523730d5b45571628b40ea777233986a8ba137a" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">A. Chakrabarti, Y. Xiong, S. Gortler and T. Zickler: <a href="http://scholar.google.de/scholar?q=Low-level%20Vision%20by%20Consensus%20in%20a%20Spatial%20Hierarchy%20of%20Regions"> Low-level Vision by Consensus in a Spatial 
Hierarchy of Regions</a>. CVPR 2015.<br></td>
   </tr>
   <tr>
    <td class="results">169</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=8f73bd76469b5f1b4676e3e5f60a7dd6978a2645">UHP</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">16.67 %</td>
     <td class="results">19.67 %</td>
     <td class="results">  2.9 px</td>
     <td class="results">  3.7 px</td>
     <td class="results">0.02 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="8f73bd76469b5f1b4676e3e5f60a7dd6978a2645" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">170</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=a314d3f4db80a52ea4912142d87ff0fc80783b67">SGM-post</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">16.96 %</td>
     <td class="results">19.78 %</td>
     <td class="results">  3.3 px</td>
     <td class="results">  3.8 px</td>
     <td class="results">5 s</td>
     <td class="results">4 cores @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="a314d3f4db80a52ea4912142d87ff0fc80783b67" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Z. Zhong: <a href="http://scholar.google.de/scholar?q=Efficient%20Learning%20based%20Semi-Global%20Stereo%20Matching"> Efficient Learning based Semi-Global Stereo 
Matching</a>. 2015 submitted.<br></td>
   </tr>
   <tr>
    <td class="results">171</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=4262edfc6c4ea42a2b8d86e2c9a7102f48224167">Flow2Stereo</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">16.96 %</td>
     <td class="results">18.84 %</td>
     <td class="results">  2.8 px</td>
     <td class="results">  3.1 px</td>
     <td class="results">0.05 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="4262edfc6c4ea42a2b8d86e2c9a7102f48224167" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">P. Liu, I. King, M. Lyu and J. Xu: <a href="http://scholar.google.de/scholar?q=Flow2Stereo:%20Effective%20Self-Supervised%20Learning%20of%20Optical%20Flow%20and%20Stereo%20Matching"> Flow2Stereo: Effective Self-Supervised 
Learning of Optical Flow and Stereo Matching</a>. CVPR 2020.<br></td>
   </tr>
   <tr>
    <td class="results">172</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=28cee436ba42c61f617725692ddefef26eb34335">SepStereo</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">17.08 %</td>
     <td class="results">19.18 %</td>
     <td class="results">  3.2 px</td>
     <td class="results">  3.6 px</td>
     <td class="results">0.087s</td>
     <td class="results">GPU @ 2.0 Ghz (Pyhton)</td>
     <td class="results"><input type="checkbox" value="28cee436ba42c61f617725692ddefef26eb34335" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">173</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=4c8aa9ba940e4255300eb6114c9777b3066b22e1">CAT</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">17.38 %</td>
     <td class="results">20.46 %</td>
     <td class="results">  3.3 px</td>
     <td class="results">  4.3 px</td>
     <td class="results">10 s</td>
     <td class="results">1 core @ 3.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="4c8aa9ba940e4255300eb6114c9777b3066b22e1" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">J. Ha, J. Jeon, G. Bae, S. Jo and H. Jeong: <a href="http://scholar.google.de/scholar?q=Cost%20Aggregation%20Table:%20Cost%20Aggregation%20Method%20Using%20Summed%20Area%20Table%20Scheme%20for%20Dense%20Stereo%20Correspondence"> Cost Aggregation Table: Cost Aggregation Method Using Summed Area Table Scheme for Dense Stereo Correspondence</a>. Advances in Visual Computing 2014.<br></td>
   </tr>
   <tr>
    <td class="results">174</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=770aca82d7507aaf6a67ab51cdd79c9010e288ce">RBM</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">17.90 %</td>
     <td class="results">20.65 %</td>
     <td class="results">  3.6 px</td>
     <td class="results">  4.0 px</td>
     <td class="results">0.2 s</td>
     <td class="results">1 core @ 3.0 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="770aca82d7507aaf6a67ab51cdd79c9010e288ce" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">N. Einecke and J. Eggert: <a href="http://scholar.google.de/scholar?q=Block-Matching%20Stereo%20with%20Relaxed%20Fronto-Parallel%20Assumption"> Block-Matching Stereo with Relaxed Fronto-Parallel Assumption</a>. IV 2014.<br></td>
   </tr>
   <tr>
    <td class="results">175</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=00c53eb7f5c0f5c900760ba8722420c79db558a8">AARBM</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">18.24 %</td>
     <td class="results">21.00 %</td>
     <td class="results">  3.7 px</td>
     <td class="results">  4.2 px</td>
     <td class="results">0.25 s</td>
     <td class="results">1 core @ 3.0 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="00c53eb7f5c0f5c900760ba8722420c79db558a8" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">N. Einecke and J. Eggert: <a href="http://scholar.google.de/scholar?q=Block-Matching%20Stereo%20with%20Relaxed%20Fronto-Parallel%20Assumption"> Block-Matching Stereo with Relaxed Fronto-Parallel Assumption</a>. IV 2014.<br></td>
   </tr>
   <tr>
    <td class="results">176</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=4525302406d13234fd5a61fd89ee5ddab5eb3a66">Ensemble</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">18.28 %</td>
     <td class="results">21.95 %</td>
     <td class="results">  4.5 px</td>
     <td class="results">  6.9 px</td>
     <td class="results">135 s</td>
     <td class="results">2 cores @ &gt;3.5 Ghz (Matlab)</td>
     <td class="results"><input type="checkbox" value="4525302406d13234fd5a61fd89ee5ddab5eb3a66" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">A. Spyropoulos and P. Mordohai: <a href="http://scholar.google.de/scholar?q=Ensemble%20Classifier%20for%20Combining%20Stereo%20Matching%20Algorithms"> Ensemble Classifier for Combining Stereo 
Matching Algorithms</a>. International Conference on 3D Vision 
(3DV) 2015.<br></td>
   </tr>
   <tr>
    <td class="results">177</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=2fe35076d6f5065dd3da734f87e366f98320729d">SNCC</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">18.36 %</td>
     <td class="results">21.16 %</td>
     <td class="results">  3.7 px</td>
     <td class="results">  4.2 px</td>
     <td class="results">0.11 s</td>
     <td class="results">1 core @ 3.1 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="2fe35076d6f5065dd3da734f87e366f98320729d" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">N. Einecke and J. Eggert: <a href="http://scholar.google.de/scholar?q=A%20Two-Stage%20Correlation%20Method%20for%20Stereoscopic%20Depth%20Estimation"> A Two-Stage Correlation Method for Stereoscopic Depth Estimation</a>. DICTA 2010.<br></td>
   </tr>
   <tr>
    <td class="results">178</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=a7b77e8fddfa90949754d01a1d09b6d8bbabdbb7">ATGV</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">18.43 %</td>
     <td class="results">22.49 %</td>
     <td class="results">  3.3 px</td>
     <td class="results">  5.3 px</td>
     <td class="results">6 min</td>
     <td class="results">&gt;8 cores @ 3.0 Ghz (Matlab + C/C++)</td>
     <td class="results"><input type="checkbox" value="a7b77e8fddfa90949754d01a1d09b6d8bbabdbb7" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">R. Ranftl, T. Pock and H. Bischof: <a href="http://scholar.google.de/scholar?q=Minimizing%20TGV-based%20Variational%20Models%20with%20Non-Convex%20Data%20terms"> Minimizing TGV-based Variational Models with Non-Convex Data terms</a>. ICSSVM 2013.<br></td>
   </tr>
   <tr>
    <td class="results">179</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=e7c7502262a3ed73cd55231e3299f99b2c752309">CSPMS</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">18.59 %</td>
     <td class="results">22.41 %</td>
     <td class="results">  4.5 px</td>
     <td class="results">  6.0 px</td>
     <td class="results">6 s</td>
     <td class="results">4 cores @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="e7c7502262a3ed73cd55231e3299f99b2c752309" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">J. Cho and M. Humenberger: <a href="http://scholar.google.de/scholar?q=Fast%20PatchMatch%20Stereo%20Matching%20Using%20Multi-Scale%20Cost%20Fusion%20for%20Automotive%20Applications"> Fast PatchMatch Stereo 
Matching Using Multi-Scale Cost Fusion for 
Automotive Applications</a>. IV 2015.<br></td>
   </tr>
   <tr>
    <td class="results">180</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=822c33e35a5cd08ce56b10cc83ce38593988fec4">AABM</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">18.65 %</td>
     <td class="results">21.45 %</td>
     <td class="results">  3.8 px</td>
     <td class="results">  4.4 px</td>
     <td class="results">0.12 s</td>
     <td class="results">1 core @ 3.1 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="822c33e35a5cd08ce56b10cc83ce38593988fec4" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">N. Einecke and J. Eggert: <a href="http://scholar.google.de/scholar?q=Stereo%20Image%20Warping%20for%20Improved%20Depth%20Estimation%20of%20Road%20Surfaces"> Stereo Image Warping for Improved Depth Estimation of Road Surfaces</a>. IV 2013.<br></td>
   </tr>
   <tr>
    <td class="results">181</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=3abee17f5a7125de4c49ff1ea809e022fd45c33b">ALTGV</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">18.86 %</td>
     <td class="results">22.19 %</td>
     <td class="results">  3.4 px</td>
     <td class="results">  4.2 px</td>
     <td class="results">20 s</td>
     <td class="results">GPU @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="3abee17f5a7125de4c49ff1ea809e022fd45c33b" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">G. Kuschk and D. Cremers: <a href="http://scholar.google.de/scholar?q=Fast%20and%20Accurate%20Large-scale%20Stereo%20Reconstruction%20using%20Variational%20Methods"> Fast and Accurate Large-scale Stereo Reconstruction using Variational Methods</a>. ICCV Workshop on Big Data in 3D Computer Vision 2013.<br></td>
   </tr>
   <tr>
    <td class="results">182</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=6b7f7c7b31f501a7f613ca5a9050e711f8f73e4c">AAFS</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">19.01 %</td>
     <td class="results">21.31 %</td>
     <td class="results">  3.3 px</td>
     <td class="results">  3.8 px</td>
     <td class="results">0.01 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="6b7f7c7b31f501a7f613ca5a9050e711f8f73e4c" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">J. Chang, P. Chang and Y. Chen: <a href="http://scholar.google.de/scholar?q=Attention-Aware%20Feature%20Aggregation%20for%20Real-time%20Stereo%20Matching%20on%20Edge%20Devices"> Attention-Aware Feature Aggregation for 
Real-time Stereo Matching on Edge Devices</a>. Proceedings of the Asian Conference 
on Computer Vision 2020.<br></td>
   </tr>
   <tr>
    <td class="results">183</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=8ce7fb7c240e60507df1f31e4d82f57dab65ee82">ITGV</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">19.05 %</td>
     <td class="results">22.52 %</td>
     <td class="results">  4.9 px</td>
     <td class="results">  5.8 px</td>
     <td class="results">7 s</td>
     <td class="results">1 core @ 3.0 Ghz (Matlab + C/C++)</td>
     <td class="results"><input type="checkbox" value="8ce7fb7c240e60507df1f31e4d82f57dab65ee82" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">R. Ranftl, S. Gehrig, T. Pock and H. Bischof: <a href="http://scholar.google.de/scholar?q=Pushing%20the%20Limits%20of%20Stereo%20Using%20Variational%20Stereo%20Estimation"> Pushing the Limits of Stereo Using Variational Stereo Estimation</a>. IV 2012.<br></td>
   </tr>
   <tr>
    <td class="results">184</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=0d77446194f3c3a2da39ad4af3eee98ddf1935f9">PASMNet_192</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/The-Learning-And-Vision-Atelier-LAVA/PAM/blob/master/PASMnet" target="blank">code</a></td>
     <td class="results">19.29 %</td>
     <td class="results">23.21 %</td>
     <td class="results">  4.5 px</td>
     <td class="results">  5.7 px</td>
     <td class="results">0.06 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="0d77446194f3c3a2da39ad4af3eee98ddf1935f9" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">185</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=15430b649d2c09de379d20e2dddec3c282e634c4">DispSegNet</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">20.15 %</td>
     <td class="results">22.96 %</td>
     <td class="results">  3.7 px</td>
     <td class="results">  4.2 px</td>
     <td class="results">0.9 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="15430b649d2c09de379d20e2dddec3c282e634c4" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">J. Zhang, K. Skinner, R. Vasudevan and M. Johnson-Roberson: <a href="http://scholar.google.de/scholar?q=DispSegNet:%20Leveraging%20Semantics%20for%20End-to-End%20Learning%20of%20Disparity%20Estimation%20From%20Stereo%20Imagery"> DispSegNet: Leveraging Semantics for End-
to-End Learning of Disparity Estimation From 
Stereo Imagery</a>. IEEE Robotics and Automation Letters 2019.<br></td>
   </tr>
   <tr>
    <td class="results">186</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=52bcdee0002e5d25ffa72661b8ffa486348eb41a">ARW</a></td>
     <td class="results"></td>
     <td class="results"><a href="http://www.mathworks.com/matlabcentral/fileexchange/49501-stereo-matching-using-adaptive-random-walk" target="blank">code</a></td>
     <td class="results">20.17 %</td>
     <td class="results">23.92 %</td>
     <td class="results">  5.2 px</td>
     <td class="results">  6.8 px</td>
     <td class="results">4.6s</td>
     <td class="results">1 core @ 3.5 Ghz (MATLAB+C/C++)</td>
     <td class="results"><input type="checkbox" value="52bcdee0002e5d25ffa72661b8ffa486348eb41a" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">S. Lee, J. Lee, J. Lim and I. Suh: <a href="http://scholar.google.de/scholar?q=Robust%20Stereo%20Matching%20using%20Adaptive%20Random%20Walk%20with%20Restart%20Algorithm"> Robust Stereo Matching using Adaptive Random 
Walk with Restart Algorithm</a>. Image and vision computing (accepted) 2015.<br></td>
   </tr>
   <tr>
    <td class="results">187</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=c01cb4765512cb890170c4f89ed17b5553a82ff0">iSGM</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">20.52 %</td>
     <td class="results">24.84 %</td>
     <td class="results">  4.7 px</td>
     <td class="results">  8.6 px</td>
     <td class="results">8 s</td>
     <td class="results">2 cores @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="c01cb4765512cb890170c4f89ed17b5553a82ff0" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">S. Hermann and R. Klette: <a href="http://scholar.google.de/scholar?q=Iterative%20Semi-Global%20Matching%20for%20Robust%20Driver%20Assistance%20Systems"> Iterative Semi-Global Matching for Robust Driver 
Assistance Systems</a>. ACCV 2012.<br></td>
   </tr>
   <tr>
    <td class="results">188</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=fc55ab003d7a643f2fb2a978d01c286c747b3b9c">mSGM-LDE</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">20.96 %</td>
     <td class="results">25.53 %</td>
     <td class="results">  5.5 px</td>
     <td class="results">  9.3 px</td>
     <td class="results">55 s</td>
     <td class="results">2 cores @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="fc55ab003d7a643f2fb2a978d01c286c747b3b9c" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">V. Nguyen, D. Nguyen, S. Lee and J. Jeon: <a href="http://scholar.google.de/scholar?q=Local%20Density%20Encoding%20for%20Robust%20Stereo%20Matching"> Local Density Encoding for Robust Stereo 
Matching</a>. TCSVT 2014.<br></td>
   </tr>
   <tr>
    <td class="results">189</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=c3e639d5ab83f9018bd6e92ac553b33ea7edcdb0">Permutation Stereo</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">21.96 %</td>
     <td class="results">24.90 %</td>
     <td class="results">  5.0 px</td>
     <td class="results">  5.8 px</td>
     <td class="results">30 s</td>
     <td class="results">GPU @ 2.5 Ghz (Matlab)</td>
     <td class="results"><input type="checkbox" value="c3e639d5ab83f9018bd6e92ac553b33ea7edcdb0" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">P. Brousseau and S. Roy: <a href="http://scholar.google.de/scholar?q=A%20Permutation%20Model%20for%20the%20Self-Supervised%20Stereo%20Matching%20Problem"> A Permutation Model for the Self-
Supervised Stereo Matching Problem</a>. 2022 19th Conference on Robots and 
Vision (CRV) 2022.<br></td>
   </tr>
   <tr>
    <td class="results">190</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=96b487cbd205f068c843c97e2cec068d59abaa11">wSGM</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">22.07 %</td>
     <td class="results">25.17 %</td>
     <td class="results">  8.0 px</td>
     <td class="results">  9.0 px</td>
     <td class="results">6s</td>
     <td class="results">1 core @ 3.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="96b487cbd205f068c843c97e2cec068d59abaa11" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">R. Spangenberg, T. Langner and R. Rojas: <a href="http://scholar.google.de/scholar?q=Weighted%20Semi-Global%20Matching%20and%20Center-Symmetric%20Census%20Transform%20for%20Robust%20Driver%20Assistance"> Weighted Semi-Global Matching and Center-Symmetric Census Transform for Robust Driver Assistance</a>. CAIP 2013.<br></td>
   </tr>
   <tr>
    <td class="results">191</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=6c71a4d2fbd680002635ec369be413d512e7b3e5">ELAS</a></td>
     <td class="results"></td>
     <td class="results"><a href="http://www.cvlibs.net/software/libelas" target="blank">code</a></td>
     <td class="results">22.49 %</td>
     <td class="results">26.13 %</td>
     <td class="results">  5.4 px</td>
     <td class="results">  6.3 px</td>
     <td class="results">0.3 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="6c71a4d2fbd680002635ec369be413d512e7b3e5" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">A. Geiger, M. Roser and R. Urtasun: <a href="http://scholar.google.de/scholar?q=Efficient%20Large-Scale%20Stereo%20Matching"> Efficient Large-Scale Stereo Matching</a>. ACCV 2010.<br></td>
   </tr>
   <tr>
    <td class="results">192</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=61d76414e24e27d1e8af684f2ee1bf4bc0aa7fa2">S+GF (Cen)</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/rookiepig/CrossScaleStereo" target="blank">code</a></td>
     <td class="results">22.58 %</td>
     <td class="results">27.10 %</td>
     <td class="results">  5.6 px</td>
     <td class="results"> 10.1 px</td>
     <td class="results">140 s</td>
     <td class="results">1 core @ 3.0 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="61d76414e24e27d1e8af684f2ee1bf4bc0aa7fa2" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">K. Zhang, Y. Fang, D. Min, L. Sun, S. Yang, S. Yan and Q. Tian: <a href="http://scholar.google.de/scholar?q=Cross-Scale%20Cost%20Aggregation%20for%20Stereo%20Matching"> Cross-Scale Cost Aggregation 
for Stereo Matching</a>. CVPR 2014.<br></td>
   </tr>
   <tr>
    <td class="results">193</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=de6f3c4cf16e21aa3ed7f0cbb5827dc537c55b0e">linBP</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">23.00 %</td>
     <td class="results">27.42 %</td>
     <td class="results">  5.9 px</td>
     <td class="results">  9.6 px</td>
     <td class="results">1.6 min</td>
     <td class="results">1 core @ 3.0 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="de6f3c4cf16e21aa3ed7f0cbb5827dc537c55b0e" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">W. Khan, V. Suaste, D. Caudillo and R. Klette: <a href="http://scholar.google.de/scholar?q=Belief%20Propagation%20Stereo%20Matching%20Compared%20to%20iSGM%20on%20Binocular%20or%20Trinocular%20Video%20Data"> Belief Propagation Stereo Matching 
Compared to iSGM on Binocular or Trinocular Video 
Data</a>. IV 2013.<br></td>
   </tr>
   <tr>
    <td class="results">194</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=070da51ada34368eebff0417f6295b314209f582">Toast2</a></td>
     <td class="results"><div class="icon"><img src="./KITTI2012Reflective_files/icon_st.png" alt="This method uses stereo information."></div></td>
     <td class="results"></td>
     <td class="results">23.11 %</td>
     <td class="results">26.12 %</td>
     <td class="results">  5.0 px</td>
     <td class="results">  5.7 px</td>
     <td class="results">0.03 s</td>
     <td class="results">4 cores @ 3.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="070da51ada34368eebff0417f6295b314209f582" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">B. Ranft and T. Strau\ss: <a href="http://scholar.google.de/scholar?q=Modeling%20Arbitrarily%20Oriented%20Slanted%20Planes%20for%20Efficient%20Stereo%20Vision%20based%20on%20Block%20Matching"> Modeling Arbitrarily Oriented Slanted 
Planes for Efficient Stereo Vision based on Block 
Matching</a>. Intelligent Transportation Systems 
(ITSC), 2014 IEEE 17th International Conference 
on 2014.<br></td>
   </tr>
   <tr>
    <td class="results">195</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=ee9afd8390ee34f0ff21a4595cf41f3fb113a070">rSGM</a></td>
     <td class="results"></td>
     <td class="results"><a href="http://userpage.fu-berlin.de/spangenb/" target="blank">code</a></td>
     <td class="results">23.20 %</td>
     <td class="results">26.71 %</td>
     <td class="results">  6.7 px</td>
     <td class="results">  7.9 px</td>
     <td class="results">0.2 s</td>
     <td class="results">4 cores @ 2.6 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="ee9afd8390ee34f0ff21a4595cf41f3fb113a070" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">R. Spangenberg, T. Langner, S. Adfeldt and R. Rojas: <a href="http://scholar.google.de/scholar?q=Large%20Scale%20Semi-Global%20Matching%20on%20the%20CPU"> Large Scale Semi-Global Matching on the CPU</a>. IV 2014.<br></td>
   </tr>
   <tr>
    <td class="results">196</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=c12cb5d53c35f555318ba782aa80ace136204cdd">SGM</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">23.22 %</td>
     <td class="results">26.03 %</td>
     <td class="results">  5.1 px</td>
     <td class="results">  5.8 px</td>
     <td class="results">3.7 s</td>
     <td class="results">1 core @ 3.0 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="c12cb5d53c35f555318ba782aa80ace136204cdd" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">H. Hirschmueller: <a href="http://scholar.google.de/scholar?q=Stereo%20Processing%20by%20Semi-Global%20Matching%20and%20Mutual%20Information"> Stereo Processing by Semi-Global Matching and Mutual Information</a>. PAMI 2008.<br></td>
   </tr>
   <tr>
    <td class="results">197</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=862a0bac33fd0865d8dbe3e345bf609d9b9ae148">SSMW</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">23.53 %</td>
     <td class="results">26.59 %</td>
     <td class="results">  5.2 px</td>
     <td class="results">  6.2 px</td>
     <td class="results">2.5 min</td>
     <td class="results">8 cores @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="862a0bac33fd0865d8dbe3e345bf609d9b9ae148" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">X. Li, J. Liu, G. Chen and H. Fu: <a href="http://scholar.google.de/scholar?q=Efficient%20Methods%20Using%20Slanted%20Support%20Windows%20for%20Slanted%20Surfaces"> Efficient Methods Using Slanted 
Support Windows for Slanted Surfaces</a>. IET Computer Vision, 
http://ietdl.org/t/5QsTxb 2016.<br></td>
   </tr>
   <tr>
    <td class="results">198</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=afa8706f2e86134b65568fd0d5600c46dd4f05c7">OASM-Net</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">23.79 %</td>
     <td class="results">28.18 %</td>
     <td class="results">  4.6 px</td>
     <td class="results">  7.3 px</td>
     <td class="results">0.73 s</td>
     <td class="results">GPU @ 2.5 Ghz (Python)</td>
     <td class="results"><input type="checkbox" value="afa8706f2e86134b65568fd0d5600c46dd4f05c7" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">A. Li and Z. Yuan: <a href="http://scholar.google.de/scholar?q=Occlusion%20Aware%20Stereo%20Matching%20via%20Cooperative%20Unsupervised%20Learning"> Occlusion Aware Stereo Matching via Cooperative Unsupervised Learning</a>. Proceedings of the Asian Conference on Computer Vision, ACCV 2018.<br></td>
   </tr>
   <tr>
    <td class="results">199</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=d65ba0e7bc08408ac5c2d7c878a2193f4a7ca783">HSMA</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">24.04 %</td>
     <td class="results">28.43 %</td>
     <td class="results">  5.6 px</td>
     <td class="results">  9.3 px</td>
     <td class="results">44s</td>
     <td class="results">1 core @ 3.0 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="d65ba0e7bc08408ac5c2d7c878a2193f4a7ca783" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">O. Zeglazi, M. Rziza, A. Amine and C. Demonceaux: <a href="http://scholar.google.de/scholar?q=A%20hierarchical%20stereo%20matching%20algorithm%20based%20on%20adaptive%20support%20region%20aggregation%20method"> A hierarchical stereo matching 
algorithm 
based on adaptive support region aggregation 
method</a>. Pattern Recognition Letters 2018.<br></td>
   </tr>
   <tr>
    <td class="results">200</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=21cb9e96f79d5ea48450ace483c2a72079cd4bc9">LAMC-DSΜ</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">24.72 %</td>
     <td class="results">28.38 %</td>
     <td class="results">  5.1 px</td>
     <td class="results">  8.0 px</td>
     <td class="results">10.8 min</td>
     <td class="results">2 cores @ 2.5 Ghz (Matlab)</td>
     <td class="results"><input type="checkbox" value="21cb9e96f79d5ea48450ace483c2a72079cd4bc9" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">C. Stentoumis, L. Grammatikopoulos, I. Kalisperakis, E. Petsa and G. Karras: <a href="http://scholar.google.de/scholar?q=A%20local%20adaptive%20approach%20for%20dense%20stereo%20matching%20in%20architectural%20scene%20reconstruction"> A local adaptive approach for dense stereo matching in architectural scene reconstruction</a>. ISPRS 2013.<br></td>
   </tr>
   <tr>
    <td class="results">201</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=14718804009e850bce54567a8724810944b5fdd3">GF (Census)</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/rookiepig/CrossScaleStereo" target="blank">code</a></td>
     <td class="results">26.71 %</td>
     <td class="results">30.99 %</td>
     <td class="results">  8.8 px</td>
     <td class="results"> 12.9 px</td>
     <td class="results">120 s</td>
     <td class="results">1 core @ 3.0 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="14718804009e850bce54567a8724810944b5fdd3" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">A. Hosni, C. Rhemann, M. Bleyer, C. Rother and M. Gelautz: <a href="http://scholar.google.de/scholar?q=Fast%20Cost-Volume%20Filtering%20for%20Visual%20Correspondence%20and%20Beyond"> Fast Cost-Volume Filtering 
for Visual Correspondence and Beyond</a>. TPAMI 2013.<br>K. Zhang, Y. Fang, D. Min, L. Sun, S. Yang, S. Yan and Q. Tian: <a href="http://scholar.google.de/scholar?q=Cross-Scale%20Cost%20Aggregation%20for%20Stereo%20Matching"> Cross-Scale Cost Aggregation 
for Stereo Matching</a>. CVPR 2014.<br></td>
   </tr>
   <tr>
    <td class="results">202</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=19b312c72b6d5b5ff9d9a920b177c3b7fe20ccda">Deep-Raw</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">27.70 %</td>
     <td class="results">31.87 %</td>
     <td class="results">  9.8 px</td>
     <td class="results"> 13.2 px</td>
     <td class="results">1 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="19b312c72b6d5b5ff9d9a920b177c3b7fe20ccda" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">Z. Chen, X. Sun, Y. Yu, L. Wang and C. Huang: <a href="http://scholar.google.de/scholar?q=A%20Deep%20Visual%20Correspondence%20Embedding%20Model%20for%20Stereo%20Matching%20Costs"> A Deep Visual Correspondence 
Embedding Model for Stereo Matching Costs</a>. ICCV 2015.<br></td>
   </tr>
   <tr>
    <td class="results">203</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=be71e03238a9cb91eb9d316a1f91ebb2e0eb05b6">BSM</a></td>
     <td class="results"></td>
     <td class="results"><a href="http://media.cs.tsinghua.edu.cn/~zhangkang/projects.html" target="blank">code</a></td>
     <td class="results">27.72 %</td>
     <td class="results">31.35 %</td>
     <td class="results">  7.5 px</td>
     <td class="results"> 10.3 px</td>
     <td class="results">2.5 min</td>
     <td class="results">1 core @ 3.0 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="be71e03238a9cb91eb9d316a1f91ebb2e0eb05b6" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">K. Zhang, J. Li, Y. Li, W. Hu, L. Sun and S. Yang: <a href="http://scholar.google.de/scholar?q=Binary%20stereo%20matching"> Binary stereo matching</a>. Pattern Recognition (ICPR), 2012 21st 
International Conference on 2012.<br></td>
   </tr>
   <tr>
    <td class="results">204</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=cb83355364412e13cb12f6772be9f0d611e681c7">IIW</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">28.34 %</td>
     <td class="results">31.82 %</td>
     <td class="results">  8.5 px</td>
     <td class="results"> 11.7 px</td>
     <td class="results">5.5 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="cb83355364412e13cb12f6772be9f0d611e681c7" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">A. Murarka and N. Einecke: <a href="http://scholar.google.de/scholar?q=A%20meta-technique%20for%20increasing%20density%20of%20local%20stereo%20methods%20through%20iterative%20interpolation%20and%20warping"> A meta-technique for increasing density of local stereo methods through iterative interpolation and warping</a>. Canadian Conference on Computer and Robot Vision 2014.<br></td>
   </tr>
   <tr>
    <td class="results">205</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=4ff2f8d59bda7b73b1c51507ce86ee1c1679d595">GLDS</a></td>
     <td class="results"></td>
     <td class="results"><a href="http://stereo--vision.com/" target="blank">code</a></td>
     <td class="results">28.48 %</td>
     <td class="results">31.84 %</td>
     <td class="results">  5.8 px</td>
     <td class="results">  7.5 px</td>
     <td class="results">26 s</td>
     <td class="results">GPU @ 1.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="4ff2f8d59bda7b73b1c51507ce86ee1c1679d595" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">K. Oguri and Y. Shibata: <a href="http://scholar.google.de/scholar?q=A%20new%20stereo%20formulation%20not%20using%20pixel%20and%20disparity%20models"> A new stereo formulation not using pixel and disparity 
models</a>. 2018.<br></td>
   </tr>
   <tr>
    <td class="results">206</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=f50bdd1990f33304a944e3fc36b910d9d6108583">ADSM</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">28.58 %</td>
     <td class="results">31.54 %</td>
     <td class="results">  8.4 px</td>
     <td class="results"> 10.6 px</td>
     <td class="results">125 s</td>
     <td class="results">1 core @ 2.0 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="f50bdd1990f33304a944e3fc36b910d9d6108583" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">O. Zeglazi, M. Rziza, A. Amine and C. Demonceaux: <a href="http://scholar.google.de/scholar?q=Accurate%20dense%20stereo%20matching%20for%20road%20scenes"> Accurate dense stereo matching 
for road scenes</a>. 2017 IEEE International 
Conference on Image Processing, ICIP 2017,
               Beijing, China, September 17-20, 
2017 .<br></td>
   </tr>
   <tr>
    <td class="results">207</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=726e279203c9a766f43d11e418e4ec15b33255a4">SM_GPTM</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">29.68 %</td>
     <td class="results">32.77 %</td>
     <td class="results"> 11.7 px</td>
     <td class="results"> 12.9 px</td>
     <td class="results">6.5 s</td>
     <td class="results">2 cores @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="726e279203c9a766f43d11e418e4ec15b33255a4" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">C. Cigla and A. Alatan: <a href="http://scholar.google.de/scholar?q=An%20Improved%20Stereo%20Matching%20Algorithm%20with%20Ground%20Plane%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20and%20Temporal%20Smoothness%20Constraints"> An Improved Stereo Matching Algorithm with Ground Plane
               and Temporal Smoothness Constraints</a>. ECCV Workshops 2012.<br></td>
   </tr>
   <tr>
    <td class="results">208</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=8a5f6b3461d83adb8e744974aab4876ab584b1db">SymST-GP</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">30.18 %</td>
     <td class="results">33.86 %</td>
     <td class="results"> 12.1 px</td>
     <td class="results"> 15.2 px</td>
     <td class="results">0.254 s</td>
     <td class="results">Dual - Nvidia GTX Titan  (CUDA)</td>
     <td class="results"><input type="checkbox" value="8a5f6b3461d83adb8e744974aab4876ab584b1db" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">R. Ralha, G. Falcao, J. Amaro, V. Mota, M. Antunes, J. Barreto and U. Nunes: <a href="http://scholar.google.de/scholar?q=Parallel%20refinement%20of%20slanted%203D%20reconstruction%20using%20dense%20stereo%20induced%20from%20symmetry"> Parallel refinement of slanted 3D 
reconstruction using dense stereo induced from 
symmetry</a>. Journal of Real-Time Image 
Processing 2016.<br></td>
   </tr>
   <tr>
    <td class="results">209</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=f14b1f46f8363c029642629b4c5fe9f22ba93ced">HLSC_mesh</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">31.04 %</td>
     <td class="results">34.50 %</td>
     <td class="results">  9.0 px</td>
     <td class="results"> 11.3 px</td>
     <td class="results">800 s</td>
     <td class="results">1 core @ 2.5 Ghz (Matlab + C/C++)</td>
     <td class="results"><input type="checkbox" value="f14b1f46f8363c029642629b4c5fe9f22ba93ced" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">S. Hadfield, K. Lebeda and R. Bowden: <a href="http://scholar.google.de/scholar?q=Stereo%20reconstruction%20using%20top-down%20cues"> Stereo reconstruction using top-down 
cues</a>. Computer Vision and Image 
Understanding 2016.<br></td>
   </tr>
   <tr>
    <td class="results">210</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=fbc0e59585b714cb0c2fe4628e5be446d0cabff5">CrossCensus</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">31.35 %</td>
     <td class="results">34.22 %</td>
     <td class="results">  8.0 px</td>
     <td class="results"> 10.1 px</td>
     <td class="results">30 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="fbc0e59585b714cb0c2fe4628e5be446d0cabff5" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">K. Zhang, J. Lu and G. Lafruit: <a href="http://scholar.google.de/scholar?q=Cross-Based%20Local%20Stereo%20Matching%20Using%20Orthogonal%20Integral%20Images"> Cross-Based Local Stereo Matching Using 
Orthogonal Integral Images</a>. Circuits and Systems for Video 
Technology, IEEE Transactions on 2009.<br></td>
   </tr>
   <tr>
    <td class="results">211</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=fde66093f5742e9809a43f22236e46e8b66a9946">GCSF</a></td>
     <td class="results"><div class="icon"><img src="./KITTI2012Reflective_files/icon_fl.png" alt="This method uses optical flow information."></div></td>
     <td class="results"><a href="http://cmp.felk.cvut.cz/~cechj/GCSF/" target="blank">code</a></td>
     <td class="results">31.46 %</td>
     <td class="results">33.93 %</td>
     <td class="results">  5.9 px</td>
     <td class="results">  6.7 px</td>
     <td class="results">2.4 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="fde66093f5742e9809a43f22236e46e8b66a9946" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">J. Cech, J. Sanchez-Riera and R. Horaud: <a href="http://scholar.google.de/scholar?q=Scene%20Flow%20Estimation%20by%20Growing%20Correspondence%20Seeds"> Scene Flow Estimation by Growing 
Correspondence Seeds</a>. CVPR 2011.<br></td>
   </tr>
   <tr>
    <td class="results">212</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=820ca629e25d3115fccc0f2f307eb90b39cc7a3d">GCS</a></td>
     <td class="results"></td>
     <td class="results"><a href="http://cmp.felk.cvut.cz/~cechj/" target="blank">code</a></td>
     <td class="results">32.01 %</td>
     <td class="results">34.42 %</td>
     <td class="results">  6.2 px</td>
     <td class="results">  7.0 px</td>
     <td class="results">2.2 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="820ca629e25d3115fccc0f2f307eb90b39cc7a3d" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">J. Cech and R. Sara: <a href="http://scholar.google.de/scholar?q=Efficient%20Sampling%20of%20Disparity%20Space%20for%20Fast%20And%20Accurate%20Matching"> Efficient Sampling of Disparity Space 
for Fast And Accurate Matching</a>. BenCOS 2007.<br></td>
   </tr>
   <tr>
    <td class="results">213</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=76bf3cbe03def2a20c0f4e24490cc3d5b3ad6c6f">SDM</a></td>
     <td class="results"></td>
     <td class="results"><a href="http://cmp.felk.cvut.cz/demos/Stereo/Components/Stm.html" target="blank">code</a></td>
     <td class="results">32.42 %</td>
     <td class="results">34.83 %</td>
     <td class="results">  7.7 px</td>
     <td class="results">  8.6 px</td>
     <td class="results">1 min</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="76bf3cbe03def2a20c0f4e24490cc3d5b3ad6c6f" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">J. Kostkova: <a href="http://scholar.google.de/scholar?q=Stratified%20dense%20matching%20for%20stereopsis%20in%20complex%20scenes"> Stratified dense matching for stereopsis 
in complex scenes</a>. BMVC 2003.<br></td>
   </tr>
   <tr>
    <td class="results">214</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=281865984a875b52c7679e2c77e1a057b208981c">OCV-BM-post</a></td>
     <td class="results"></td>
     <td class="results"><a href="http://opencv.willowgarage.com/wiki/" target="blank">code</a></td>
     <td class="results">32.83 %</td>
     <td class="results">35.71 %</td>
     <td class="results">  8.6 px</td>
     <td class="results">  9.3 px</td>
     <td class="results">0.1 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="281865984a875b52c7679e2c77e1a057b208981c" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">G. Bradski: <a href="http://scholar.google.de/scholar?q=The%20OpenCV%20Library"> The OpenCV Library</a>. Dr. Dobb's Journal of Software Tools 2000.<br></td>
   </tr>
   <tr>
    <td class="results">215</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=9a6116f7c4066ea76712b49de4d92d9a86a83695">MSMW</a></td>
     <td class="results"><div class="icon"><img src="./KITTI2012Reflective_files/icon_st.png" alt="This method uses stereo information."></div></td>
     <td class="results"><a href="http://demo:demo@dev.ipol.im/~facciolo/ipol_demo/msmw2/" target="blank">code</a></td>
     <td class="results">33.69 %</td>
     <td class="results">35.97 %</td>
     <td class="results">  9.3 px</td>
     <td class="results"> 10.0 px</td>
     <td class="results">3 min</td>
     <td class="results">4 cores @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="9a6116f7c4066ea76712b49de4d92d9a86a83695" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">A. Buades and G. Facciolo: <a href="http://scholar.google.de/scholar?q=On%20the%20performance%20of%20local%20methods%20for%20stereovision"> On the performance of local methods for stereovision</a>. 2013 submitted.<br></td>
   </tr>
   <tr>
    <td class="results">216</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=3ae300a3a3b3ed3e48a63ecb665dffcc127cf8ab">OCV-SGBM</a></td>
     <td class="results"></td>
     <td class="results"><a href="http://opencv.willowgarage.com/wiki/" target="blank">code</a></td>
     <td class="results">34.00 %</td>
     <td class="results">36.78 %</td>
     <td class="results"> 13.1 px</td>
     <td class="results"> 14.0 px</td>
     <td class="results">1.1 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="3ae300a3a3b3ed3e48a63ecb665dffcc127cf8ab" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">H. Hirschmueller: <a href="http://scholar.google.de/scholar?q=Stereo%20processing%20by%20semiglobal%20matching%20and%20mutual%20information"> Stereo processing by semiglobal matching 
and mutual information</a>. PAMI 2008.<br></td>
   </tr>
   <tr>
    <td class="results">217</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=09af0352b38730dc6698f9a46490810bf4b33e73">CostFilter</a></td>
     <td class="results"></td>
     <td class="results"><a href="http://www.ims.tuwien.ac.at/research/costFilter/" target="blank">code</a></td>
     <td class="results">35.43 %</td>
     <td class="results">37.95 %</td>
     <td class="results"> 11.8 px</td>
     <td class="results"> 13.5 px</td>
     <td class="results">4 min</td>
     <td class="results">1 core @ 2.5 Ghz (Matlab)</td>
     <td class="results"><input type="checkbox" value="09af0352b38730dc6698f9a46490810bf4b33e73" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">C. Rhemann, A. Hosni, M. Bleyer, C. Rother and M. Gelautz: <a href="http://scholar.google.de/scholar?q=Fast%20Cost-Volume%20Filtering%20for%20Visual%20Correspondence%20and%20Beyond"> Fast Cost-Volume Filtering for Visual 
Correspondence and Beyond</a>. CVPR 2011.<br></td>
   </tr>
   <tr>
    <td class="results">218</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=a9f1497fd2c3dc61009719031db9f9d25c2a168b">VariableCros</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">37.67 %</td>
     <td class="results">40.73 %</td>
     <td class="results"> 13.8 px</td>
     <td class="results"> 16.1 px</td>
     <td class="results">30 s</td>
     <td class="results">1 core @ 2.5 Ghz (Matlab)</td>
     <td class="results"><input type="checkbox" value="a9f1497fd2c3dc61009719031db9f9d25c2a168b" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">K. Zhang, J. Lu and G. Lafruit: <a href="http://scholar.google.de/scholar?q=Cross-Based%20Local%20Stereo%20Matching%20Using%20Orthogonal%20Integral%20Images"> Cross-Based Local Stereo Matching Using 
Orthogonal Integral Images</a>. Circuits and Systems for Video 
Technology, 
IEEE Transactions on 2009.<br></td>
   </tr>
   <tr>
    <td class="results">219</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=472e0cc8eee2b5071d94713b09593b909c05ec0d">GC+occ</a></td>
     <td class="results"></td>
     <td class="results"><a href="http://pub.ist.ac.at/~vnk/software.html" target="blank">code</a></td>
     <td class="results">42.30 %</td>
     <td class="results">45.12 %</td>
     <td class="results"> 14.9 px</td>
     <td class="results"> 17.6 px</td>
     <td class="results">6 min</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="472e0cc8eee2b5071d94713b09593b909c05ec0d" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">V. Kolmogorov and R. Zabih: <a href="http://scholar.google.de/scholar?q=Computing%20Visual%20Correspondence%20with%20Occlusions%20using%20Graph%20Cuts"> Computing Visual Correspondence with 
Occlusions using Graph Cuts</a>. ICCV 2001.<br></td>
   </tr>
   <tr>
    <td class="results">220</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=ad21e0783c1ac8e453b041715ebb8970db51aff7">ALE-Stereo</a></td>
     <td class="results"></td>
     <td class="results"><a href="http://www.inf.ethz.ch/personal/ladickyl/" target="blank">code</a></td>
     <td class="results">80.56 %</td>
     <td class="results">81.22 %</td>
     <td class="results"> 24.6 px</td>
     <td class="results"> 25.4 px</td>
     <td class="results">50 min</td>
     <td class="results">1 core @ 3.0 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="ad21e0783c1ac8e453b041715ebb8970db51aff7" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11">L. Ladicky, P. Sturgess, C. Russell, S. Sengupta, Y. Bastanlar, W. Clocksin and P. Torr: <a href="http://scholar.google.de/scholar?q=Joint%20Optimisation%20for%20Object%20Class%20Segmentation%20and%20Dense%20Stereo%20Reconstruction"> Joint Optimisation for Object Class 
Segmentation and Dense Stereo Reconstruction</a>. BMVC 2010.<br></td>
   </tr>
   <tr>
    <td class="results">221</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=bb9bac7a344cbaf746948be307b5ed85d8d2e48f">AVERAGE</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">84.41 %</td>
     <td class="results">85.32 %</td>
     <td class="results"> 26.2 px</td>
     <td class="results"> 28.2 px</td>
     <td class="results">0.01 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="bb9bac7a344cbaf746948be307b5ed85d8d2e48f" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
   <tr>
    <td class="results">222</td>
     <td class="results"><a href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=stereo&amp;error=4&amp;eval=all&amp;result=7320f46b59144717a1da1a45e6f409f71d6926ce">MEDIAN</a></td>
     <td class="results"></td>
     <td class="results"></td>
     <td class="results">87.87 %</td>
     <td class="results">88.57 %</td>
     <td class="results"> 29.6 px</td>
     <td class="results"> 31.5 px</td>
     <td class="results">0.01 s</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
     <td class="results"><input type="checkbox" value="7320f46b59144717a1da1a45e6f409f71d6926ce" name="selected[]"></td>
   </tr>
   <tr>
    <td class="results_sub" colspan="11"></td>
   </tr>
 </tbody></table></form>

<center><a target="_blank" href="https://www.cvlibs.net/datasets/kitti/table_stereo_flow.php?benchmark=stereo&amp;table=refl&amp;error=4&amp;eval=all&amp;mode=1">This table as LaTeX</a></center><br><br>

</div></div>
<div class="section">
<h2 class="title">Related Datasets</h2>
<div class="entry"><p>

</p><ul>
<li><a href="http://hci.iwr.uni-heidelberg.de/Static/challenge2012/" target="_blank">HCI/Bosch Robust Vision Challenge</a>: Optical flow and stereo vision challenge on high resolution imagery recorded at a high frame rate under diverse weather conditions (e.g., sunny, cloudy, rainy). The Robert Bosch AG provides a prize for the best performing method.</li>
<li><a href="http://www.mi.auckland.ac.nz/index.php?option=com_content&amp;view=article&amp;id=44&amp;Itemid=67" target="_blank">Image Sequence Analysis Test Site (EISATS)</a>: Synthetic image sequences with ground truth information provided by UoA and Daimler AG. Some of the images come with 3D range sensor information.</li>
<li><a href="http://vision.middlebury.edu/stereo/" target="_blank">Middlebury Stereo Evaluation</a>: The classic stereo evaluation benchmark, featuring four test images in version 2 of the benchmark, with very accurate ground truth from a structured light system. 38 image pairs are provided in total.</li>
<li><a href="http://www.6d-vision.com/ground-truth-stixel-dataset" target="_blank">Daimler Stereo Dataset</a>: Stereo bad weather highway scenes with partial ground truth for freespace</li>
<li><a href="http://make3d.cs.cornell.edu/data.html" target="_blank">Make3D Range Image Data</a>: Images with small-resolution ground truth used to learn and evaluate depth from single monocular images.</li>
<li><a href="http://www.robots.ox.ac.uk/~lubor/" target="_blank">Lubor Ladicky's Stereo Dataset</a>: Stereo Images with manually labeled ground truth based on polygonal areas.</li>
</ul>
<p></p></div></div>

<div class="section">
<h2 class="title">Citation</h2>
<div class="entry"><p>
When using this dataset in your research, we will be happy if you cite us:<br>
@INPROCEEDINGS{<a href="https://www.cvlibs.net/publications/Geiger2012CVPR.pdf" target="_blank">Geiger2012CVPR</a>,<br>
&nbsp; author = {<a href="https://www.cvlibs.net/" target="blank">Andreas Geiger</a> and <a href="http://www.mrt.kit.edu/mitarbeiter_lenz.php" target="blank">Philip Lenz</a> and <a href="http://ttic.uchicago.edu/~rurtasun" target="blank">Raquel Urtasun</a>},<br>
&nbsp; title = {Are we ready for Autonomous Driving? The KITTI Vision Benchmark Suite},<br>&nbsp; booktitle = {Conference on Computer Vision and Pattern	Recognition (CVPR)},<br>
&nbsp; year = {2012}<br>
}
</p></div></div>

  <div class="clearfix"></div>
  <div class="tracker">
  <div id="eXTReMe"><br><br><a href="http://extremetracking.com/open?login=votec">
  <img src="./KITTI2012Reflective_files/i.gif" style="border: 0;" height="38" width="41" id="EXim" alt="eXTReMe Tracker"></a>
  <script type="text/javascript"><!--
  var EXlogin='votec' // Login
  var EXvsrv='s10' // VServer
  EXs=screen;EXw=EXs.width;navigator.appName!="Netscape"?
  EXb=EXs.colorDepth:EXb=EXs.pixelDepth;
  navigator.javaEnabled()==1?EXjv="y":EXjv="n";
  EXd=document;EXw?"":EXw="na";EXb?"":EXb="na";
  EXd.write("<img src=http://e1.extreme-dm.com",
  "/"+EXvsrv+".g?login="+EXlogin+"&amp;",
  "jv="+EXjv+"&amp;j=y&amp;srw="+EXw+"&amp;srb="+EXb+"&amp;",
  "l="+escape(EXd.referrer)+" height=1 width=1>");//-->
  </script><img src="./KITTI2012Reflective_files/s10.g" height="1" width="1"><noscript><div id="neXTReMe"><img height="1" width="1" alt=""
  src="http://e1.extreme-dm.com/s10.g?login=votec&amp;j=n&amp;jv=n" />
  </div></noscript></div>
  </div>

</div>
<div class="clearfix">&nbsp;</div>
</div>
</div>

<div id="footer" class="container">
	<p>© 2023 | <a href="https://www.cvlibs.net/aboutme.html" target="_blank">Andreas Geiger</a> | <a href="https://www.cvlibs.net/" target="_blank">cvlibs.net</a> | <a href="http://www.freecsstemplates.org/" target="_blank">csstemplates</a></p>
</div>





</body></html>