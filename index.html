<html lang="en" class=" js "><head><meta charset="utf-8"> 
    <title>Ziyang Chen-陈子扬</title><meta property="og:locale" content="en">
<meta property="og:site_name" content="">
<meta property="og:title" content="">
<link rel="canonical" href="https://chrischoy.github.io/">
<meta property="og:url" content="https://chrischoy.github.io/">
<meta name="twitter:site" content="@">
<meta name="twitter:title" content="">
<meta name="twitter:description" content="Computer Vision’er’">
<meta name="twitter:url" content="https://chrischoy.github.io/">
<meta name="twitter:card" content="summary"> 
<script type="text/javascript" async="" src="https://ssl.google-analytics.com/ga.js"></script><script type="application/ld+json"> 
    { "@context" : "http://schema.org", 
      "@type" : "Person", 
      "name" : "", 
      "url" : "https://chrischoy.github.io", 
      "sameAs" : null } 
</script> 
<link href="https://chrischoy.github.io/feed.xml" type="application/atom+xml" rel="alternate" title=" Feed"> 
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0"> 
<script> document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js '; </script> 
<link rel="shortcut icon" href="img/GZU-removebg-preview.ico" type="image/x-icon">
<link rel="stylesheet" href="https://chrischoy.github.io/assets/css/main.css">
<meta http-equiv="cleartype" content="on"> 

<style type="text/css">
    table.gridtable {
        font-family: verdana,arial,sans-serif;
        font-size:11px;
        color:#333333;
        border-width: 1px;
        border-color: #666666;
        border-collapse: collapse;
    }
    table.gridtable th {
        border-width: 1px;
        padding: 8px;
        border-style: solid;
        border-color: #666666;
        background-color: #dedede;
    }
    table.gridtable td {
        border-width: 1px;
        padding: 8px;
        border-style: solid;
        border-color: #666666;
        background-color: #ffffff;
    }
</style>


<!--实现悬停功能-->
<style>
    /* 设置一些样式，确保图像不会超过容器 */
    #gif-container {
      overflow: hidden;
      box-shadow: 4px 4px 8px #888;
    }
  </style>
<!--实现点击复制功能-->
<style id="fit-vids-style">.fluid-width-video-wrapper{width:100%;position:relative;padding:0;}.fluid-width-video-wrapper iframe,.fluid-width-video-wrapper object,.fluid-width-video-wrapper embed {position:absolute;top:0;left:0;width:100%;height:100%;}</style><script charset="utf-8" src="https://platform.twitter.com/js/timeline.16b53cc33aaa562f8f41a495bf720289.js"></script>
<script>
    copyInnerTextOfCell = (event) => {
      let innerText = event.target.innerText;
      var tmpInput = document.createElement("input");
      document.body.appendChild(tmpInput);
      tmpInput.value = "ziyangchen2000@gmail.com";
      tmpInput.select();
      document.execCommand("cut"); // copy
      tmpInput.remove();
      alert("Copy Succeed! This is ZiyangChen's email address!" + "成功复制陈子扬的电子邮箱地址！");
    }
</script>

<!--实现点击展开功能-->
<meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
    .collapsible {
      background-color: #f1f1f1;
      color: black;
      cursor: pointer;
      padding: 18px;
      width: 100%;
      border: none;
      text-align: center; 
      outline: none;
      font-size: 15px;
    }

    .content {
      padding: 0 18px;
      display: none;
      overflow: hidden;
      background-color: white;
    }
    </style>

    <title>倒计时</title>
    <style>
        #timer {
            font-size: 15px;
            text-align: center;
            margin-top: 1px;
        }
    </style>

    <title>Current Date1</title>

    <title>Current Date2</title>

</head>
<body style="margin-bottom: 131px;">
<div class="masthead">
    <div class="masthead__inner-wrap">
        <div class="masthead__menu">
            <nav id="site-nav" class="greedy-nav"> 
                <button class="hidden" count="0"><div class="navicon"></div></button>
                <ul class="visible-links">
                    <li class="masthead__menu-item"><a href="">Home</a></li>
                    <li class="masthead__menu-item"><a href="#news">News</a></li>
                    <li class="masthead__menu-item"><a href="#publications">Publications</a></li>
                    <li class="masthead__menu-item"><a href="#communication">Communications</a></li>
                    <li class="masthead__menu-item"><a href="#education">Experience</a></li>
                    <li class="masthead__menu-item"><a href="#social">Service</a></li>
                    <li class="masthead__menu-item"><a href="#visitors">Visitors</a></li>
                </ul>
                <ul class="hidden-links hidden"></ul>
            </nav>
        </div>
    </div>
</div>
<div id="main" role="main">
    <div class="sidebar sticky">
        <div itemscope="" itemtype="http://schema.org/Person">
            <div class="author__content">
                <img src="img/ChenziyangPhoto2.jpg">
                <h3 class="author__name">Ziyang Chen</h3>
                <p class="author__bio">Master of C.S.<br>Guizhou University<br>陈子扬<br>贵州大学<br>计算机科学与技术学硕</p>
            </div>
            <div class="author__urls-wrapper"> 
                <button class="btn btn--inverse">Follow</button>
                <ul class="author__urls social-icons" style="display: none;">
                    <li><a onclick="copyInnerTextOfCell(event)"><i class="fa fa-envelope" aria-hidden="true"></i>&nbsp;&nbsp;ziyangchen2000@gmail.com</a></li>
                    <li><a href="https://github.com/ZYangChen"><i class="fa fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
                    <li><a href="https://orcid.org/0000-0002-9361-0240"><i class="fa fa-info-circle"></i>&nbsp;&nbsp;ORCID</a></li>
                    <li><a href="https://scholar.google.com/citations?user=t64KgqAAAAAJ&hl=en&oi=sra"><i class="fa fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
                    <li><a href="https://webofscience.clarivate.cn/wos/author/record/KHX-1531-2024"><i class="fa fa-internet-explorer"></i>&nbsp;&nbsp;Web of Science</a></li>
                    <li><a href="https://www.semanticscholar.org/author/Ziyang-Chen/2296219254"><i class="fa fa-scribd"></i>&nbsp;&nbsp;Semantic Scholar</a></li>
                    <li><a href="https://www.researchgate.net/profile/Ziyang-Chen-25"><i class="fa fa-registered"></i>&nbsp;&nbsp;Research Gate</a></li>               
                    <li><a href="https://dblp.org/pid/96/4424-2.html"><i class="fa fa-fw fa-graduation-cap" aria-hidden="true"></i>&nbsp;&nbsp;DBLP</a></li>
                </ul>
            </div>
        </div>
    </div>    
    
    <article class="page" itemscope="" itemtype="http://schema.org/CreativeWork"><meta itemprop="dateModified" content="April 06, 2020">
        <div class="page__inner-wrap"><header></header><section class="page__content" itemprop="text">
            <p>
                【<strong>English Resume</strong>】【<a href="Chinese.html">中文简历</a>】<br>
                Hello! My name is Ziyang Chen (陈子扬). I am currently pursuing a MSc in Computer Science & Technology at Guizhou University. My supervisor is 
                Prof. <a href="http://cs.gzu.edu.cn/2021/1210/c17588a163831/page.htm">Yongjun Zhang (张永军)</a>. 
                I was guided by Prof. <a href="https://www.scholat.com/hlin">Hailin Li (李海林)</a> when I was an undergraduate student.
                My current research interest lies in <strong>Stereo Vision</strong>. 
            </p>
            <!--<h2 id="exhibition">Exhibition</h2>
            <div>

            </div>-->
            <h2 id="news">News 📝</h2>
            <details open=""><summary>Click to expand</summary>
            <div style="height: 233px; overflow: auto;">                       
            <ul>
                <!--✌Master-->
                <li><i>Oct. 1, 2024:</i> I am awarded <font color="red">National Scholarship</font>.</li>
                <li><i>Jun. 7, 2024:</i> <font color="red">MoCha-V2</font> ranks <strong>1st</strong> on <a href="img/bad1-all.html">Middlebury benchmark</a>!🚀🚀🚀 I am the designer of this algorithm. 
                    <details id="closeDetails"><summary>Click to expand the screenshots of stereo matching leaderboards</summary>
                        <ul>
                            <li>🚩Middlebury leaderboard (Jun. 7, 2024) 👇
                            <img style="width:100%;" src="img/middlebury.png"></li>
                            <li>🚩<a href="img/ref/eth3d-benchmark/Low-res two-view results - ETH3D.html">ETH3D leaderboard</a> (Jun. 27, 2024) 👇
                            <img style="width:100%;" src="img/ref/eth3d-benchmark/eth3d.png"></li>
                        </ul>
                    </details>  
                </li>
                <li><i>Feb. 27, 2024:</i> <font color="red">MoCha-Stereo (抹茶算法)</font> is accepted by <a href="https://cvpr.thecvf.com/Conferences/2024/AcceptedPapers">CVPR2024</a>!!! [<a href="http://gs.gzu.edu.cn/2024/0315/c13269a213613/page.htm">Report</a>]🔥🔥🔥 This is the <strong>first time</strong> that Guizhou University publishes its work in CVPR as the <strong>only corresponding institution</strong>. 
                    It once held <strong>1st</strong> on <a href="img/ref/KITTI2015_11_18.html">
                    KITTI 2015
                    </a> and 
                    <a href="img/ref/KITTI2012Reflective.html">
                    KITTI 2012 Reflective
                    </a> benchmarks for 245 days. 🚀🚀🚀 I am the designer of this algorithm. 
                    
                    <details id="closeDetails"><summary>Click to expand the screenshots of these leaderboards (Nov. 3, 2023)</summary>
                        <ul>
                            <li>🚩KITTI 2015 leaderboard 👇
                            <img style="width:100%;" src="img/KITTI_20151.png"></li>
                            <li>🚩KITTI 2012 Reflective leaderboard 👇
                            <img style="width:100%;" src="img/KITTI_20121.png"></li>
                        </ul>
                    </details>      

                </li>

                <li><i>Feb. 1, 2024:</i> <font color="red">HART (赤鹿算法)</font> proposed by us ranks <strong>1st</strong> on 
                    <a href="img/ref/HART/KITTI2012.html">KITTI 2012 Reflective</a>
                    benchmark! 🚀🚀🚀 I am the designer of this algorithm. 
                </li>
                
            </ul>
            </div>
            </details>


            <h2 id="publications">Selected Publications 📖</h2>
            <div>
                <div class="box" style="text-align: center;">
                    <HR style="border:1 dashed #666666" width="100%" color=#666666 SIZE=5>
                    <span style="text-align: center"><strong>2025</strong></span>
                    <HR style="border:1 dashed #666666" width="100%" color=#666666 SIZE=5>
                </div>
                <article class="archive__item" itemscope="" itemtype="http://schema.org/CreativeWork">
                    <div class="publication">                         
                        <div class="left" id="hart"> 
                            <img src="img/hart.png" width="700" style="box-shadow: 4px 4px 8px #888">
                        </div>
                        <div class="right">
                            <h3><a href="https://github.com/ZYangChen">
                                Hadamard Attention Recurrent Transformer: A Strong Baseline for Stereo Matching Transformer
                            </a></h3>
                            <a class="author"><strong>Ziyang Chen</strong></a>,
                            <a class="author" href="http://cs.gzu.edu.cn/2021/1210/c17588a163831/page.htm">Yongjun Zhang✉</a>,
                            <a class="author" href="https://www.gzcc.edu.cn/jsjyxxgcxy/contents/3205/3569.html">Wenting Li</a>,
                            <a class="author" href="https://teacher.nwpu.edu.cn/wangbingshu.html">Bingshu Wang</a>,
                            <a class="author" href="https://orcid.org/0009-0007-2504-0219">Yabo Wu</a>,
                            <a class="author" href="https://www.ece.pku.edu.cn/info/1045/2131.htm">Yong Zhao</a>,
                            <a class="author" href="http://dsail.vip/PersonInCharge.html">C. L. Philip Chen</a>
                            <br>
                            <p class="venue">                                    
                                📙Arxiv Report
                            </p>
                            <div class="btn-links">                         
                                <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2501.01023" target="_blank" rel="noopener">
                                    Paper
                                </a>
                                <a href="./manuscript/hart.txt" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename="">
                                    Cite
                                </a>
                                <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/ZYangChen/HART" target="_blank" rel="noopener">
                                    Code
                                </a>
                                <img src="https://img.shields.io/github/stars/ZYangChen/HART?style=social">
                            </div>
                        </div>                        

                        <br>

                        <div class="left"> 
                            <img src="img/MoChaV2.jpg" width="700" style="box-shadow: 4px 4px 8px #888">
                        </div>
                        <div class="right">
                            <h3><a href="https://ieeexplore.ieee.org/document/10689488">
                                Motif Channel Opened in a White-Box: Stereo Matching via Motif Correlation Graph
                            </a></h3>
                            <a class="author"><strong>Ziyang Chen</strong></a>,
                            <a class="author" href="http://cs.gzu.edu.cn/2021/1210/c17588a163831/page.htm">Yongjun Zhang✉</a>,
                            <a class="author" href="https://www.gzcc.edu.cn/jsjyxxgcxy/contents/3205/3569.html">Wenting Li</a>,
                            <a class="author" href="https://teacher.nwpu.edu.cn/wangbingshu.html">Bingshu Wang</a>,
                            <a class="author" href="https://www.ece.pku.edu.cn/info/1045/2131.htm">Yong Zhao</a>,
                            <a class="author" href="http://dsail.vip/PersonInCharge.html">C. L. Philip Chen</a>
                            <br>
                            <p class="venue">                                    
                                📙Arxiv Report
                            </p>
                            <div class="btn-links">                         
                                <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2411.12426" target="_blank" rel="noopener">
                                    Paper
                                </a>
                                <a href="./manuscript/mocha.txt" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename="">
                                    Cite
                                </a>
                                <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/ZYangChen/MoCha-Stereo" target="_blank" rel="noopener">
                                    Code
                                </a>
                                <img src="https://img.shields.io/github/stars/ZYangChen/MoCha-Stereo?style=social">
                            </div>
                        </div>
                    </div>
                    </article>   
                    <div class="box" style="text-align: center;">
                        <HR style="border:1 dashed #666666" width="100%" color=#666666 SIZE=5>
                        <span style="text-align: center"><strong>2024</strong></span>
                        <HR style="border:1 dashed #666666" width="100%" color=#666666 SIZE=5>
                    </div>
                    <article class="archive__item" itemscope="" itemtype="http://schema.org/CreativeWork">
                        <div class="publication">
                        <div class="left" id="mocha"> 
                            <img src="img/MoCha.gif" width="700" style="box-shadow: 4px 4px 8px #888">
                        </div>
                        <div class="right">
                            <h3><a href="https://arxiv.org/abs/2404.06842">
                                MoCha-Stereo: Motif Channel Attention Network for Stereo Matching
                            </a></h3>                                                        
                            <a class="author"><strong>Ziyang Chen</strong>†</a>,
                            <a class="author" href="https://scholar.google.com/citations?user=CsVTBJoAAAAJ&hl=en">Wei Long†</a>,
                            <a class="author" href="https://orcid.org/0009-0002-4212-5023">He Yao†</a>,
                            <a class="author" href="http://cs.gzu.edu.cn/2021/1210/c17588a163831/page.htm">Yongjun Zhang✉</a>,
                            <a class="author" href="https://teacher.nwpu.edu.cn/wangbingshu.html">Bingshu Wang</a>,
                            <a class="author" href="http://cs.gzu.edu.cn/2021/1210/c17588a163794/page.htm">Yongbin Qin</a>,
                            <a class="author" href="https://faculty.csu.edu.cn/jiawu/zh_CN/index.htm">Jia Wu</a>
                            <p class="venue">
                            📕<a href="https://cvpr.thecvf.com/Conferences/2024">IEEE Conference on Computer Vision and Pattern Recognition (<font color="red">CVPR</font>) 2024</a><br>
                             💡CCF-A 💡CAAI-A 💡<a href="./manuscript/google_scholar.html">H5-index: 440 (<font color="red">1st</font> in CS, <font color="red">1st</font> in CV)</a>
                            </p>
                            <div class="btn-links">
                                <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content/CVPR2024/html/Chen_MoCha-Stereo_Motif_Channel_Attention_Network_for_Stereo_Matching_CVPR_2024_paper.html" target="_blank" rel="noopener">
                                    Paper
                                </a>
                                <a id="chinese2025" class="btn btn-outline-primary btn-page-header btn-sm" target="_blank" rel="noopener">
                                    中文
                                </a> 
                                <a href="./manuscript/mocha.txt" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename="">
                                    Cite
                                </a>
                                <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/ZYangChen/MoCha-Stereo" target="_blank" rel="noopener">
                                    Code
                                </a>
                                <img src="https://img.shields.io/github/stars/ZYangChen/MoCha-Stereo?style=social">
                            </div>
                            <script>
                                // 获取按钮元素
                                var chineseButton = document.getElementById('chinese2025');
                            
                                // 添加点击事件
                                chineseButton.addEventListener('click', function() {
                                    // 显示提示弹窗
                                    alert("Sorry! It will be available to the public in 2026!");
                                });
                            </script> 
                        </div> 
                        
                        <br>
                                                                                                                               
                        <div class="left"> 
                            <img src="img/dc_sat.png" width="700" style="box-shadow: 4px 4px 8px #888">
                        </div>
                        <div class="right">
                            <h3><a href="https://ieeexplore.ieee.org/document/10689488">
                                Surface Depth Estimation from Multi-view Stereo Satellite Images with Distribution Contrast Network
                            </a></h3>
                            <a class="author"><strong>Ziyang Chen</strong></a>,
                            <a class="author" href="https://www.gzcc.edu.cn/jsjyxxgcxy/contents/3205/3569.html">Wenting Li✉</a>,
                            <a class="author" href="https://tongzhan.gznc.edu.cn/info/1015/3622.htm">Zhongwei Cui</a>,
                            <a class="author" href="http://cs.gzu.edu.cn/2021/1210/c17588a163831/page.htm">Yongjun Zhang✉</a>
                            <br>
                            <p class="venue">                                    
                                📘IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 2024
                                <br>💡JCR Q1 💡SCI Q2 <font color="red">TOP</font> 💡CAAI-B 💡IF: 4.7
                            </p>
                            <div class="btn-links">                         
                                <a class="btn btn-outline-primary btn-page-header btn-sm" href="manuscript/Surface_Depth_Estimation_from_Multi-view_Stereo_Satellite_Images_with_Distribution_Contrast_Network.pdf" target="_blank" rel="noopener">
                                    Paper
                                </a>
                                <a href="./manuscript/dc_satmvs.txt" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename="">
                                    Cite
                                </a>
                                <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/ZYangChen/DC-SatMVS" target="_blank" rel="noopener">
                                  Code
                                </a>
                                <img src="https://img.shields.io/github/stars/ZYangChen/DC-SatMVS?style=social">
                            </div>
                        </div>

                        <br>
                                                                                                                               
                        <div class="left"> 
                            <img src="img/scene91.gif" width="700" style="box-shadow: 4px 4px 8px #888">
                        </div>
                        <div class="right">
                            <h3><a href="https://link.springer.com/article/10.1007/s00371-024-03334-1">
                                FDN-MVS: Feature Distribution Normalization Network for Multi-View Stereo
                            </a></h3>
                            <a class="author"><strong>Ziyang Chen</strong></a>,
                            <a class="author" href="https://orcid.org/0009-0002-1031-5260">Yang Zhao</a>,
                            <a class="author" href="https://orcid.org/0009-0000-7588-3088">Junling He</a>,  
                            <a class="author" href="https://orcid.org/0009-0008-9786-5946">Yujie Lu</a>,   
                            <a class="author" href="https://tongzhan.gznc.edu.cn/info/1015/3622.htm">Zhongwei Cui</a>,
                            <a class="author" href="https://www.gzcc.edu.cn/jsjyxxgcxy/contents/3205/3569.html">Wenting Li</a>,
                            <a class="author" href="http://cs.gzu.edu.cn/2021/1210/c17588a163831/page.htm">Yongjun Zhang✉</a>
                            <br>
                            <p class="venue">                                    
                                📘The Visual Computer 2024
                                <br>💡JCR Q2 💡SCI Q3 💡CCF-C 💡CAAI-C 💡IF: 3.5
                            </p>
                            <div class="btn-links">                         
                                <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://link.springer.com/article/10.1007/s00371-024-03334-1" target="_blank" rel="noopener">
                                    Paper
                                </a>
                                <a href="./manuscript/fdn.txt" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename="">
                                    Cite
                                </a>
                                <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/ZYangChen/FDN-MVS" target="_blank" rel="noopener">
                                  Code
                                </a>
                                <img src="https://img.shields.io/github/stars/ZYangChen/FDN-MVS?style=social">
                            </div>
                        </div>
                            
                                                                          
                    </div>                    
                </article>
                
            
            </div>
             

            <div>
                <small><details open=""><summary>Description of symbols</summary>
                    <ul>
                        <li>✉&nbsp;: Corresponding author</li>
                        <li>&nbsp;†&nbsp; : Co-first author</li>
                        <li>📘: Journal</li>
                        <li>📕: Conference</li>
                        <li>📙: Others</li>
                    </ul>
                    The above zoning and related values are based on the paper at the time of acceptence. If you want to see all of my works, 
                        please check via <a href="https://scholar.google.com/citations?user=t64KgqAAAAAJ&hl=en&oi=sra">Google Scholar</a>.
                </details></small>
            </div>

            <h2 id="communication">Open Source Communications 🤝</h2>
            <details id="closeDetails"><summary>Click to expand</summary>
                <div style="height: 180px; overflow: auto;">        
                <table class="gridtable">
                    <tr>
                        <th>Occasion</th><th>Level</th><th>Form</th><th>Where</th><th>When</th><th>Introduction Title</th><th>Presentation Type</th><th>Material</th>
                    </tr>

                    <tr>
                        <td><a href="https://cvpr.thecvf.com/Conferences/2024">The 34th IEEE/CVF Conference on Computer Vision and Pattern Recognition</a> (CVPR2024)<br>
                            <br>|<a href="img/ref/Track_ Poster Session 6 & Exhibit Hall.html">Schedule</a>
                            <br>|<a href="img/scene_of_cvpr2024.jpg">Scene</a>
                        </td>
                        <td>International<br>& CCF-A</td>
                        <td>IEEE Conference Proceeding</td>
                        <td>Seattle, USA</td>
                        <td>Jun. 21, 2024</td>
                        <td>MoCha-Stereo: Motif Channel Attention Network for Stereo Matching</td>
                        <td>Onsite Poster & Paper Included</td>
                        <td>|<a href="manuscript/mocha_poster.pdf">Poster</a><br>|<a href="#mocha">Paper⭐</a><br>(Representative Work)</td>
                    </tr>
                    
                    <!--<tr>
                        <td><a href="https://icmva.org/">The 7th International Conference on Machine Vision and Applications</a> (ICMVA 2024)<br>
                            <br>|<a href="manuscript/ICMVA2024-InvitaionLetter-Ziyang Chen.pdf">Invitaion Letter</a>
                            <br>|<a href="manuscript/ICMVA-2024-Program.pdf">Schedule</a>
                        </td>
                        <td>International</td>
                        <td>ACM Conference Proceeding</td>
                        <td>Singapore</td>
                        <td>Mar. 13, 2024</td>
                        <td>Why not normalise the distribution for multi-view stereo refinement [M048-A]</td>
                        <td>Online Oral</td>
                        <td></td>
                    </tr>-->
                </table>
                <!--以下是一些我好朋友的工作,我认为他们的工作同样值得推荐
                <br>
                Here are some of my good friends' works that I think are worth recommending:
                <ul>
                    <li><a href="https://orcid.org/0000-0002-4121-2742"><strong>Long W (龙伟)</strong></a>, Zhang Y✉, Cui Z, et al. Threshold Attention Network for Semantic Segmentation of Remote Sensing Images[J]. <font color="red">IEEE Trans</font>actions on Geoscience and Remote Sensing, 2023.</li>
                    <li><a href="https://orcid.org/0009-0002-4212-5023"><strong>Yao H (姚和)</strong></a>, Zhang Y✉, Jian H, et al. Nighttime pedestrian detection based on Fore-Background contrast learning[J]. Knowledge-Based Systems, 2023: 110719.</li>
                    <li><a href="https://www.scholat.com/hlin">Li H</a>✉, <a href="https://mahochan.github.io/"><strong>Chen M (陈漫桦)</strong></a>. <a href="https://www.sciencedirect.com/science/article/pii/S1568494623008943">Time series clustering based on normal cloud model and complex network</a>[J]. Applied Soft Computing, 2023, 148: 110876. </li>
                    <li><strong>Xu Y(徐毓杰)</strong>, Zhang Y✉, <a href="http://cs.gzu.edu.cn/2021/1210/c17588a163796/page.htm">Li Z</a>, et al. <a href="https://www.sciencedirect.com/science/article/pii/S0097849322001182">Multi-scale dehazing network via high-frequency feature fusion</a>[J]. Computers & Graphics, 2022, 107: 50-59. [<a href="https://github.com/xuyj-DL/HFDMN">Code</a>]</li>
                    <li><strong>Xu Y(徐毓杰)</strong>, Zhang Y✉, et al. <a href="https://www.sciencedirect.com/science/article/pii/S0045790622005274">A robust edge-guided and color-guided network for single image dehazing</a>[J]. Computers and Electrical Engineering, 2022, 103: 108301. [<a href="https://github.com/GZU-ZhangYJ-group/ECGDN">Code</a>]</li>
                </ul>                                                                                                                             
                        
                </div>  -->
            </details>    

            <div>
                <h2 id="education">Experience 🏃‍♂️</h2>
                <dl>
                    <span>
                    <dt><img src="img/gzu.jpg" width="150" height="150" alt="gzu" align="left"></dt>
                    <dt> 👨‍🎓 Guizhou University </dt>
                    <dd>&nbsp; Sep. 2022 - Jun. 2025 (Expected)</dd>
                    <dd>&nbsp; <strong>Master</strong> of Science in Computer Science</dd>
                    <dd>&nbsp; <i>Supervisor:</i> Prof. <a href="http://cs.gzu.edu.cn/2021/1210/c17588a163831/page.htm">Yongjun Zhang</a> (张永军 教授) </dd>
                    <dd>&nbsp; 🎖 Nov. 2024, <a href="https://www.gzu.edu.cn/2024/1108/c635a242007/page.htm">Merit Student</a>.</dd>
                    <dd>&nbsp; 🎖 Sep. 2024, <a href="https://gsa.gzu.edu.cn/2024/0923/c18220a236773/page.htm">National Scholarship</a>.</dd>
                    <br>
                    <br>

                    <span>                        
                    <dt><img src="img/hqu.jpg" width="150" height="150" alt="hqu" align="left"></dt>
                    <dt> 👨‍🎓 Huaqiao University </dt>
                    <dd>&nbsp; Jun. 2018 - Jul. 2022</dd>
                    <dd>&nbsp; <strong>Bachelor</strong> of Administration in Information Management and Information Systems </dd>
                    <dd>&nbsp; <i>Supervisor:</i> Prof. <a href="https://www.scholat.com/hlin">Hailin Li</a> (李海林 教授) </dd>
                    <dd>&nbsp; <i>Lab:</i> <a href="https://www.scholat.com/team/hqudm">HQUDM (华侨大学数据科学与创新管理研究团队)</a>, 
                        leading by Prof. Hailin Li </dd>
                    <dd>&nbsp; 🎖 Jun. 2022, <a href="https://jwc.hqu.edu.cn/info/1138/8788.htm">Excellent Graduation Thesis (优秀毕业论文)</a>. Rank: 1/48</dd>
                    <dd>&nbsp; 🎖 Dec. 2021, Huaqiao University Scholarship.</dd>
                    </span>
                </dl>

                <h2 id="social">Social Service 👨‍💼</h2>  
                Reviewer of
                <ul>
                    <li>IEEE Transactions on Circuits and Systems for Video Technology (IEEE TCSVT)</li>       
                    <li>Knowledge-Based Systems (KBS)</li>
                    <li>Neurocomputing</li>
                    <li>Photogrammetric Engineering & Remote Sensing</li>
                    <li>International Journal of Machine Learning and Cybernetics</li>
                    <li>Electronics Letters</li>
                    <!-- <li>the 8th International Conference on Computer Science and Application Engineering (CSAE)</li> -->
                </ul>   

                Student Member of
                <ul>
                    <li><a href="https://ieeexplore.ieee.org/Xplore/home.jsp">IEEE</a> <small>📧IEEE e-mail: ziyangchen@ieee.org</small></li>      
                </ul>
                            
                <h2 id="visitors">Visitors 🌏</h2>                
                </div>
                    <script type="text/javascript" src="//rf.revolvermaps.com/0/0/6.js?i=5u5v36uynno&amp;m=6&amp;c=00fff6&amp;cr1=ffc000&amp;f=arial&amp;l=0" async="async"></script>
                </div></section>
                <footer class="page__meta"><p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Updated:</strong> <time datetime="2024-09-07">Sep. 7, 2024</time></p></footer>
            </div>    
        </div>
    </article>
</div>
<div class="page__footer"><footer>
<div class="page__footer-copyright">
    The template for the design of the web page borrow codes comes from <a href="https://github.com/YunheWang/HomePage">Yunhe Wang</a>,
    <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>. </div>
</footer></div><script src="https://chrischoy.github.io/assets/js/main.min.js"></script> <script type="text/javascript"> var _gaq = _gaq || []; _gaq.push(['_setAccount', 'UA-43980256-2']); _gaq.push(['_trackPageview']); (function() { var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true; ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s); })(); </script> <script src="//d3js.org/d3.v4.min.js" type="text/javascript"></script> <script src="//d3js.org/d3-axis.v1.min.js" type="text/javascript"></script>
<!--<iframe scrolling="no" frameborder="0" allowtransparency="true" src="https://platform.twitter.com/widgets/widget_iframe.2b2d73daf636805223fb11d48f3e94f7.html?origin=https%3A%2F%2Feveneveno.github.io" title="Twitter settings iframe" style="display: none;"></iframe><iframe id="rufous-sandbox" scrolling="no" frameborder="0" allowtransparency="true" allowfullscreen="true" style="position: absolute; visibility: hidden; display: none; width: 0px; height: 0px; padding: 0px; border: none;" title="Twitter analytics iframe"></iframe></body></html>-->
